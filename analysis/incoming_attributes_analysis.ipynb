{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "This notebook investigates the student population given incoming attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "# Preparing the data\n",
    "We need to load pre survey (incoming attitudes), post survey (demographics data), and worksheet (incoming knowledge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di\n",
    "\n",
    "# This line will hide code by default when the notebook is converted to HTML\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\applications\\anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils_read_parsing\n",
    "%aimport utils_timeline_viz\n",
    "from utils_timeline_viz import *\n",
    "from utils_read_parsing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import ranksums\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "pd.set_option(\"display.width\", 100)\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.api import interaction_plot, abline_plot\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = 10, 6\n",
    "pd.set_option('precision',3)\n",
    "np.set_printoptions(precision=3,suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Grabbing the worksheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%reload_ext utils_read_parsing\n",
    "#grab worksheet data - beers\n",
    "worksheets = get_worksheet_metadata('beers')\n",
    "pre_b = get_pre_worksheet(sim='beers')\n",
    "\n",
    "ids = get_students_to_analyze_log_worksheets('beers')\n",
    "pre_b = pre_b[pre_b['Student ID'].isin(worksheets[(worksheets['Type']=='p')&worksheets['Student ID'].isin(ids)]['other id'].values)]\n",
    "\n",
    "#ids in pre/post match \"other id\" in worksheet metdata so we need to assign the correct id in logs for each entry in pre/post\n",
    "pre_b['sid'] = pre_b['Student ID'].apply(lambda row: worksheets.loc[worksheets[(worksheets['other id']==row)].index[0],'Student ID'])\n",
    "\n",
    "#grab worksheet data - caps\n",
    "worksheets = get_worksheet_metadata('caps')\n",
    "pre_c = get_pre_worksheet(sim='caps')\n",
    "\n",
    "ids = get_students_to_analyze_log_worksheets('caps')\n",
    "pre_c= pre_c[pre_c['Student ID'].isin(worksheets[(worksheets['Type']=='p')&worksheets['Student ID'].isin(ids)]['other id'].values)]\n",
    "\n",
    "#ids in pre/post match \"other id\" in worksheet metdata so we need to assign the correct id in logs for each entry in pre/post\n",
    "pre_c['sid'] = pre_c['Student ID'].apply(lambda row: worksheets.loc[worksheets[(worksheets['other id']==row)].index[0],'Student ID'])\n",
    "\n",
    "pre_b.index = pre_b['sid']\n",
    "pre_c.index = pre_c['sid']\n",
    "pre_b.drop(['Student ID','sid'],axis=1,inplace=True)\n",
    "pre_c.drop(['Student ID','sid'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Grabbing survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File pre_survey_results.txt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3d3af49c4535>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Run the notebook \"data_log_to_pre_post_surveys_connector\" to create this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpre_survey_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pre_survey_results.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpre_survey_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_survey_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpre_survey_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpre_survey_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File pre_survey_results.txt does not exist"
     ]
    }
   ],
   "source": [
    "## Run the notebook \"data_log_to_pre_post_surveys_connector\" to create this file\n",
    "pre_survey_df = pd.read_csv('pre_survey_results.txt', sep='\\t')\n",
    "pre_survey_df.index = pre_survey_df['sid']\n",
    "pre_survey_df.drop(['Unnamed: 0','sid'],inplace=True,axis=1)\n",
    "pre_survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Run the notebook \"data_log_to_pre_post_surveys_connector\" to create this file\n",
    "post_survey_df = pd.read_csv('post_survey_results.txt', sep='\\t')\n",
    "post_survey_df = post_survey_df[['age','english.0-writing','english.1-reading','gender-Gender non conforming/non-binary','gender-Man','gender-Prefer not to answer','gender-Woman','major','year-1st year undergraduate','year-2nd year undergraduate','year-3rd year undergraduate','year-4th year undergraduate','sim','sim_index','sid']]\n",
    "post_survey_df.index = post_survey_df['sid']\n",
    "post_survey_df.fillna(0,inplace=True)\n",
    "post_survey_df = post_survey_df[post_survey_df['sim_index']==2]\n",
    "post_survey_df.drop(['sid'],axis=1,inplace=True)\n",
    "post_survey_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([pre_b,pre_c,post_survey_df,pre_survey_df],axis=1)\n",
    "data.rename(columns={\"sim\": \"second sim\"},inplace=True)\n",
    "data.drop('sim_index',axis=1,inplace=True)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.sort_values('sid').head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "export_data = data.copy()\n",
    "export_data.to_csv('dataframe_all_incoming_factors_by_student.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Convert lickert scale and other values from strings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "value_converter2 = {\n",
    "    'Prefer not to answer':0,\n",
    "    '20-22':21,\n",
    "    '18-19':19,\n",
    "    '17 and under':17,\n",
    "    'Fluent':3,\n",
    "    'Average':2,\n",
    "    'Beginner':1,\n",
    "    'Absorbance':2,\n",
    "    'Capacitance':1,\n",
    "    'Not at all':1,\n",
    "    'Definitely':4,\n",
    "    'Somewhat':2,\n",
    "    'Mostly':3,\n",
    "    'Almost always':4,\n",
    "    'Sometimes':2,\n",
    "    'Almost never':1,\n",
    "    'Often':3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for value,replacement in value_converter2.iteritems():\n",
    "    data = data.replace(value,replacement)\n",
    "data.fillna(0,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    if data[c].dtype not in ['int64','float64']:\n",
    "        print c, data[c].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.drop('major',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "demo_columns = [\"age\",\"english.0-writing\",\"english.1-reading\",\"gender-Gender non conforming/non-binary\",\"gender-Man\",\"gender-Prefer not to answer\",\"gender-Woman\",\"year-1st year undergraduate\",\"year-2nd year undergraduate\",\"year-3rd year undergraduate\",\"year-4th year undergraduate\",\"second sim\",\"[prior_lab] What lab courses are you presently taking or have taken in the past? Check all that apply. [High school level laboratory]\",\"[prior_lab] What lab courses are you presently taking or have taken in the past? Check all that apply. [First year undergraduate physics laboratory]\",\"[prior_lab] What lab courses are you presently taking or have taken in the past? Check all that apply. [First year undergraduate chemistry laboratory]\",\"[prior_lab] What lab courses are you presently taking or have taken in the past? Check all that apply. [Higher level chemistry labs]\",\"similar_L\",\"similar_C\",\"same_L\",\"same_C\",\"prior_number_virtual_labs\"]\n",
    "att_columns = [\"perceivedvalue.0-boring\",\"perceivedvalue.1-productive\",\"perceivedvalue.2-useless\",\"perceivedvalue.3-engaging\",\"taskinterpretation.0-investigate the basic mechanics of the topic at hand\",\"taskinterpretation.1-design my own experiments that can help me understand the topic at hand\",\"taskinterpretation.2-memorize information about the topic at hand\",\"taskinterpretation.3-complete a certain number of  questions\",\"taskinterpretation.4-develop scientific reasoning skills\",\"pocc.0-learning the basic concepts\",\"pocc.1-testing my ideas and theories\",\"pocc.2-answering given questions\",\"pocc.3-memorizing key information\",\"pocc.4-exploring the topic\"]\n",
    "know_columns = ['Concentration','Wavelength','Width','Area','Separation','Battery voltage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Grabbing CVS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "storyline_data = pd.read_csv('dataframe_all_factors_by_student_x_variable.csv')\n",
    "cvs_data = storyline_data[['CVS_levels_3','variable','sid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Analysis of incoming attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "N = len(set(data['sid']))\n",
    "print \"The study includes {0} students.\".format(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are their incoming attitudes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[att_columns].hist(figsize=(12,15),layout=(len(att_columns)/3+1,3),bins=[0,1,2,3,4,5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, many attitude questions are related. Let's investigate how much:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between attitude measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "correlation_matrix = np.zeros((len(att_columns),len(att_columns)))\n",
    "for i,att_i in enumerate(att_columns):\n",
    "    for j,att_j in enumerate(att_columns):\n",
    "        r,p = spearmanr(data[att_i],data[att_j])\n",
    "        correlation_matrix[i,j] = r\n",
    "#         if r>= 0.4 or r<=-0.4:\n",
    "#             print att_i,att_j,r,p\n",
    "\n",
    "np.fill_diagonal(correlation_matrix,0)\n",
    "# correlation_matrix[(correlation_matrix<0.4)&(correlation_matrix>-0.4)] = 0\n",
    "sns.heatmap(correlation_matrix,yticklabels=att_columns,xticklabels=att_columns,annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the POCC type questions are highly correlated between each other (0.3,0.4).\n",
    "All the perveiced value questions are also highly correlated or anti-correlated (0.3,0.4) which is great since they were deisgned that way (\"Do you think the activity will be productive/useless, boring/engaging\"). What is interesting is that if they find it productive they also find it engaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the principle factors of attitudes? (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=10)\n",
    "pca.fit(data[att_columns])\n",
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three components of the PCA exaplined almost 50% of the data. Let's stick to 2 to simplify our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 2\n",
    "pca = decomposition.PCA(n_components=NC)\n",
    "pca.fit(data[att_columns])\n",
    "X = pca.transform(data[att_columns])\n",
    "data['PC1'] = zip(*X)[0]\n",
    "data['PC2'] = zip(*X)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pca.components_.T,yticklabels=att_columns,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looking at items that are part of the PC (by a factor of 0.3 percent). We can interpret the PC this way:\n",
    "\n",
    "**PC 1** - Students think:\n",
    "* the activity will be engaging, productive\n",
    "* the activity is design to develop scientific reasoning skills\n",
    "* they can do a good job of exploring the topic and testing their ideas.\n",
    "\"the engaged explorers\"\n",
    "\n",
    "**PC 2** - Students think:\n",
    "* the activity is not designed to design their own experiments\n",
    "* the activity is design to memorize information and complete a certain number of questions\n",
    "* they can do a good job of memorizing key information\n",
    "\"the robots being tested\"\n",
    "\n",
    "Since the PCs are orthogonal, we have 4 types of students:\n",
    "1. The engaged exploring robots (++)\n",
    "2. The unrobotic engaged explorers (+-)\n",
    "3. The unrobotic not engaged not exploring (--)\n",
    "4. The not engaged not exploring robots (-+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering into two attitudinal groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters = KMeans(n_clusters=2, n_init=10, verbose=0).fit(data[att_columns])\n",
    "data['cluster_2_label'] = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='PC1', y='PC3',data=data,fit_reg=False,hue='cluster_2_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters split PC1 exactly which makes since: kmeans clustering divides by the variables that explain most of the variance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=len(att_columns)/3+1,ncols=3,figsize=(12,15))\n",
    "for ax,col in zip(axes.reshape(-1),att_columns):\n",
    "    sns.distplot(data[data['cluster_2_label']==0][col],ax=ax,bins=[0,1,2,3,4,5],kde=False,label='0',color='red');\n",
    "    sns.distplot(data[data['cluster_2_label']==1][col],ax=ax,bins=[0,1,2,3,4,5],kde=False,label='1',color='blue');\n",
    "#     sns.distplot(data[data['PC2']<0][col],ax=ax,bins=[0,1,2,3,4,5],kde=False,label='0',color='red');\n",
    "#     sns.distplot(data[data['PC2']>=0][col],ax=ax,bins=[0,1,2,3,4,5],kde=False,label='1',color='blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the \"red\" students think:\n",
    "* the activity will be productive, not boring, no useless, and engaging\n",
    "* the activity was design to develop scientific reasoning skills and test their ideas\n",
    "* they can do a good job a exploring the topic at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incoming knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "correlation_matrix = np.zeros((len(know_columns),len(know_columns)))\n",
    "for i,att_i in enumerate(know_columns):\n",
    "    for j,att_j in enumerate(know_columns):\n",
    "        r,p = spearmanr(data[att_i],data[att_j])\n",
    "        correlation_matrix[i,j] = r\n",
    "#         if r>= 0.4 or r<=-0.4:\n",
    "#             print att_i,att_j,r,p\n",
    "\n",
    "np.fill_diagonal(correlation_matrix,0)\n",
    "# correlation_matrix[(correlation_matrix<0.4)&(correlation_matrix>-0.4)] = 0\n",
    "sns.heatmap(correlation_matrix,yticklabels=know_columns,xticklabels=know_columns,annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Area\",'Concentration','Separation','Width']].stack().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['incoming_knowledge_L'] = (data['Concentration']+data['Width']+data['Wavelength'])\n",
    "data['incoming_knowledge_C'] = (data['Area']+data['Separation']+data['Battery voltage'])\n",
    "data['incoming_knowledge_all'] = (data['Area']+data['Separation']+data['Battery voltage']+data['Concentration']+data['Width']+data['Wavelength'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is incoming knowledge related to incoming attitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['incoming_knowledge_L','incoming_knowledge_C','incoming_knowledge_all']\n",
    "fig,axes = plt.subplots(nrows=1,ncols=len(cols),figsize=(15,5))\n",
    "for ax,col in zip(axes.reshape(-1),cols):\n",
    "    sns.distplot(data[data['cluster_2_label']==0][col],ax=ax,bins=range(0,20),kde=False,label='attitude cluster 0',color='red');\n",
    "    sns.distplot(data[data['cluster_2_label']==1][col],ax=ax,bins=range(0,20),kde=False,label='attitude cluster 1',color='blue');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attitudes and CVS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By PC, what is the distribution of CVS levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs_data_with_pc = cvs_data.merge(data[['PC1','PC2','sid']], how='left',on='sid')\n",
    "# cvs_data_with_pc.reset_index(inplace=True)\n",
    "cvs_data_with_pc.sort_values(by='sid').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=2,ncols=2,figsize=(10,8))\n",
    "sns.countplot(data=cvs_data_with_pc[cvs_data_with_pc['PC1']<=0],y='CVS_levels_3',ax=ax[0,0],label='Low PC1',color='blue',alpha=0.7);ax[0,0].set(xlabel='Low PC1');ax[0,0].set(xlim=(0,160));\n",
    "sns.countplot(data=cvs_data_with_pc[cvs_data_with_pc['PC1']>0],y='CVS_levels_3',ax=ax[0,1],label='High PC1',color='blue',alpha=0.7);ax[0,1].set(xlabel='High PC1');ax[0,1].set(xlim=(0,160));\n",
    "sns.countplot(data=cvs_data_with_pc[cvs_data_with_pc['PC2']<=0],y='CVS_levels_3',ax=ax[1,0],label='Low PC2',color='blue',alpha=0.7);ax[1,0].set(xlabel='Low PC2');ax[1,0].set(xlim=(0,160));\n",
    "sns.countplot(data=cvs_data_with_pc[cvs_data_with_pc['PC2']>0],y='CVS_levels_3',ax=ax[1,1],label='High PC2',color='blue',alpha=0.7);ax[1,1].set(xlabel='High PC2');ax[1,1].set(xlim=(0,160));\n",
    "#     ax[N].set(ylabel='')\n",
    "#     ax[N].set(xlabel='')\n",
    "#     ax[N].set(yticklabels = ['','','',''])\n",
    "#     ax[N].set(xlim=(0,180))\n",
    "# ax[0].set(ylabel='main score')\n",
    "# ax[1].set(xlabel='Number of students')\n",
    "# ax[0].set(yticklabels = ['None-all incorrect','Identify','Qualitative','Quantitative']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking out students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want 8 students, 2 for each type:\n",
    "* high attitude (cluster=0, PC1>2), high knowledge (incoming_knowledge_L ==8)\n",
    "* high attitude (cluster=0, PC1>2), low knowledge (incoming_knowledge_L ==3)\n",
    "* low attitude (cluster=1, PC1<-2), low knowledge (incoming_knowledge_L ==3)\n",
    "* low attitude (cluster=1, PC1<-2), high knowledge (incoming_knowledge_L ==8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print 'a',data[(data['cluster_2_label']==0)&(data['incoming_knowledge_L']>=6)]['sid']\n",
    "# print 'b',data[(data['cluster_2_label']==0)&(data['incoming_knowledge_L']==2)]['sid']\n",
    "# print 'c',data[(data['cluster_2_label']==1)&(data['incoming_knowledge_L']==2)]['sid']\n",
    "# print 'd',data[(data['cluster_2_label']==1)&(data['incoming_knowledge_L']>=6)]['sid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'a',data[(data['PC1']>2)&(data['incoming_knowledge_L']>=6)]['sid']\n",
    "print 'b',data[(data['PC1']>2)&(data['incoming_knowledge_L']==2)]['sid']\n",
    "print 'c',data[(data['PC1']<-2)&(data['incoming_knowledge_L']==3)]['sid']\n",
    "print 'd',data[(data['PC1']<-2)&(data['incoming_knowledge_L']>=6)]['sid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sid',\"Concentration\",\"Wavelength\",\"Width\",\"perceivedvalue.0-boring\",\"perceivedvalue.1-productive\",\"taskinterpretation.1-design my own experiments that can help me understand the topic at hand\",\"pocc.4-exploring the topic\"]\n",
    "exploration = data[data['sid'].isin([19989152,10537160,13654167,11929166])][columns]\n",
    "exploration['Fakename'] = ['Saturn','Tatouine','Ursula','Venus']\n",
    "exploration['knowledge'] = ['low','high','low','high']\n",
    "exploration['incoming_attitude'] = ['low','high','high','low']\n",
    "exploration.sort_values('Concentration',inplace=True)\n",
    "exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%aimport utils_timeline_viz\n",
    "matplotlib.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = 25, 15\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "to_plot_beers = ['Pause','','Log axis','Inverse axis','Linear axis','Other axes','Abs vs. TrialNumber','Abs vs. Width','Abs vs. Concentration','','Graph edit axes','Graph add/del','Data Table delete','Record','','Wavelength','Width','Concentration','Detector','Laser toggle','','Absorbance']\n",
    "\n",
    "def save_multipage_viz(students_to_explore):\n",
    "    sim_name = {\"beers\":\"Light absorbance\",'capacitor':'Charge'}\n",
    "    with PdfPages('multipage_timeline_viz_{0}.pdf'.format('_'.join([str(n) for n in students_to_explore['sid']]))) as pdf:\n",
    "        for sim,to_plot in [('beers',to_plot_beers)]:#,('capacitor',to_plot_caps)]:\n",
    "            for i,row in students_to_explore.iterrows():\n",
    "                studentid = row['sid']\n",
    "                name = row['Fakename']\n",
    "                att = row['incoming_attitude']+' attitude'\n",
    "                know = row['incoming_knowledge']+' knowledge'\n",
    "                filename = find_student_log_file(sim,studentid)\n",
    "                date = date = re.search(r'\\d{7,8}_([\\d\\-\\.\\_]+)\\.txt', filename).group(1)\n",
    "                df = prep_parsing_data(filename)\n",
    "                plt.figure(figsize=(20,12))\n",
    "                plt.title(\"{1} \\t {0} \\t {2} \\t {3}\".format(name,sim_name[sim],att,know),fontsize=25)\n",
    "                plot(df,to_plot,family_name_to_code,function_to_use,colors)\n",
    "#                 plt.show()\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "save_multipage_viz(exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
