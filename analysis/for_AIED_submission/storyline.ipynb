{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "This notebook organizes all the results in the \"analysis\" folder within a concrete storyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di\n",
    "\n",
    "# This line will hide code by default when the notebook is converted to HTML\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\applications\\anaconda2\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils_read_parsing\n",
    "from utils_timeline_viz import *\n",
    "from utils_read_parsing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import ranksums\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "pd.set_option(\"display.width\", 100)\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.api import interaction_plot, abline_plot\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = 7, 4\n",
    "pd.set_option('precision',3)\n",
    "np.set_printoptions(precision=3,suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "# Preparing the data\n",
    "We wish to have a table that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  --------  ---  -----  -----  ---  ---------  ---------\n",
      "student  variable  pre  post   index  sim  CVS table  CVS graph\n",
      "s1       v1        1.0  2.333  1      L    Yes        No\n",
      "s1       v2        ...  ...    1      L    Yes        Yes\n",
      "s1       v3        ...  ...    2      C    No         No\n",
      "s1       v4        ...  ...    2      C    Yes        No\n",
      "-------  --------  ---  -----  -----  ---  ---------  ---------\n"
     ]
    }
   ],
   "source": [
    "t = [['student','variable','pre','post','index','sim','CVS table','CVS graph']]\n",
    "t.append(['s1','v1','1.0','2.333','1','L','Yes','No'])\n",
    "t.append(['s1','v2','...','...','1','L','Yes','Yes'])\n",
    "t.append(['s1','v3','...','...','2','C','No','No'])\n",
    "t.append(['s1','v4','...','...','2','C','Yes','No'])\n",
    "print tabulate(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "source": [
    "## Grabing the CVS data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "table_cvs_df = pd.read_csv('table_cvs_results.txt', sep='\\t')\n",
    "graph_cvs_df = pd.read_csv('graph_cvs_results.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "metadf = get_student_metadata()\n",
    "order = dict(zip(metadf.index,metadf['activity order']))\n",
    "graph_cvs_df['activity order'] = graph_cvs_df.studentid.apply(lambda sid: order[sid])\n",
    "table_cvs_df['activity order'] = table_cvs_df.studentid.apply(lambda sid: order[sid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "variables = [\"Area\",\"Separation\",\"Width\",\"Concentration\",\"Wavelength\",\"Battery voltage\"]\n",
    "\n",
    "def binarize(threshold,number):\n",
    "    if number>= threshold : return 1\n",
    "    else: return 0\n",
    "    \n",
    "# Given that we want to compare the stringency of CVS, we created different definitions with 2,3,4 points needed\n",
    "\n",
    "graph_cvs_2_df = graph_cvs_df.copy()\n",
    "graph_cvs_3_df = graph_cvs_df.copy()\n",
    "graph_cvs_4_df = graph_cvs_df.copy()\n",
    "graph_cvs_5_df = graph_cvs_df.copy()\n",
    "for v in variables:\n",
    "    graph_cvs_2_df[v] = graph_cvs_df.apply(lambda row: binarize(2,row[v]), axis=1)\n",
    "    graph_cvs_3_df[v] = graph_cvs_df.apply(lambda row: binarize(3,row[v]), axis=1)\n",
    "    graph_cvs_4_df[v] = graph_cvs_df.apply(lambda row: binarize(4,row[v]), axis=1)\n",
    "    graph_cvs_5_df[v] = graph_cvs_df.apply(lambda row: binarize(5,row[v]), axis=1)\n",
    "\n",
    "table_cvs_2_df = table_cvs_df.copy()\n",
    "table_cvs_3_df = table_cvs_df.copy()\n",
    "table_cvs_4_df = table_cvs_df.copy()\n",
    "table_cvs_5_df = table_cvs_df.copy()\n",
    "for v in variables:\n",
    "    table_cvs_2_df[v] = table_cvs_df.apply(lambda row: binarize(2,row[v]), axis=1)\n",
    "    table_cvs_3_df[v] = table_cvs_df.apply(lambda row: binarize(3,row[v]), axis=1)\n",
    "    table_cvs_4_df[v] = table_cvs_df.apply(lambda row: binarize(4,row[v]), axis=1)\n",
    "    table_cvs_5_df[v] = table_cvs_df.apply(lambda row: binarize(5,row[v]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# table_intervals_df = pd.read_csv('table_intervals_results.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Grabbing the worksheet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%reload_ext utils_read_parsing\n",
    "#grab worksheet data\n",
    "worksheets = get_worksheet_metadata('beers')\n",
    "pre = get_pre_worksheet(sim='beers')\n",
    "main = get_main_worksheet(sim='beers')\n",
    "\n",
    "ids = get_students_to_analyze_log_worksheets('beers')\n",
    "pre= pre[pre['Student ID'].isin(worksheets[(worksheets['Type']=='p')&worksheets['Student ID'].isin(ids)]['other id'].values)]\n",
    "main= main[main['Student ID'].isin(worksheets[(worksheets['Type']=='m')&worksheets['Student ID'].isin(ids)]['other id'].values)]\n",
    "\n",
    "#ids in pre/post match \"other id\" in worksheet metdata so we need to assign the correct id in logs for each entry in pre/post\n",
    "pre['sid'] = pre['Student ID'].apply(lambda row: worksheets.loc[worksheets[(worksheets['other id']==row)].index[0],'Student ID'])\n",
    "main['sid'] = main['Student ID'].apply(lambda row: worksheets.loc[worksheets[worksheets['other id']==row].index[0],'Student ID'])\n",
    "\n",
    "# print len(ids),len(pre),len(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "## make desired table for beers\n",
    "melted_pre = pd.melt(pre, id_vars=['sid'], value_vars=['Concentration','Width'], var_name='variable',value_name='pre')\n",
    "melted_main = pd.melt(main, id_vars=['sid'], value_vars=['Concentration','Width'], var_name='variable',value_name='main')\n",
    "\n",
    "L_scores = melted_pre.merge(melted_main, on=['sid','variable'], how='outer')\n",
    "L_scores['sim'] = 'L'\n",
    "\n",
    "L_scores['CVS_table_2'] = L_scores.apply(lambda row: table_cvs_2_df.loc[table_cvs_2_df[table_cvs_2_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "L_scores['CVS_graph_2'] = L_scores.apply(lambda row: graph_cvs_2_df.loc[graph_cvs_2_df[graph_cvs_2_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "L_scores['CVS_table_3'] = L_scores.apply(lambda row: table_cvs_3_df.loc[table_cvs_3_df[table_cvs_3_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "L_scores['CVS_graph_3'] = L_scores.apply(lambda row: graph_cvs_3_df.loc[graph_cvs_3_df[graph_cvs_3_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "L_scores['CVS_table_4'] = L_scores.apply(lambda row: table_cvs_4_df.loc[table_cvs_4_df[table_cvs_4_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "L_scores['CVS_graph_4'] = L_scores.apply(lambda row: graph_cvs_4_df.loc[graph_cvs_4_df[graph_cvs_4_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "L_scores['CVS_table_5'] = L_scores.apply(lambda row: table_cvs_5_df.loc[table_cvs_5_df[table_cvs_5_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "L_scores['CVS_graph_5'] = L_scores.apply(lambda row: graph_cvs_5_df.loc[graph_cvs_5_df[graph_cvs_5_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "\n",
    "L_scores['number_points_table'] = L_scores.apply(lambda row: table_cvs_df.loc[table_cvs_df[table_cvs_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "L_scores['number_points_graph'] = L_scores.apply(lambda row: graph_cvs_df.loc[graph_cvs_df[graph_cvs_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "L_scores['sim_index'] = L_scores.apply(lambda row: table_cvs_2_df.loc[table_cvs_2_df[table_cvs_2_df['studentid']==row['sid']].index[0],'activity order'].index(row['sim'])+1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# L_scores[L_scores['variable']=='Width'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%reload_ext utils_read_parsing\n",
    "#grab worksheet data\n",
    "worksheets = get_worksheet_metadata('caps')\n",
    "pre = get_pre_worksheet(sim='caps')\n",
    "main = get_main_worksheet(sim='caps')\n",
    "\n",
    "ids = get_students_to_analyze_log_worksheets('caps')\n",
    "pre= pre[pre['Student ID'].isin(worksheets[(worksheets['Type']=='p')&worksheets['Student ID'].isin(ids)]['other id'].values)]\n",
    "main= main[main['Student ID'].isin(worksheets[(worksheets['Type']=='m')&worksheets['Student ID'].isin(ids)]['other id'].values)]\n",
    "\n",
    "#ids in pre/post match \"other id\" in worksheet metdata so we need to assign the correct id in logs for each entry in pre/post\n",
    "pre['sid'] = pre['Student ID'].apply(lambda row: worksheets.loc[worksheets[(worksheets['other id']==row)].index[0],'Student ID'])\n",
    "main['sid'] = main['Student ID'].apply(lambda row: worksheets.loc[worksheets[worksheets['other id']==row].index[0],'Student ID'])\n",
    "\n",
    "# print len(ids),len(pre),len(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "## make desired table for caps\n",
    "melted_pre = pd.melt(pre, id_vars=['sid'], value_vars=['Area','Separation'], var_name='variable',value_name='pre')\n",
    "melted_main = pd.melt(main, id_vars=['sid'], value_vars=['Area','Separation'], var_name='variable',value_name='main')\n",
    "\n",
    "C_scores = melted_pre.merge(melted_main, on=['sid','variable'], how='outer')\n",
    "C_scores['sim'] = 'C'\n",
    "C_scores['CVS_table_2'] = C_scores.apply(lambda row: table_cvs_2_df.loc[table_cvs_2_df[table_cvs_2_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "C_scores['CVS_graph_2'] = C_scores.apply(lambda row: graph_cvs_2_df.loc[graph_cvs_2_df[graph_cvs_2_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "C_scores['CVS_table_3'] = C_scores.apply(lambda row: table_cvs_3_df.loc[table_cvs_3_df[table_cvs_3_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "C_scores['CVS_graph_3'] = C_scores.apply(lambda row: graph_cvs_3_df.loc[graph_cvs_3_df[graph_cvs_3_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "C_scores['CVS_table_4'] = C_scores.apply(lambda row: table_cvs_4_df.loc[table_cvs_4_df[table_cvs_4_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "C_scores['CVS_graph_4'] = C_scores.apply(lambda row: graph_cvs_4_df.loc[graph_cvs_4_df[graph_cvs_4_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "C_scores['CVS_table_5'] = C_scores.apply(lambda row: table_cvs_5_df.loc[table_cvs_5_df[table_cvs_5_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "C_scores['CVS_graph_5'] = C_scores.apply(lambda row: graph_cvs_5_df.loc[graph_cvs_5_df[graph_cvs_5_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "C_scores['number_points_table'] = C_scores.apply(lambda row: table_cvs_df.loc[table_cvs_df[table_cvs_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "C_scores['number_points_graph'] = C_scores.apply(lambda row: graph_cvs_df.loc[graph_cvs_df[graph_cvs_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "\n",
    "C_scores['sim_index'] = C_scores.apply(lambda row: table_cvs_2_df.loc[table_cvs_2_df[table_cvs_2_df['studentid']==row['sid']].index[0],'activity order'].index(row['sim'])+1,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([L_scores,C_scores])\n",
    "# data['intervals_in_table'] = data.apply(lambda row: table_intervals_df.loc[table_intervals_df[table_intervals_df['studentid']==row['sid']].index[0],row['variable']],axis=1)\n",
    "# data['CVS_table_only'] = data.apply(lambda row: row['CVS_table']*(1-row['CVS_graph']), axis = 1)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding wrapper use data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use_table</th>\n",
       "      <th>use_graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>592.0</td>\n",
       "      <td>592.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       use_table  use_graph\n",
       "count      592.0    592.000\n",
       "mean         1.0      0.845\n",
       "std          0.0      0.363\n",
       "min          1.0      0.000\n",
       "25%          1.0      1.000\n",
       "50%          1.0      1.000\n",
       "75%          1.0      1.000\n",
       "max          1.0      1.000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_wrapper_df = pd.read_csv('use_wrapper_results.txt', sep='\\t')\n",
    "data['use_table'] = data.apply(lambda row: use_wrapper_df.loc[use_wrapper_df[use_wrapper_df['studentid']==row['sid']].index[0],'use_table'], axis=1)\n",
    "data['use_graph'] = data.apply(lambda row: use_wrapper_df.loc[use_wrapper_df[use_wrapper_df['studentid']==row['sid']].index[0],'use_graph'], axis=1)\n",
    "data[['use_table','use_graph']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone uses the table once and 85% use the graph once. Lets redo the analysis only with students who used the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding pre-survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sid</th>\n",
       "      <th>level_experience_sims</th>\n",
       "      <th>similar_L</th>\n",
       "      <th>similar_C</th>\n",
       "      <th>experience_undergrad_labs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>77047160</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>23836160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>64006159</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>24566161</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>46792161</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       sid  level_experience_sims  similar_L  similar_C  experience_undergrad_labs\n",
       "0           5  77047160                      2          0          0                          1\n",
       "1           6  23836160                      0          0          0                          1\n",
       "2           7  64006159                      1          0          0                          1\n",
       "3           8  24566161                      3          0          1                          1\n",
       "4           9  46792161                      2          1          0                          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_survey_df = pd.read_csv('pre_survey_results.txt', sep='\\t')\n",
    "pre_survey_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['level_experience_sims'] = data.apply(lambda row: pre_survey_df.loc[pre_survey_df[pre_survey_df['sid']==row['sid']].index[0],'level_experience_sims'], axis=1)\n",
    "data['experience_undergrad_labs'] = data.apply(lambda row: pre_survey_df.loc[pre_survey_df[pre_survey_df['sid']==row['sid']].index[0],'experience_undergrad_labs'], axis=1)\n",
    "data['used_similar_sim_L'] = data[data['sim']=='L'].apply(lambda row: pre_survey_df.loc[pre_survey_df[pre_survey_df['sid']==row['sid']].index[0],'similar_L'],axis=1)\n",
    "data['used_similar_sim_L'].fillna(0, inplace=True)\n",
    "data['used_similar_sim_C'] = data[data['sim']=='C'].apply(lambda row: pre_survey_df.loc[pre_survey_df[pre_survey_df['sid']==row['sid']].index[0],'similar_C'],axis=1)\n",
    "data['used_similar_sim_C'].fillna(0, inplace=True)\n",
    "data['used_similar_sim'] = data['used_similar_sim_L'] + data['used_similar_sim_C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a \"CVS_levels\" column to our data (graph=2, table=1, none=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 27)\n",
      "(0, 27)\n",
      "(1, 27)\n",
      "(0, 27)\n"
     ]
    }
   ],
   "source": [
    "data['CVS_levels_2']=0\n",
    "data['CVS_levels_3']=0\n",
    "data['CVS_levels_4']=0\n",
    "data['CVS_levels_5']=0\n",
    "# data['CVS_table_only'] = data.apply(lambda row: row['CVS_table']*(1-row['CVS_graph']), axis = 1)\n",
    "data['CVS_levels_2']=data['CVS_table_2']+data['CVS_graph_2']\n",
    "data['CVS_levels_3']=data['CVS_table_3']+data['CVS_graph_3']\n",
    "data['CVS_levels_4']=data['CVS_table_4']+data['CVS_graph_4']\n",
    "data['CVS_levels_5']=data['CVS_table_5']+data['CVS_graph_5']\n",
    "print data[(data['CVS_table_2']==0)&(data['CVS_graph_2']==1)].shape\n",
    "print data[(data['CVS_table_3']==0)&(data['CVS_graph_3']==1)].shape\n",
    "print data[(data['CVS_table_4']==0)&(data['CVS_graph_4']==1)].shape\n",
    "print data[(data['CVS_table_5']==0)&(data['CVS_graph_5']==1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>variable</th>\n",
       "      <th>pre</th>\n",
       "      <th>main</th>\n",
       "      <th>sim</th>\n",
       "      <th>CVS_table_2</th>\n",
       "      <th>CVS_graph_2</th>\n",
       "      <th>CVS_table_3</th>\n",
       "      <th>CVS_graph_3</th>\n",
       "      <th>CVS_table_4</th>\n",
       "      <th>...</th>\n",
       "      <th>use_graph</th>\n",
       "      <th>level_experience_sims</th>\n",
       "      <th>experience_undergrad_labs</th>\n",
       "      <th>used_similar_sim_L</th>\n",
       "      <th>used_similar_sim_C</th>\n",
       "      <th>used_similar_sim</th>\n",
       "      <th>CVS_levels_2</th>\n",
       "      <th>CVS_levels_3</th>\n",
       "      <th>CVS_levels_4</th>\n",
       "      <th>CVS_levels_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10127163</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>10127163</td>\n",
       "      <td>Width</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>10127163</td>\n",
       "      <td>Area</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>10127163</td>\n",
       "      <td>Separation</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>10192168</td>\n",
       "      <td>Separation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10192168</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10192168</td>\n",
       "      <td>Area</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>10192168</td>\n",
       "      <td>Width</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10232160</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>10232160</td>\n",
       "      <td>Width</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>10232160</td>\n",
       "      <td>Separation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>10232160</td>\n",
       "      <td>Area</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sid       variable  pre  main sim  CVS_table_2  CVS_graph_2  CVS_table_3  CVS_graph_3  \\\n",
       "0    10127163  Concentration  1.0   3.0   L            1            1            1            1   \n",
       "148  10127163          Width  1.0   3.0   L            1            1            1            1   \n",
       "296  10127163           Area  3.0   3.0   C            1            1            1            1   \n",
       "444  10127163     Separation  3.0   3.0   C            1            1            1            1   \n",
       "538  10192168     Separation  1.0   2.0   C            1            1            1            1   \n",
       "96   10192168  Concentration  1.0   3.0   L            1            1            1            1   \n",
       "390  10192168           Area  1.0   2.0   C            1            0            0            0   \n",
       "244  10192168          Width  1.0   0.0   L            1            0            1            0   \n",
       "1    10232160  Concentration  1.0   1.0   L            1            1            1            1   \n",
       "149  10232160          Width  1.0   1.0   L            0            0            0            0   \n",
       "445  10232160     Separation  1.0   3.0   C            1            1            1            1   \n",
       "297  10232160           Area  1.0   3.0   C            1            1            1            1   \n",
       "\n",
       "     CVS_table_4      ...       use_graph  level_experience_sims  experience_undergrad_labs  \\\n",
       "0              1      ...               1                      1                          1   \n",
       "148            1      ...               1                      1                          1   \n",
       "296            1      ...               1                      1                          1   \n",
       "444            1      ...               1                      1                          1   \n",
       "538            1      ...               1                      1                          1   \n",
       "96             1      ...               1                      1                          1   \n",
       "390            0      ...               1                      1                          1   \n",
       "244            1      ...               1                      1                          1   \n",
       "1              1      ...               1                      1                          1   \n",
       "149            0      ...               1                      1                          1   \n",
       "445            1      ...               1                      1                          1   \n",
       "297            1      ...               1                      1                          1   \n",
       "\n",
       "     used_similar_sim_L  used_similar_sim_C  used_similar_sim  CVS_levels_2  CVS_levels_3  \\\n",
       "0                   0.0                 0.0               0.0             2             2   \n",
       "148                 0.0                 0.0               0.0             2             2   \n",
       "296                 0.0                 0.0               0.0             2             2   \n",
       "444                 0.0                 0.0               0.0             2             2   \n",
       "538                 0.0                 0.0               0.0             2             2   \n",
       "96                  0.0                 0.0               0.0             2             2   \n",
       "390                 0.0                 0.0               0.0             1             0   \n",
       "244                 0.0                 0.0               0.0             1             1   \n",
       "1                   1.0                 0.0               1.0             2             2   \n",
       "149                 1.0                 0.0               1.0             0             0   \n",
       "445                 0.0                 0.0               0.0             2             2   \n",
       "297                 0.0                 0.0               0.0             2             2   \n",
       "\n",
       "     CVS_levels_4  CVS_levels_5  \n",
       "0               2             2  \n",
       "148             2             2  \n",
       "296             2             2  \n",
       "444             2             2  \n",
       "538             2             0  \n",
       "96              2             2  \n",
       "390             0             0  \n",
       "244             1             1  \n",
       "1               2             0  \n",
       "149             0             0  \n",
       "445             2             1  \n",
       "297             2             2  \n",
       "\n",
       "[12 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values('sid').head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000000000EAF52E8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F262EB8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F2EC9E8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F3E24A8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F52F208>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000000000F3F1A90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F6E8278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F7A0E10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F89CF98>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000F9A9AC8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000000000FA1C2B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000FB27E48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000FC1F4A8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000FCF4128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000FD9AA58>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000000000FEA87B8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000000FDB65F8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010473828>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000000001053E400>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010636588>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000000107120B8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000000107B8860>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000000108C8438>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010953278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000010A04DD8>]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAEICAYAAAAX0F61AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdUFdfahx/KkS4EC4gItoCCAVs0dkEC9hoVey/RGHu9\ndlGxJCYWbFjwYkgiKioGNFyvRkyM3RjRIArYC4pIEzic/f3Bx1yOYEQFJbqftViLM7vMu3+zZ949\n794zoyOEEEgkEolEIik2dN+2ARKJRCKRvOtIZyuRSCQSSTEjna1EIpFIJMWMdLYSiUQikRQz0tlK\nJBKJRFLMSGcrkUgkEkkxU6KcbUpKCitWrMDLywsXFxfc3d1ZsmQJycnJBAcH4+TkxMOHDwssO2LE\nCMaMGQOAWq1mw4YNeHl5UatWLRo1asSECROIj49/k815aaZNm8aXX375WnUEBwfj5eWFs7MztWrV\nolatWlLHV2DTpk20bNkSJycnXFxcpI6vQUpKCj4+PtSsWRNnZ2ep4yswZMgQHB0dtf4aNGjw1nQs\nqr7xIn7//XccHR1JTU197bqSkpKYOXMmTZs2pUGDBnzxxRfcuXOnCKwsHCXG2SYnJ9OzZ0+OHz/O\nzJkz2b9/P3PnzuXo0aMMGTKE1q1bo6+vz4EDB/KVffz4MceOHaNTp04AfP311wQHBzNjxgzCw8NZ\nv349qamp9OnThydPnrzppr0xIiIimDt3LmlpaXz44Yd06dKF7OxsBgwYIHV8CXbs2MGaNWsAcHBw\noFmzZqhUKiZPnix1fElyz+u9e/ei0WgYP368PK9fgb/++ovy5cvj7OzMV199xY8//siiRYukji/B\n9OnTiYqKYs2aNfz73/8mPT2dzz//nOzs7Dey/xLjbJcvX44Qgq1bt9KsWTMqVapE8+bN2bBhA1FR\nUYSGhtKqVSvCwsLylT1w4ACmpqa0aNECgJ07dzJ69GhatGiBra0tLi4ufPPNN6SmphIREfGmm/bG\nCA4Oxs7ODjMzM4KCgliwYAGffPIJN2/elDq+BKmpqdSsWRNjY2OCgoJYsmQJaWlpWFhYSB1fkuXL\nl/PkyRPKly+PmZkZlpaW8rx+SVJSUnjw4AEGBgZs376d9u3b4+rqioeHh9SxkDx69Ij//Oc/zJ49\nG1dXVxwdHVm0aBGXLl0iOjr6jdig/0b28gIyMzPZt28fkyZNwsjISCvNxsaGgIAAqlWrhpWVFaNG\njSIhIYGyZcsqeUJDQ2nXrh0qlQoAHR0djh8/Trt27dDXz2mikZERISEhWFpaFtquwMBA/P39efz4\nMZ9++ikajYbKlSszZswYpk2bhlqtJj4+nvj4eL755hscHBxYvHgxx44dIyUlBWtra0aOHMlnn30G\nQL9+/ahbty5//vknJ0+exN7enilTptCsWTNln+np6cqIs1SpUnh7ezNu3LhC2Tts2DCGDh3K5MmT\nFR11dHRITk6WOr6Ejr1792blypVMmjQJIQT+/v5YWFhQs2ZNLCwspI6F1DEzM5O9e/eio6PD2rVr\nGTJkiJIm+2Phdbx06RIAAwYMKFHXx7wcOXKEr7/+mtjYWCpVqsTgwYPp1q0bqampNG7cmK+//ppW\nrVop+Tt06ECHDh0YPnw4sbGx+Pj4cOrUKSwtLWnTpg3jxo2jVKlS+fbzww8/4O/vz507d7C1tWXk\nyJF07tz5hfYZGhqyYcMGnJyc8qW9sbt5UQKIiYkRDg4O4sKFC3+bLysrS3zyySciMDBQ2Xb37l1R\no0YNcf78eWXb+vXrhYODg2jcuLGYOnWq2LVrl3jw4MFL2RQaGipcXFzE7t27RUxMjJg2bZpwdHQU\nK1euFEIIMXXqVOHo6Ch2794toqKiRFpamhg0aJAYOHCguHTpkoiLixMLFy4Uzs7Oyr779u0rnJ2d\nxapVq0RMTIxYtmyZcHZ2FteuXVPqdHBwEF9//bW4fv26+PHHH4WDg4OIjIx8JR0vXbokatasKUJC\nQqSOr6DjunXrhKOjo6hRo4bYs2dPvnxSx8LpOHXqVCGEEA0aNBA7d+6UOr6kjmvWrBEODg5i8ODB\nokmTJqJjx45i165db1XHqVOnijFjxgghhIiOjhYuLi7i+++/F/Hx8WL//v3i448/FqGhoUIIIcaN\nGycmTpyolL1y5YpwdHQUt27dEk+fPhVubm5i/vz54urVq+LEiROiffv2YtasWUIIIY4fPy4cHBxE\nSkqKuHjxoqhRo4YICwsTN2/eFNu3bxeOjo4iNjb2pWzPxdfXV9SrV0+kpqa+UvmXpUQ429OnTwsH\nBwcRFxf3wrwLFiwQffr0UX5v2bJFtG7dOl++8PBwMWDAAOHs7CwcHBxEzZo1xfz584VarS6UTT17\n9hSLFi1SfmdmZormzZtrnZTP7jcgIEBcv35d+f3o0SPh4OAgTp48KYTIOSn79++vVaZjx45i6dKl\nSp3t27fXSvfw8BAbNmwolM15dbx3757w8PAQvXr1KrDNUsfnk6vjqVOnRFRUlFi5cqVwcnISv/32\nW768Usfns3LlSuHg4CCuXLkihHi+sxVC6vh3jB8/Xhn8Xbp0SWzevFk4Ozsrziwvb0rHvM52ypQp\nYubMmVrpa9euFV27dhVCCBERESHq1KkjMjIyhBBCfPvtt6JXr15CCCGCg4OFp6enVtnTp0+LGjVq\niOTkZC1ne/DgQVGzZk1x7tw5JW9kZKRISkoqlM15CQ0NFTVq1BDff//9S5d9VUpEGPmDDz4AclaL\nvYiOHTuyfft27t+/T/ny5QkNDVUm/vPi5eWFl5cXqampnDhxgpCQEAIDA7GysmL48OEv3M9ff/1F\n3759ld8qlYpatWpp5alUqZLW7969exMeHs7WrVuJi4sjKioKQGsCvn79+lplXFxcuHLlivLbzs5O\nK93MzIyMjIwX2gv/0zE6Opply5ahUqlYvXo1enp6+fJKHZ9Pro4qlYqaNWtSs2ZN/vjjD7777js+\n+eQTrbxSx4JJSEggMDAQgLS0tBfmlzo+n9GjR7N//34aNWpEjRo1qFGjBjdu3ODf//437dq108r7\npnTMy5UrV4iOjiY0NFTZplarlRB18+bNUalU/PLLL3h4eBAWFka/fv0AiImJ4caNG9SpU0cpK4RA\no9EQFxentZ9mzZrh4uJCjx49qFq1Ki1btqRLly6ULl36pezdtWsXM2fOZNCgQfTs2fOlyr4OJWKB\nlJ2dHRYWFly4cKHA9MWLF7N161YgpxPb29tz4MABrl+/zsWLF+nYsaOS9/LlyyxYsED5bWJigpub\nG99++y1t27bl6NGjhbJJX18fjUbzt3kMDQ2V/zUaDUOHDmX16tVYWFjQs2dPtm/fnq/Ms44vOzsb\nXV3d56ZDTucrDLmLo6ZNm4aRkRGBgYFaczBSx8LpeOvWLczMzLT644cffkhiYiIgdSyMjkePHuXx\n48dAjrOqU6cOjx8/Zs6cOQwdOhSQOha2P1auXDnf9bFatWrcv38feDs65iU7O5t+/foREhKi/IWG\nhhISEgLkDGi8vLwICwvj8uXLXL9+ndatWwM5Trl27dpaZffs2cPBgwepXr261n4MDQ0JCgoiKCgI\nT09PIiMj6datG8eOHSu0rVu2bGH69OkMHTqUKVOmvHRbX4cS4Wz19PRo3749//73v3n69KlWWnx8\nPEFBQcrkPuSM3iIiIggPD+fjjz/GxsZGSdNoNAQGBnLixIl8+zE1NVXuWl7Ehx9+yMWLF5Xf2dnZ\nykKFgoiKiuK3335j48aNjBkzBk9PT1JSUgDtkypvnUIILly4QI0aNQpl04t48OABWVlZZGVlsWHD\nBi1HK3UsPH5+flhZWWn1xwsXLlC9enWpYyH59NNPOXjwIJ06dcLKyooffvgBc3NzvvzySxYuXCh1\nfAnGjh1LmTJltPrjxYsXqVq16lvTMS/VqlUjPj4ee3t75e+3335TIhuQsyDql19+ISwsjCZNmijX\nptyy1tbWStnExESWLl1KVlaW1n7Onj3LqlWrqFu3LuPHj2ffvn04Oztz8ODBQtkZHByMr68vY8eO\nZcKECS/dztelRDhbyAmVZGdnM3DgQI4dO8aNGzc4ePAgQ4YMwdnZme7duyt5O3bsyOnTp9m7d2++\nlWhOTk54enoyduxYduzYwfXr17l06RKbNm1i3759DBo0qFD2DBw4kB9++IG9e/dy7do1FixYwK1b\nt9DR0Skwf7ly5dDT02P//v3cunWLY8eOMXXqVCBnVWYuhw4dIjAwkNjYWJYuXcrNmzfp0aPHy8pV\nID4+PhgYGGBpacmoUaP46aefOH/+PCEhIVLHl6Bfv37ExsaSlJSEt7c3EyZM4Pz58zg4OEgdC4mp\nqSn29vZMmzYNXV1dZs+ejVqtRkdHh/Pnz0sdXwIPDw/i4uJISkqiV69ezJ07lz179lCvXr23pmNe\nBg8ezOHDh1m3bh3x8fGEhYWxZMkSrKyslDz169fHxMSEbdu20b59ey1bdXV1mTp1KtHR0Zw5c4bp\n06eTlZWFmZmZ1n6MjIxYv34927Zt4+bNm0RGRnL16lVcXFxeaOODBw/w8fGhffv2dO/enQcPHih/\neY9jcVIi5mwBLC0tCQoKws/Pj1mzZpGQkICVlRWtW7dm5MiRWsvAbW1tcXV15eLFi3h5eeWr66uv\nvsLf35+tW7fi4+ODrq4urq6u+Pv7a80N/B2enp7cuHGDpUuXkpKSQps2bahTp47WCDIvVlZWzJ8/\nHz8/P/z8/KhYsSK9e/dmx44dXLx4kebNmwPQrl07IiIiWLp0KY6OjmzevFlr5PmqZGZm8p///AeN\nRkNSUhJ37txh/PjxQE4n7du3r9SxkLRp04bU1FTWrVvHX3/9RUxMDACbN2+W/fElyXtenz9/nhUr\nVmBjYyN1fAk6d+5Meno6mzZt4vLly0RHR6Ojo8OuXbvemo55qVWrFitXrmTlypWsXr2acuXKMXLk\nSK1HvXR0dGjXrh3bt2/Hw8ND2W5sbMzmzZtZvHgx3bt3x8jICDc3N6ZPn55vPzVq1GDZsmX4+fmx\nbNkyLC0tGTRoEN26dXuhjYcPHyY9PZ3Q0FCtuWWAdevW4ebm9tLtfmne2FKsfxjHjx8XN27c0NrW\ntm1bsXv37leus2/fvsLX1/d1TftHIXUsGqSORYPUUfK2KDF3tm+SpKSkvw0dGBoacujQIY4fP46P\njw8WFhbs3buXe/fuaT2o/iYpjM3Phl2KG6lj0SB1LBqkjkVDSbTp79BoNM99J3Qu5ubmBb4k403y\nXjrbCRMmEBkZ+dz0tm3b4uPjw5MnTxg2bBjp6ek4OTmxadMmypQp8wYt/R+FsXnFihVv0CKpY1Eh\ndSwapI5FQ0m06e94+PAhTZs2/ds8GzduVEL+bwsdIQq5/lwikUgkEskrUWJWI0skEolE8q4ina1E\nIpFIJMXMP3rO9vbt20DOly9y/39XydvGonw0A6SORYXUsWi4ffv2e6EhFJ+O71NfhP+1s6j7YlHy\nj3a2udxoVz/fNr2Ne9+CJf9spI5Fg9Tx9SlIQ5A6vu9kD+tYcML+U2/WkFfgnXC27xL/5M4kkUgk\nkoKRzlYikUjeMNnZ2QQFBZGSkkJaWhqenp5kZGTg6+tLhQoVgJy3XTVu3JiIiAgiIiLQ09Oja9eu\n1KtX7y1bL3kVis3ZqtVq1q5dq7wcv1u3bpQpU0Z2JolE8t5z6tQpjI2NmTJlCleuXGHZsmX07NmT\n9u3b06FDByXf48ePCQsLw9fXl6ysLGbNmoWLi8tzXy8pKbkUm7M9evQoZmZmjBkzhpSUFCZPnsxn\nn30mO5NEInnvqV27Nq6urspvPT09rl27xu3btzl16hTW1tYMHDiQmJgYHB0dUalUqFQqrK2tiY+P\nz/f5OUnJp9icbaNGjZQPbQshZGd6RbKBHwzKkTp7tgw3SSTvCAYGBgCkp6ezZcsW2rZti6mpKa1a\ntaJq1ars2rWLHTt2ULlyZYyNjZVyRkZGpKWlvbD+vKtyS/IK3Zflxt+klfR2Fpuzzf0Ac3p6Ol9/\n/TXe3t5kZWUVWWeC/4lb0AEo6cI/j2fbclrfFGOhYer8+TJC8BI8u9BMGbTU+lgOWiQlgsTERFau\nXEmDBg2oV68e5ubmmJiYANCgQQM2b96Mk5OT1je+09PTlTx/x/v26A/wfj/6k5CQwPLly/H09KRp\n06akpqYWWWcC/rYTvSsdzFWdigupANy5cwdARghegbyDFjlHJnnbJCcns3btWkaMGKG8l3nhwoUM\nHjyY6tWrc+HCBapWrUr16tUJCgoiMzMTtVrNrVu3qFSp0lu2XvIqFJuzffz4sdJ5PvroI0B2plfB\ngJxXVxdXuAnejwhB3kGLtbU1pUqVkoMWyVvj559/Jj09nZ07d5KRkQHAgAEDCAgIQE9PDwsLC4YP\nH46xsTFt2rRhzpw5aDQavL293/rXaySvRrE52927d5OSksLOnTvZuXMnAP3795ed6RVI1NFjzbx5\nxRJugvcjQpB30LJ48WK8vLzkoKUQPO/lEuw/9Y9tU0mga9eudO3aNd8bpBYsWJAvr4eHh9YH1yX/\nTIrN2Q4aNIhBgwbl2y4708uRjB4bDCswok8fGW56TeSg5fUpaMHehx9+KOe+JZIXIF9qUcL5TykL\n0tGV4abXRA5aigY59y2RvBrS2ZZwOmc+pDMPqTR3lww3vQZy0FI05J37huJ5PtTGxua5j3i8i6Hr\nd7FNkvxIZyt5L5CDlqLhTSzYex/C8bkU59eTJCUL6WwlEslLUdxz35KiQ349qeQgPx4vkUgKTe7c\nd58+fZQ3xC1cuJCYmBgArbnvS5cukZmZSVpampz7lrz3yDtbiURSaOTct0TyakhnK5FICo2c+341\n5HeqJdLZSiQSiaTIeN7A4n2fJ5ZzthKJRCKRFDPS2UokEolEUsxIZyuRSCQSSTEjna1EIpFIJMWM\ndLYSiUQikRQz0tlKJBKJRFLMSGcrkUgkEkkxI52tRCKRSCTFjHS2EolEIpEUMyXK2aakpLBixQq8\nvLxwcXHB3d2dJUuWkJycTHBwME5OTjx8+LDAsv+6ncbcO+kAZAvBd999R//+/fH09KRLly4sWLCA\nW7duFdoWX19f5syZUyTt+jvOnTuHm5sb6enpr13XgwcPGDt2LPXr18fFxYV69epJHV+DlJQUhg0b\nhqOjo9TxFbh//z6Ojo75/jw8PF5Pz+zs19ZTrVYTEhJS6Pxbt25lxIgRr5z+spw5c4ZevXpRp04d\nWrVqxbp168jOzgYKd51MTEwssN73TccjR47QuXNnXFxcaN26Nbt37y6yul+WEuNsk5OT6dmzJ8eP\nH2fmzJns37+fuXPncvToUYYMGULr1q3R19fnwIED+co+yRacTsvmU7Oct09uepjBTz/9xOjRo9m2\nbRuLFi0iLS2NsWPHkpKS8qab9sYYO3YsCQkJWFhYYGdnh4WFBU2bNpU6vgLJycl069aNyMhIANkf\nX4GYmBhKly5NZGQk4eHhVK5cGWdnZ2bPnv1aem7cuPG19YyIiGDLli1F2t6i4vbt2wwdOpQ6deqw\ne/duZsyYwZYtWwgICCj0dfKXX37JV+/7pmNMTAxffPEF7du3Z//+/YwYMYKZM2fy22+/vRV7Soyz\nXb58OUIItm7dSrNmzahUqRLNmzdnw4YNREVFERoaSqtWrQgLC8tX9peULEx0dWhoktOJwp5kMWDA\nABo2bIi1tTU1a9Zkzpw5pKamKhfPd42UlBQqVKiAtbU1pUqVYseOHQwYMICoqCip4yuwfPly7t27\nR+3atQFkf3wFYmJiqFKlCuXKlWPr1q3o6emxfft2mjdv/np6hoW903qGh4djZWXFlClTqFy5Mq1a\ntWLgwIHs2bOn0NfJw4cP56v3fdPxzp079OzZk6FDh1KpUiW6dOmCg4MDJ06ceCv2lAhnm5mZyb59\n+6hcuTI+Pj7MnTuXu3fvAjlfFAkICKB169Z07NiRU6dOkZCQoFX+vylqWprpo6+jA4AuOpw5c0YJ\nuwAYGhri7+9P06ZNX8nG33//naFDh+Ll5cXAgQOVi0J6ejqtW7fm2LFjWvkHDx5MUFAQADdu3GDK\nlCm0bt0ab29v1q1bR2ZmZoH7CU3KpH98Cm1ikhkUn8rBJ1mFss/U1JTFixfz3//+l8qVKzNt2jTW\nrl2rOAupY+F0BHj69Ck7duxAR0cn3wfPpY6F1zEmJoasrCymTZtGcHAwHTt2xMjISCtPQXo+evRI\nK8+zeurovJ6e586dY8mSJTx58gQ3NzfOnTtHdnY2/v7+eHt74+HhQdeuXVm9erXWPjQaDatWraJt\n27Z069aNwMDA5+4jKiqKL774Ak9PT/r27csPiRlohCiUbh4eHixevFhrv6dOnSI+Pr7QOv7xxx9v\nTcfNDzPoE5eCV0wyn8Wm4PfgKdl52v6mdGzWrBkzZ84EckLmBw8e5Nq1a8p3mN80JcLZ3rhxg9TU\nVMqVK8fChQvp3bs327ZtU9Lr1auHhYUFzZo1w8LCQivUlJCQwIX0bD41UynbPvtARXh4ON27d8fX\n15fw8HAePXpExYoVMTU1fWn7YmNjmTNnDp06dWLz5s3079+ftWvXcujQIYyMjGjcuLHWSDIuLo64\nuDjc3d3JzMxkypQp2NrasmHDBqZPn87JkydZvXp1vv1cuXKFlQ8yGFrGgK32JnSxULHs/lNuZmpe\nSseoqCjCw8PR19fH3Nxc6viSOgYFBZGdnY2Pjw8tW7bMly51LJyO586dIzk5maioKNRqNd999x2x\nsbH58j2r55EjR5S0BLUmn549evR4LT2dnZ0ZPXo0pUuXZufOnTg7OxMUFMTPP//MtGnTCAwMZMSI\nEezevZtff/1VKRcTE8PDhw/x8/Nj1KhRbN++nYiIiHz1JyYmMmXKFD755BO2bNnCmDFj2JOUxQ+P\nCx7QPIudnZ0ySAaIjIzk/PnzNGvWDLVazbVr1wosl1fH0qVLvz0dk7OYYmVIgL0Jw8sYEJKUxW+p\n6jeuYy7379/HxcWFMWPG0KlTJxo2bPhS5YsMUQI4ffq0cHBwEDt37lS2DR8+vMC8CxYsEH369FF+\nb9myRbRu3TpfvvDwcDFgwADh7OwsHBwcRM2aNcX8+fOFWq0ulE1Tp04VY8aMEUIIMWXKFDFz5kyt\n9LVr14quXbsKIYSIiIgQderUERkZGUIIIb799lvRq1cvIYQQwcHBwtPTM197a9SoIZKTk8Xx48eF\ng4ODSElJEQcPHhQ1a9YU586dU/JGRkaKpKSkQtmcq+Pq1avF6dOnRa9evUTt2rUVu/IidXw+LVu2\nFA4ODiIuLk4cOnRIODg4PDev1PH5uLq6Ck9PT7F9+3bh4OAgGjRoIJo0aSIeP3783DJvSs+dO3eK\nBg0aKL9//vln8euvv2rlad++vVi9erUQQoiVK1eKjz/+WKSmpirpixcvFt7e3kp6ly5dhBA5eg8a\nNEirrr1794qGDRsWyra8ZGZminbt2om6deuKn3/+WTg4OIi+ffu+sJzU8X+kpKSIixcvit27d4u6\ndesqtrxpSsT3bD/44AMgJ7yQi66uLtnZ2ejp6Wnl7dixI9u3b+f+/fuUL1+e0NBQOnXqlK9OLy8v\nvLy8SE1N5cSJE4SEhBAYGIiVlRXDhw9/KfuuXLlCdHQ0oaGhyja1Wo2+fo58zZs3R6VS8csvv+Dh\n4UFYWBj9+vUDckZxN27coE6dOkpZIQQajYa4uDit/TRr1gwXFxd69OhB1apVadmyJV26dKF06dKF\nsjNXRysrK+rWrcu3335L06ZNOXr0KK1atdLKK3UsmB07digrcZOSkpTtBfVFkDr+HUOGDKFBgwaU\nL18egCpVqhAXF8eBAwfo0aNHgWXehp6QE7o9ceIEy5YtIzY2lujoaG7cuIGnp6eSx8HBAWNjY+W3\ns7MzwcHB+eqKiYnh999/19JYo9Hw9OlTEhMTlfP0RTx9+pRx48YRHx/PrFmzqFatmlLX8/pjLlLH\n/2FiYoKTkxNOTk48ePAAf39/Ro8e/dJte11KhLO1s7PDyMiIS5cuKduEEEpnWrx4MRUqVGDgwIG4\nuLhgb2/PgQMHaNGiBRcvXmTlypVKucuXL7Njxw5mzZoF5Ajt5uaGm5sb48eP5+jRoy/dibKzs+nX\nrx/e3t4FpqtUKry8vAgLC8PW1pbr16/TunVrIOciWLt2ba05mFysrKw4f/688tvQ0JCgoCDOnj3L\nkSNHOHToEIGBgaxbt44mTZr8rY1JSUlcvHgRQ0NDRcdy5cqhUqkUpyF1fLGOe/fuVfTq3bs3uro5\nMy3169dn3rx5dOzYUepYCB0BSpcuTXZ2trIyPiUlBVtbW+7du6eV723rCbB69WoCAgLo1q0bnp6e\nTJw4kYkTJ2rlye0LuWg0GlQqFc+iVqvx9PRk3Lhx+dLMzMwKZU9KSgojRowgOjqaXr16YWtrq+iY\nlJRUoKOVOmpz+fJlUlJSqF+/vrLNwcGB5OTkFw5WioMSMWerp6dHkyZN2L9/P0+fPiU6Oho7OzsA\n4uPjCQoK0joYHTt2JCIigvDwcD7++GNsbGyUNI1GQ2BgYIErzkxNTQs9GspLtWrViI+Px97eXvn7\n7bfftCb2O3TowC+//EJYWBhNmjTB0tJSq6y1tbVSNjExkaVLl5KVpb3Y5OzZs6xatYq6desyfvx4\n9u3bh7OzMwcPHnyhjUlJSUycOJFatWopOh49epSsrCyqV68udSykjsuXL8fX1xdHR0esrKwYNGgQ\nACEhIbi7u0sdC6njvXv3WLFiBfv27UNPT4+mTZty7949YmNjlTs0eHvnt87/LxLKZdOmTUydOpVp\n06bRuXNnbG1tuX37NiLPYpyYmBjU6v/NPZ47d47q1avnq7tatWrExsZqHZ8rV66watWqfI6mILKz\nsxk1ahRXr15l27ZtuLu7c/bsWS0dnz59qlVG6pif8PBw/vWvf2lFTC9cuECVKlXeuKOFEuJsAebP\nn48QAnd3d5YuXYqnpycHDx5kyJAhODs70717dyVvx44dOX36NHv37qVz585a9Tg5OeHp6cnYsWPZ\nsWMH168fGG00AAAgAElEQVRf59KlS2zatIl9+/YpF8+XYfDgwRw+fJh169YRHx9PWFgYS5YswcrK\nSslTv359TExM2LZtG+3bt9eyVVdXl6lTpxIdHc2ZM2eYPn06WVlZ+UZnRkZGrF+/nm3btnHz5k0i\nIyO5evUqLi4uL7TRzs6OFi1akJiYSFZWFs2bN2fcuHG4urpy9+5dqWMhdbSysqJDhw64u7uTmJjI\n9u3bgZzR+K+//ip1fAkdXVxcOHr0KJ9//jlPnjwhIyODrKwsTE1NuXHjxls9v42NjUlLSyMmJoaM\njAysrKw4cuQI8fHxXLx4kbFjx5KUlKS1SjsxMZEZM2Zw5coVgoODCQ4OZtiwYfnq7tOnD3Fxcfj4\n+HDt2jUiIyOZM2cOZmZmhXIS27dv58SJE/j4+FC2bFmqVKlCZmYmkyZNQkdHB1NTUwYOHMixY8ek\njn9Dt27duH//Pr6+vsTFxRESEsKmTZv44osvCtW2IuetzBQ/hwcPHoh58+YJNzc38dFHHwkPDw+x\nbNkykZycnC9v7969haurq0hJScmXlpGRIdasWSPatm0rXFxcRO3atcWAAQPEyZMnC21L3gUpQuRM\n/Hfo0EE4OzuLli1binXr1gmNRqNVZunSpcLV1VVr8l8IIaKjo8WgQYOEi4uLaNiwoZg2bZqyyCTv\nghQhhNi/f79o166dqFWrlmjevLlYs2ZNoW1OSkoS06dPFw0aNBDOzs6idu3aUsdX0DGXBw8eiGHD\nhgkHBwep4yvo+PDhQzF16lTxySefiNq1a4vBgweLKVOmlIjzOykpSfTo0UM4OzuL8PBwcfbsWdG5\nc2fx0UcfiRYtWogFCxaIGTNmiIEDBwohchbuDB48WPzrX/8Srq6uonnz5uL7779X6su7sEcIIU6e\nPCl69uwpatWqJZo0aSJ8fX0LXKhYEN7e3sLBwSHfX+5CpJJ0nSzJOgohxJkzZ0TPnj2Fi4uLaNWq\nlfjxxx8LXbao0RGikA8tSSQSiUQieSVKxAKpN82zYY1nMTQ0LPRChjeBRqN57jtjczE3N6dUqVJv\nyKIcpI5Fg9SxaCnJeqalpZGamvrcdD09PWV+/W0jdSxa/rF3thqNBn9/f+Lj41GpVIwcORJra+tC\nlR0yZMjfvo6sbdu2rFixoqhMfW1OnDihPLrxPDZu3Ejz5s1fum6pozZSxxdTUnXMpSTruWHDBr76\n6qvnppctWzbf279eBalj0ehYpLy1APZrcvz4ceXh5L/++kssWbLkLVtUPISEhIgJEyaIGTNmFEv9\nUseiQepYNEgdi4b3QcdDhw6JLVu2CCGESE5OFiNHjny7Br2AErMa+WW5fPmy8kozBwcHrl69+pYt\nKh6srKyYNGlSsdUvdSwapI5Fg9SxaHgfdGzUqBE9e/YEtN/LUFL5x4aRJRKJRCL5p1BsC6TUajVr\n167lwYMHZGVl0a1bN8qUKYOvry8VKlQAwNPTk8aNGxMREUFERAR6enp07dqVevXqFWoft2/fBnK+\neJH7/7tK3jbmfTi9KJA6Fg1Sx6Lh9u3b74WGUHw6vk99Ef7XzqLui0VJsTnbo0ePYmZmxpgxY0hJ\nSWHy5Ml89tlntG/fng4dOij5Hj9+TFhYGL6+vmRlZTFr1ixcXFwKfH3X+0D2sI4FJ+w/Vez7vtGu\nfr5tehv3Fvt+3zWkjpJneZvn9bvEP1nHYnO2jRo1Ur4bmBtPv3btGrdv3+bUqVNYW1szcOBAYmJi\ncHR0RKVSoVKpsLa2Jj4+vsDXd0kkEolE8k+k2JytoaEhkPMx66+//hpvb2+ysrJo1aoVVatWZdeu\nXezYsYPKlStrfQHCyMiItLS0Qu0jb8igJIcPXoYbz/zOBn4wKEfq7NlKOD4jI6NIw/ESiUQiKV6K\n9aUWCQkJLF++HE9PT5o2bUpqaiomJiYANGjQgM2bN+Pk5KT1Uu309HQlz4vInYsoKLTwroTtTuub\nYiw0TJ0/nytXrrBs2TJ69uwpw/ESiUTyD6LYHv15/PgxCxcupE+fPri7uwOwcOFCYmJigJyvL1St\nWpXq1atz6dIlMjMzSUtL49atW1SqVKm4zPrH4apOpXXmI+V3bjj+zJkzzJkzh7Vr15Kenq4Vjjc2\nNlbC8RKJRCJ5+xTbne3u3btJSUlh586d7Ny5E4D+/fsTEBCAnp4eFhYWDB8+HGNjY9q0acOcOXPQ\naDR4e3u/tde8lUQMyHkyKz09nS1bttC2bVtMTU2LJRz/bAg7b9o/jYIWKQGw/9Q/tk0SieSfS7E5\n20GDBhX4maYFCxbk2+bh4YGHh0dxmfKPJ1FHjzXz5tGgQQPq1auHubl5sYTjXzbtn0pxPbIikRSW\nvGsx0tLS8PT0lGsx3nHeyw8R/JNIRo8NhhUY0acPZcqUAXLC8YMHD6Z69epa4figoCAyMzNRq9Uy\nHP8M8uImKUnItRjvH9LZlnD+U8qCdHTZuXMnGRkZAAwYMECG418SeXGTlCRc1am48L+v1shHI999\npLMt4XTOfEhnHlJp7i6t8KcMx78c8uImKUkU91oMZR3Gc9YuVPoHvASiIApaV5JLSZ8Wks5W8l4g\nF5oVPe9im94kxbkW40VrLd7VtRgluU9KZyt5b5ALzV6f7OxsgoKCSElJUea+P/zwQzn3/ZLItRjv\nH9LZSt4L5MWtaDh16hTGxsZMmTJFzn2/BnItxvuHdLaS9wJ5cSsaateujaurq/K7OOa+c0OBJTkk\n+LI8O7WQdy1GXuRajHcX6Wwl7wVyodmr8eyrUHMvGOnBR4tt7vt9+sQeyOe+3xeK7XWNEonk3SRR\nR4958+ZRv3596tWrR4MGDahatSqQM/cdFxeHsbHxK899SyTvItLZSiSSQpM7992nTx/lE5rynecS\nyYuRYWSJRFJo5Ny3RPJqSGcrkUgKjZz7lkheDRlGlkgkEomkmJF3thKJpMTxvNcM6m3c+4YtkUiK\nBnlnK5FIJBJJMSOdrUQikUgkxYwMI78Czz7on4sMcUkkEomkIOSdrUQikUgkxYx0thKJRCKRFDPS\n2UokEolEUsyUWGebkpLCihUr8PLywsXFBXd3d5YsWUJycjLBwcE4OTmRmJhYYNl/3U5j9uzZQM73\nN7/77jv69++Pp6cnXbp0YcGCBdy6davQtqjVakJCQgqdf+vWrYwYMeKV018VjUZD7969mTZtmrJN\n6qiNu7s7u3fvLjBt/fr1ODo6av0Vx3F6WwwePBg3NzdiY2OLdT/9+vVjyZIlr1T2v//9L25uboXK\ne/fu3Zdqj7e393OPfS7h4eF06tSpUPWVZArT1jeJm5sbv/3229s2461SIhdIJScn4+3tjampKTNn\nzqRy5crExsaydOlSTp8+zebNm5k/fz6//PJLvhPjSbbgdFo2czw9Adi4cSORkZGMGTMGe3t7EhMT\n2bZtG2PHjmXr1q2Ympq+0J6IiAi2bNlC586di6W9RcW2bds4ffo0dnZ2QMnX8W0sNAsODubx48cF\npl25coWePXsyZswYZZuBgUGx2SIpebi5udGwYcO3bcZrs27dOgwNDeGnLW/bFAB27txZqGvEu0yJ\ndLbLly9HCMHWrVsxMjICoFKlSlSvXh1PT09CQ0Np1aoVhw8fzuckfknJwkRXR3lJelhYGF988YVy\nAllbWzNnzhy6dOlCZGQkrVu3frONKybi4+NZv349zs7OyjapY34sLS21vkaTl6tXr9KjRw/KlSv3\nhq16PeTq+KLDwMDgnRhgWVhYAJD9lu3IxdLS8m2b8NYpMc5Wo9Hg7+/PtWvX2LdvH2PGjFEcRC42\nNjYEBARQrVo1rKysGDVqFI8ePcI8T57/pqhpaaaPvn5O03R0dDhz5gzu7u7o6ekBYGhoiL+/P+bm\n5ryIc+fOKSExNzc3VqxYgZMQBDzK5D/JWSSoBWZ6Orib6jMqO1vZh0ajYdWqVYSFhWFkZESXLl3o\n27dvgfuIiorCz8+P6OhoyqOmbWkV3S1KoaujUyjthBDMmDGDkSNHcurUKaKjo5k2bVqJ0fHRo0fM\nnz+f8+fPKzouWrSIx08yWXY/gw/0ICkbTHQhU0AHPz9GjRpFeHg4mZmZ9OzZk/v376Onp4eHh4dW\nmPzRo0d4e3uTlJSEjY0NQghu3rxJedRoBNQz1uOPdA1PNIKvKhoxwN2dbt260aVLFwA2bdpEYGAg\njx8/5unTp2RnZyt9MTg4GJVKRfXq1fnll18wNDSkb9++jB49WjnGa9euZceOHSQlJeHo6MjYsWOx\n/X/bDj7JYntiBglqgd3w4QwaNIhGjRoV6pj6+vqSnp7OvHnzlG3e3t707NmTLl26sHXrVq5du4a1\ntTXh15LRAB5mKkaVNUDv//vNjz/+yI4dO0hNTaVLly4IIZS60tLSmDFjBn/88QdCCExNTfniiy/w\n8vJi8+bNhISE0LBhQ27eSOVWloZO5qUIScqkmYk+R1PVZNeujZ6eHqmpqVSvXh0fHx8mTJhA69at\nOXfuHBcvXmT48OGsWrWKgwcPkpiYiK6uLjVq1OBf//oXtWvXBnIGiaNGjeLq1asAWgOdLCEYeSMN\nG5UuCyrk9OHvv/+e7du3s3nzZqKiogCIjIxk0qRJPH36FFNTU1JSUsjKyqJixYp07dqVo0eP8scf\nf5CVlUV4eDg///wzMTExWFlZkZiYSPv27QkNDaV27dpcvXqVu3fvUqZMGTw8PGjTpg1r1qzhjz/+\nwMLCgpYtWzJ48GBKlSrF3bt36dWrF3PnzmXTpk3cvXsXR0dHJk+erESXrl69ip+fH1FXkzHT06FD\naRW9LXOc+SO1huVjx3LkyBGMjIxwd3dn2rRpmJmZafWF3P4YHx+PSqVi5MiRWFtb88MPP+Dv78+d\nO3ewtbVl5MiRStQot690BJbeS8dMV4cUjeBIihpzPR3GHT9OUlISmzdvJjU1lZYtWzJx4kR0dHSI\ni4tj0KBBqFQqsrNz3LWLiwvTp09ny5YtHD58GAsLC0aPHk3Tpk0BuHz5Mhs2bODSpUtkZ2dTrVo1\nxowZg5OTk9Y536hRI8aNG4erqysxMTGcOnUKc3NzBgwYQLt27Qp1bvxTKTFztidPniQrK4thw4ah\nVqu5du1agfnq1auHhYUFzZo1o3Tp0hw5ckRJS1BruJCezadmKmVbjx49CA8Pp3v37vj6+hIeHs6j\nR4+oWLFiocIazs7OjB49mtKlS7Nz506cnZ35ITGTn5OzmGJlSIC9CcPLGBCSlMWvv/6qlIuJieHh\nw4f4/b/j2L59OxEREfnqT0xMZMqUKXzyySds2bKF0WUN2ZOUxQ+PMwut3bZt28jOzqZfv34kJiai\n0WhKlI6zZ8/G3Nwcb29vTExMcHZ2ZteuXSSoBSodMNHVYYudMfal9HgqoGbNmlr6GBkZsWjRIho2\nbMiBAwf44YcfAPjrr794/Pgx48ePZ/ny5dy4cYPr16+zdOlSRpc1JEEt+OmJmtHlDPCpYIR9KT0t\nu77//nsCAwOZO3cufn5+aDQaFi1aROPGjfH398fAwIC4uDju3bvHnj17GDRoECtXrlQu8qtXr+bf\n//43M2bMYPfu3VhaWjJ9+nSyheBkqhq/hKcMtDRgo50J7du3Z+7cuVy8eLHQx/VF/Pbbb6SlpbHK\n1oTRZQ3Zl5TFb6lqAA48yWLLli18/vnn+Pn5cffuXeLi4pSyM2bM4M8//2Tw4MEsXryYChUqsGTJ\nEv744w88PDxITk4mIiKCTualWFbRmLhMDR/o6XAuPZvWpVWYmJhgbm6OEAJXV1cGDBiAWq0mODiY\n6tWr4+7uzvnz59m5cyft27fHz8+Ptm3bYmxsrKwDyMrKol+/fsTFxTFlyhRmzZrFkydPAIhKz0al\no8Ok8ob8nqrmt1Q1NzM1bNmyhS+//FLLKYeHhzN37lxMTEx48uQJdevWZePGjdjb27NixQpsbGzY\nsGED5ubmREdHo1Kp8Pf3x9bWltTUVK5fv87atWs5d+4c9vb2mJqaMn36dEJDQ/nyyy+xtbVlw4YN\nTJ8+nZMnT7J69Wqt47Bt2zYmTZrEunXrSEpKYv369QAkJSUxYcIEypQpw5pKxowvZ8j3jzMJe5IF\nwNy76QCsWbOGRYsWcf36dcaPH5/vOOdeGxcuXEjv3r3Ztm0bUVFRzJ07l4kTJ3LgwAH69+/PtGnT\ntI5xXvYmZWFXSo8NdiY4Gurh4+PDgQMHWLx4MRMmTCAsLEy5fvn4+AA5d8dffvklH3zwAZcuXWLo\n0KHY2dmxfv16PvroI5YtW4YQgrS0NKZOnUr16tXx9/fHz88PIyMjvvrqq+f23aCgIBo0aMCWLVto\n2rQp33zzDY8ePXpu/neBEuNsL1++TO3atUlKSgLgzp07f5tfX18fNzc3Dh8+rGw7nKLGVqVLDcP/\nXVR79+7N3LlzqVKlCv/5z39YsmQJ3bt3Z+XKlcqo7e9QqVSKM7G0tESlUmFfSpcp5Q1xNdLHWqWL\nZ2kVdqV0tRZqmJmZMXXqVCpXrkyrVq3o0KEDe/bsyVd/SEgINWvWpG/fvlSsWJEGJvoMKWNAcGLW\nC20DuH79On5+fixatAhdXV2ePHmCpaVlidHx7NmzXL16lZkzZ2Jvb4+enh5z587l1KlTGOnA5PKG\nPMwWbEvM5NLTbCro63Djxg2lvJ6eHmvXrqVRo0YsXLgQc3NzgoODgZxvp5YtW5aGDRty4sQJXF1d\nqVOnDsePH6eBiT4VVDroAvWM9bXaksv69euZMGECLVq0UD4XZ2Vlha2tLb179+b69esYGxtjbm6O\nnZ0dw4cPx8LCggsXLiCEICgoiFGjRuHp6UnlypUZN24cTZs2JUUjCErMpIdFKdzMVNiodOnYsSOf\nfvopO3bseOExLSwGBgY5d9KlcvpgVQNd/srQALAvKZNOnTrh7u5O5cqVmTx5stKPNRoN58+fp3v3\n7vTt25dPPvmE1atXo6ury8aNG7Gzs8PMzAxzc3M+La2iokqXk2lqbmcJPi9nyC8paqZNm8aiRYsA\n6NixI/Xq1SM1NZU2bdpgampKuXLluHjxIh06dGDSpEm0aNGCx48f07t3b65cuQLAr7/+yv379xk2\nbBiDBw+mT58+StQg+P8HmzUN9ehqoWJtwlOW3U+nYcOGfPrpp1o69O/fn+rVq9O1a1fGjx/P8ePH\nKVu2LPb29ggh6N27N3Z2dpQqVYrGjRvz559/UqZMGbp16wZA1apVMTc3Jy0tDRMTE3R1dalXrx5d\nu3bFxMSEL7/8Ejs7O1xdXRk/fjz79+8nNTVV2X+fPn1wcXGhatWqdOrUib/++guAQ4cOoa+vz+TJ\nk7EvpUcDE33GljPESAfOpam5lqFh2bJlVKlSBUdHR5YvX87Ro0cVfXLJvTYCODg4cPXqVW7duoWO\njg4VKlSgYsWK9O7dm02bNj03XGtbSpeeH5TCRqVLazMVqampjBo1iqpVq+Lu7k6lSpUUR3337l0A\nunXrRqdOnVi6dCmurq6UL1+eXr16YWdnR9euXXny5AmPHj3i6dOneHt7M2LECCpWrEj16tXp1KnT\ncx0/QJ06dejUqRM2NjYMGTIEtVqtRDfeVUpMGDk9PR1jY2NlrkGj0ZCdJyxbEL1796Znz54YHDlC\n+fLlOfbZZ3Tr50GlkSO18vXq1YtevXqRmprKiRMnCAkJYffu3VStWpXhw4e/0DYLCwt0dXWxsbEB\nwPvIeU6cOMH3R44QGxtLdHQ0NzKTMTExwcbGBjMzM2rUqEG1atWUOho2bEh4eLiSrlKpsLGx4d69\ne5w7d04rhKLRwFONwDTwZz744ANle+7+c8kNHw8ZMoSqVasCKJrllnvbOh46dIiMjAw6d+6MWq0m\nMzOTAQMGAOA4ZzkffPABtdeuJeLXXzEzM+NO8v901NPTw8rKSkvHGjVqKKGn1NRU0tLSaNeuHRkZ\nGYrTP3PmDPsMDUlXgwBtHd3dMTc3x9zcnNu3bzNz5kzlTsvIyIj79+9jYGBAixYtOH36NCdOnEAI\noWhoYmKCWq0mMTGRR48e8dFHHym2OTg4/P9dgQ/XGzbkckoa3z/9/4FIu3ZkZWVRpUqVfMexIIyN\njQHtY66vr4+5ubnShypWrIi9vT3sPwWAZb9+GNWqRaWpU4mvXZthDRpola9SpQoXLlwgPj4eyLmz\n//7777X2e/fuXWxsbLC3tyc2NpZK+8+wf/9+jBcsIDExkYZbQ5jt5cXMmTPR1c0Zqw8bNozs7Gz0\n9fWpVKmSEk3R09PDy8uL7777jsuXL3P27Fl+//13NJqcAcGVK1fQ0dFh06ZNBAQEACjH8G7FqlTa\ntw+AmenptGvXjrjHj/FfulRxKLnXik8++YRq1arx+eef891336FWq5k6dSrR0dFAzvd2dXV1SU9P\n59GjR2g0GjIyMrCysgJy7rBr1KhB//79CQgIQEdHh1WrVpGSksL9+/e1zk0hhFK+fPnyQI7jyNW5\nYsWKaDQabGxsSEhIwMnJSesYDfz/egIDA8nw8SlwMda1a9f48MMPld+518ZcdHV1ady4MS4uLvTo\n0YOqVavSsmVLunTpQunSpbX6SqX9pzCZNo2qT55Qyc8PgNu//w79+1O3bl1lAGZqaoqhoSE2NjZ8\n+eWXLF68mICAAK5fv86nn36KjY2N0vcg5ykHgA8++ABbW1sqVarEnj17uHz5MnFxcURFRSk65GJp\naYmNjQ0GBgY4OjrmOw/y1v9c/l/HgijMefU2KTHO1sjIiPT0dFxcXLCwsCApKalAB5Eb8ho4cCAu\nLi7Y29tz4MABWrRowcWLF1m5cqWS9/Lly+zYsYNZs2YBYGJigpubG25ubowfP56jR48Wytk+y+rV\nqwkICKBbt254enoyceJEJk6cqJUn90KUi0ajQaVS8SxqtRpPT0/GjRuXL+3ZuZtnuX37NidPnuTP\nP/9k7dq1QM6JGRsbS5cuXUqEjmq1GhsbG7Zs2cKBAwfYsGEDO3fuBHJWKAYFBWFtbY2uri4VK1bM\nV74gHXV1dZWLcsWKFdm8eTNz5syhVKlSDBw4EAMDA8qWLcukSZNwcHAoUMfc8r6+vsq8Ui779u0j\nPT1dKZeRkaGloRBCOZZ550GfrX/ixIn5HmPJnQN/EToFzNer1Wqt3wX1p7zln7Utd9+5odoRI0Yo\nC+ByyR2U2Nra8ueffxIbG0tYWBhNmzZl3759ig25unXt2pU5c+bg6upK//79c1bA5rF38uTJODo6\n0rx5c2JiYujXrx+TJk3SsjGvThcuXGDixImsW7dOqef+/fs8fPgQtVrNhQsXaNGiRb62pqam4u3t\nrWzr1KkTp06d4uDBg2zYsAFra2v69etH//79+fTTT7GyslLWEOTaPGPGDMqWLYufnx+3b9/m+PHj\nVKhQQRkI5MXKyoqEhIQCj0Ou7iqV6rn9I+958SxlypTR+p17bcxbv4mJCUFBQZw9e5YjR45w6NAh\nAgMDWbduHU2aNMlXZ0H9rqA+BjBw4EAWL15Mp06duHfvHlOmTKFChQpa0zt5uXfvHt27d6dKlSo0\nb96ctm3bkpiYqBzngiio7z5Pq3eFEhNGdnR05OzZs+jp6dG0aVPu3buXb9VofHw8QUFBWgeqY8eO\nREREEB4ezscff6w1utFoNAQGBnLixIl8+zM1NdW6a/w7nu2UmzZtYurUqUybNo3OnTtja2vL7du3\ntTpLTEyM1sXx3LlzVK9ePV/d1apVIzY2Fnt7e+XvypUrrFq1Kp+jeRYrKysOHjzInj17CAkJISQk\nhFq1alG5cmX27NlTInSsVq0a9+/fx8TEhHLlyqGnp4e+vr4ycv7ss8+4du0aGzZs4M6dO8TFxWnp\neO/ePUVHIQTR0dGUK1eO0qVLY2xsjFqtxt7eno8++oj79+8TERGh6Jmens6ZM2cK1LF06dKUK1eO\ne/fuYW9vz6FDhxg5ciRbt24lLS2Ns2fP8vjxY3R1dbXuMnIxMzOjTJkyyvwtwNOnT2nSpAl//PEH\n1apV49atW1rHNTQ0lP379z9Xq7yoVCqtUGVqaupLzWk5ODgozgQgMzNTCeu5u7sDcOvWLRo3bkzj\nxo1xdXVl/vz5yny4kZERlpaW7N+/n6NHj+ZEPgwMiI+PV3SDnDscKysrAgIC8vWzBw8eoFar2bp1\nK82aNaN27dpKiFIIgYODA5BzruRqlNvGXJ2EEMycOZOmTZsyfPhwZs+erdxV5RIfH09kZCSxsbEM\nHz4cAwMDunfvrizcyw0p6+vrExUVxdKlS8nKyiIzMydUXbVqVRISEpg3bx6mpqYYGBgQEBBA8+bN\nuX//PtbW1op9iYmJSvkXUblyZaKjo7Xyrl69mrFjx2qdF7l1554Xzx7n3GsjQHR0NHZ2dpw9e5ZV\nq1ZRt25dxo8fz759+3B2dubgwYMvtOvvyMjIYOHChQC0bNmSdevWMXv2bG7evPncMvv370dfX5+t\nW7cyZMgQmjZtqnWcJTmUGGfboEEDVCoVM2fOREdHB1NTUwYOHMixY8e4ceMGBw8eZMiQITg7O9O9\ne3elXMeOHTl9+jR79+7N9xysk5MTnp6ejB07lh07dnD9+nUuXbrEpk2b2LdvH4MGDSqUbcbGxqSl\npRETE6OEn44cOUJ8fDwXL15k7NixJCUlKScv5CzsmTFjBleuXCE4OJjg4GCGDRuWr+4+ffoQFxeH\nj48P165dIzIykjlz5mBmZvZCZ6uvr691Mbe3t6dChQoYGhqycePGEqFjkyZN+PDDDxk/fjwJCQmk\npKQwevRobt68iZWVFUFBQbRv3x5LS0usra15+vSpcscAOSE+b29vDh8+zNChQ0lKSuLLL78EoG7d\nujx48ICffvqJli1bcuXKFb777jsMDQ2Vi2+pUqWeq+PQoUPx8/Pjp59+4sMPP+T69esEBQXh7OxM\nfHw8Z8+exdTU9LntGzhwIGvXruXw4cPExsYya9YsTE1NqVGjBkOHDuX7778nKChIqXfNmjXY2toW\nWLXvZvgAACAASURBVNezfPTRR5w6dYojR45w7do1rbBtYRg4cCA//vgju3fv5tq1a8ybN095vlhX\nV5ePPvqI/fv34+vry9GjR+nVqxexsbFaYfEKFSqwadMmrK2t+fjjj+nRowdLlizB09OTVatWKdGM\n3bt388MPP+S7e6pfvz7p6ekMGTIEPz8/rKyslAhMZmYmjRo1okKFCgQHB/PNN9+wY8cOvv32WwBF\np6CgIP78809mzpzJyJEjKVWqFEuXLtXaz+rVq0lNTSUrKwsfHx/atGnDsWPH+O9//wvkRHGio6PJ\nyMjgp59+4ubNm9y/fx9/f38A2rRpg7m5OREREYSGhqLRaIiKiiIhIQGVSqWEpM+cOcP06dPJysp6\nYdQJcs6p7Oxs5s2bx7Vr1zhy5AgBAQG0aNFC67z4888/uXTpEhMnTuTWrVv5Ijx5r40BAQEMGDAA\nIyMj1q9fz7Zt27h58yaRkZFcvXoVFxeXwnWQ52BgYMCZM2eAnMHY1atX+fnnn/92QJ17l3/48GFu\n3rzJrl27tI6zJIcSE0bW1dXVCkUmJCTg5+fHrFmzSEhIwMrKitatWysnXC62tra4urpy8eJFvLy8\n8tX71Vdf4e/vz9atW/Hx8UFXVxdXV1f8/f2pU6dOoWxr1KgRTk5OdO7cma+++gpfX1/mzZtHhw4d\nsLS0xMPDg88++0xrpWnjxv/X3n2HRXH8Dxx/39GLgorSggX1MCEqNqKmCfo1P3vExBoxdqIplsQK\nglEU1BijRsCCLYlGo8bYo9Fo/CYWjL1hj4IYjZV+cPv7gy8bkAMOuIMD5vU8Pg/ebZn53OzO7szs\nbFvMzc3lK+zAwEDeeOONPNt2cnJi+fLlzJs3jx49emBnZ0f37t21jkrUhUKhyNF3WPZxVCqVRERE\nEBoaSkREBBqNhkuXLhESEsKRI0eIi4tj586dHD16lPbt2/PgwQN27dolP/KSfRc1cuRIzMzMGDZs\nmPzYTtOmTYmNjWXu3Lk8ePAAFxcXTE1NmTx5MnZ2dvLgqfz4+/uTmpoqr+/s7IypqSlTp06latWq\neHh44ObmprV5G7JmZEpKSiIwMJCkpCSaN29OVFQU5ubm/Oc//yEoKIgVK1YQGhqKq6srn3/+OZ07\ndy78RySrGfTUqVOMHTsWCwsLBg8enO9MX9p06tSJp0+fsmjRIh4+fEi3bt1o1qyZfCKNjo5m5MiR\nrF69mpUrV2Jpacknn3wiDxqCrJPolStX5D7LTz/9lOTkZLZs2YJGo5HvwE6cOMHChQvlO6JsXbp0\n4fTp02zbtg21Ws3du3flR4TOnTtHixYtWL9+PcOGDSMyMhJJkuSTeufOnbl79y7z5s3jo48+wtnZ\nGcga2T58+PBccXz99deZM2cOlpaWpKWlsXv3bi5fvsykSZMICQkhISGBd999l/T0dBo1aoRGo6FH\njx7Uq1cPyGpFMDMzY+nSpYwdO5anT58yaNAgfH19CQ4OZuHChbz77rtYWVnh4+PD5MmTdfoNbG1t\nWbZsGbNmzaJHjx44ODgwatQo/Pz8AOTjwt/fH6VSSZs2bViwYEGebp/nz43Z5s6dy5IlS5g7dy7V\nq1dn8ODBuX6/4lqwYAEdOnRg3rx5KBQK2rZtS6tWrfK9S+3UqRMnT55k0qRJqNVqGjZsmOd3FkAh\nift8wUgNHDiQl19+mYkTJ5Z1UgRg7969tGnTRh5U8/DhQ9q0acOBAwfKZHDK0aNH8ff3588//8TG\nxqbU9y8IRWE0d7Zl5fnm3+dZWlrq1GRkCMnJybn67Z5nYmJiNDOziDjqzphjVZAlS5awe/duPvzw\nQzIyMli0aBFeXl75VrQlyadarc53Ws1s2aOaKxpd8l69evUCnzAQjE+lr2zHjRvH4cOH8/2+c+fO\nfPnll6WYon998803BT4Y7uDgwH//+99STFH+RBx1Z8yxKsi8efMIDQ2lV69eKJVKXn311TwTPORU\nknyeP3+ePn36FJiesLAw3RJezuiS9507d+Z6JE4wfuW2GTm/KcwqmoyMDCIiIrh//z5qtZpevXrR\nsmVLvW2/MsTR0DEEEUd9qQxxzHblyhW+/fZbQkJC9L5tEUfjYzSjkYtK2xRmFdFvv/1GlSpV+Pzz\nz5k6dSorVqzQ6/YrQxwNHUMQcdSXyhBHgK1btxIZGanTI0TFIeJofMptZattCrOKqE2bNnKTkiRJ\neu+nqQxxNHQMQcRRXypDHCFrpHdBkz6UlIij8Sm3zciCUFQTJ06U34BUq1Yt/Pz8+Prrr1EoFLi5\nuTF06FCUSiX79u1j3759mJiY4OfnJx5dEAShxMr1AKn4+HhA+/s8K9q7PF1cXOT86vsxi8oQx+wZ\ng8LDw+X8rl69mr59++Lp6cnSpUuJiYlBpVKxa9cuwsLCUKvVBAUF0aRJkwKnRsyW8/fJ/ru8y+9d\nuW47YgxaHo0phqX1vmB9xtEYy2JpnF+MeX7kcl3ZVkT5HdgFTcAtFC4uLo709HRmzpxJyv8mtr9+\n/bo8L3KzZs04ffo0SqUSDw8PeaIDJycnbt26pXWqzcooE/jeoiZJ06aRnJxMx44dUSqVooVAEAoh\nKluhUjA3N8fX1xc/Pz9Onz4tv3M0e95rKysrkpOTSU5OzvWGlezPdZHzqtqYr7CL4vZz/z9haou1\npGHi55+TmJjIZ599xsmTJ/XaQlAZZGZmsm7dOh4+fCi/jCQtLY2wsDB5tqyOHTvStm1bcdFSQRis\nstX2mECNGjVEYRLKRK1atXBwcEChUFCrVi1sbGxyvTc3JSUFGxsbrK2tc02on/25Loyx6U7fmmYk\n0YSsCUKy35Ws7xaC7AsVY7lgef6CI1tJ0nfgwAFq1arFhAkT5IuWd955h65du9KtWzd5ucePH4uL\nlgrCYJVt9mMCH330kShMQpk7cuQId+/elV8akZqaKs8F7enpycmTJ3n55Zdp0KAB69atIz09nYyM\nDOLi4nBzcyvr5BsNC7LGU6akpLBy5Uo6d+7M9u3b9dpCYGx9tvkpSfrq1q1LnTp1iI+Pl2c3u379\nOvHx8cTExODk5MT777/P1atXRbdGBWGwyrZNmzbyuzKzHxMQhUkoK61bt+a7774jKCgItVpNv379\nqFevHlFRUWRkZODq6krr1q1RKpV06tSJ4OBgNBoNffv2zfXCBgEeKUz4evp0vL29adGiRa7XBuqj\nhaAysLCwALJey5h90WJra0v79u1xd3dn8+bNbNy4kbp16xbrosUYuzS0tRAUNW23u2ifRMWtHIxp\nMVhlm/1C5pSUFObPn0/fvn1Rq9V6K0zw7w+ljx/RWOTXZAXlN0/GwNTUFH9//zyjurPfLpRThw4d\n6NChQ2knsVx4hglLLZ0ZOWCA/JLzunXrihaCYnj06BHR0dG8+uqrtGjRAjs7O/mCxNvbm+joaF56\n6aViXbSUly4NfaXNUCPj9cmgA6QePHjAvHnz6NixI6+99hpJSUl6K0xQ8A9lzAWsKLSN/mzYsKHo\n+xbKxC/m9qSgZNOmTaSlpQEwcuRIVq5cKVoIiuDZs2dERETwzjvvoFKpAAgNDWXIkCE0aNCAs2fP\n4u7uLi5aKhCDVbaPHz+WC0/2C6lFYSq6nKM/r1y5wty5c+nTp4/o+xbKxNvp//A2/+AWslm0EJTA\n3r17SUlJYc+ePezZsweAQYMGsXr1akxMTLC3t2fEiBFYW1uLi5YKwmCV7ZYtW0hMTGTTpk1s2rQJ\nyHpZtyhMRZNz9Ccg+r4FoRx6/vn5Hv/7ZzLj30kdXFxcmDFjRp51xUVLxWCwynbw4MEMHjw4z+ei\nMBWNttGf+hxIARWz77sgFTFPgiAYNzGpRTnw/OhPfQ6kgIrZ910W0wwKxqciT0EqlC/l9q0/lUX2\n6M8BAwbIj1KFhoZy9epVgFx93xcvXiQ9PZ3k5GTR9y0IgmBExJ2tkdM2+lMMpBAEQShfRGVr5PIb\n/Sn6vgVBEMoP0YwsCIIgCAYmKltBEARBMDBR2QqCIAiCgYnKVhAEQRAMTFS2giAIgmBgorIVBEEQ\nBAMTla0gCIIgGJiobAVBEATBwERlKwiCIAgGJipbQRAEQTAwMV2jIAhG53aXllo/F2/sEcorcWcr\nCIIgCAYmKltBEARBMDCjq2w9PDw4cOBAWSejSHx8fPjjjz90Wvbx48fs27fPwCnKTZ8xHTNmDBER\nEXrZVkHKKqZJSUls3LhR5+UnTZrExx9/nO/3YWFhBAcH6yNpgoH07duXLVu25Pu93/VE9jxVl2KK\nDKewvOYnc3j3PP+eV9KyHhwcTFhYWLHXN3aiz1YPNm3ahK2trU7LRkVFkZycLF6FV4iyiunKlSvZ\nv38/7777brG3kbO/UbqXgqQpcbIEA4qMjMTS0rKsk1EqDJnXDz/80CDbrShEZasH1atX13lZSZIM\nmJKKo6xiKn6fysfe3r6sk1BqDJlXXS+OK6tCK1sPDw9mz57NN998w5UrV6hXrx7Tp0+nWbNm3Llz\nh/bt27Nt2zZUKhUAmzdvJjw8nKNHj8rrL1iwgIiICG7evEnz5s2ZPXs2CxcuZPfu3VSrVo0pU6bg\n6+vL8uXLAVi0aBHh4eHExcXh5eVFSEgI9evXByAxMZHw8HD27NmDJEk0a9aMDzI0OJhmtYh3uPqM\nAdXM2ennR7Vq1Vi6dCkmJib55i8hIYF+/foRGBjIihUrePz4MS1btmTcuHFywXz48CFRUVEcO3aM\n9PR0WrVqxUcffUSNGjWArCbPWbNm0aZNG8aMGUPTpk25evUqMTEx2NnZMWjQILp06cKqVavYs2eP\nvE7Dhg25ceMGJiYmZGZmYmdnR+v0FHY8y2CZmzX1LLLSveepmmWvvCI3/+SM6dWrV1EqlZiZmeHs\n7MyNGzewsLCgWbNmXL16lTZt2gBZzb+Ojo7Ex8djY2NDeno6arWaunXr0r9/f2JiYjh0/RmJGqhn\nrkSJxF9qifqjRnHx4kUGDhzI9u3bSUlJoVatWkybNo1jx45RpUoV+vfvT8+ePY0ipgcOHODs2bN8\nfTuJG+kaqigVtK9iytAaFpgoFAWW9c2bN7N48WI5xp06dcLW1pb09HR+//13Hj16hIODA/369SMg\nIEBeLyUlhfHjx/Pzzz9TvXp1BmjS6VTVXOs+jh49yrJly7h9+zbOzs706dOHTp065ZsmHx8fPv30\nU3744QcSEhLw9PRk7NixuLq6yt9n/zbZ5T0+Pp5FixZx5swZ7O3tadeuHUOGDMHcXHuaDEWj0bB8\n+XJu3bqFmZkZAQEBODk5lWoactr+JJ0Nj9O537EjTk5ODBgwgLfeeou+ffvSp08fevbsSWZmJsuX\nL2fXrl1IksTAgQPLLL3ZihPHbdu2sX79eu7fv59vXsPCwqhSpQqJiYn8+uuv2NnZMWbMGJ48eUJ0\ndDRJSUm0a9eO8ePH65TOsLAwUlJSmD59Ort372bLli20a9eOjRs3kpKSQhvTDMbVssRKmXUc7n2q\nZu2AAfzzzz/4+PiQkZGRa3vajpWO//tuQlwyTzUSX79gjYlCwa+//kpoaCgbN27kpZdeKnKMS4NO\nfbYLFy7kk08+YevWrdja2ha5XX7evHkEBQXx7bffcunSJXr06EG9evX44YcfaNGiBVOnTuXYsWOo\n1Vn9Ijdv3qRevXps3rwZGxsbPvzwQzSarLa4adOmcfPmTVasWMGCBQsAmBSfQmaOO5IDiWrmz5/P\n5MmTC6xoc1q2bBljxozhyy+/JCEhgZCQEAAyMzMZP348CQkJhIWFMX/+fB48eEBgYGC+d0Hr1q3D\n29ublStX8tprr7FgwQIePnxInz59aNeuHQAODg4MHjwYCwsLqlatiouLC5MnT+ZAYobWbWqLqZeX\nF9bW1lhYWKBUKtFoNGg0Guzs7Lhw4QI1a9Zk27ZtACiVSsaOHUutWrUwNzenRo0abNmyBZVKxaxZ\ns7hz5w5hLtZUN4Gb6RoeZcLiF6yoXbs2AHv37mX+/PnUrl2bX375BS8vL6Kjo+natSuLFi3i9u3b\nZRrTNm3asGnTJjIzMwkMDMTLypTo2jZMdLRk51M1Pz8rvM+tc+fODBkyhNq1azN06FC++OILnj59\nym+//caSJUvYvXs3AwcO5Msvv+TChQvyeocOHaJatWosW7aM3r178+XfaZxPycyz/Rs3bhAcHEyP\nHj2Ijo7G39+fiIgI9u/fX2C6li5dysCBA1myZAlKpZJJkyblOjH98ssvcnnPzMxkwoQJvPDCCyxd\nupTJkydz/Phx+SKiNB0/fhy1Wk1oaCj9+/dnzZo1pZ6GbFfSMll4P41hNSxYs2YNvXr1Ijw8nDt3\n7uRabu3atezZs4cpU6Ywf/58fv/9d55qyra1o6hxvHDhAgsWLGDEiBGscjGnZ+rfhIeFcWtQV/jn\nbzTfRcnLbt26lTp16rB8+XIaNWrEzJkz2bNnD7Nnz2bcuHHs2rWL33//vVjpvn79OufOnWP+/PmE\nhITwe1IGO/7X930qOYN5f6fSu3dvli5diq2tba795HesHPjfcTyuliV30jX89ETNk0wNCxcuxN/f\n32grWtCxsu3fvz9vvvkm7u7uDB06lMuXL5Oenq7zTt577z1atWpF48aNad26Nc7OzowYMYL69esz\ncOBAHj9+zIkTJ/Dy8gJg5MiRaDQaGjZsyKxZs7h9+zZHjhzh9u3b7Nixg3nz5tG4cWPq1avHlClT\nuKfWcDz535Nb56pm1K1blwYNGuicxiFDhuDt7Y2HhwcTJkzg9OnT3Lp1i2PHjnHnzh2CgoLw8PDA\nw8OD4OBgrly5wokTJ7Ruq1mzZvTo0QMXFxeGDh1KRkYG165dw8rKCgsLCwD8/Pzw9PQkOTmZli1b\n8tdff9GkSRMmOurWn/Lee+9x4MABPv74Y15//XVeeOEF1q1bh5mZGa1ateLx48eYmZnJd5IBAQG8\n+eab9O/fn7Vr15KQkMD9+/fp3LkzarWagIAAPCxNMFUo6GBrSrJG4u8MGDduHAD169enbt26WFlZ\n0bp1a/z8/HBxcWHgwIGYmppy9erVMo2pmZkZ1atXJykpiWfPnlHNVIGjqYLm1qaEuVjT3KrwHhNL\nS0usra1JT0/n1VdfxcTEBB8fH+rVq0eTJk1wc3Nj2LBhWFtbExsbK6/n7u7O1KlTqV27Nj179qSt\njSk/Pcl7fKxfv54OHTrQrVs3XF1d8fX1pXfv3mzYsKHAdPXq1QtfX1/q1avHpEmTuHfvXq44de3a\nVS7vv/zyC2ZmZnz88cfUrl2bpk2bMnbsWHbs2EFSUlKhMdCnS5cuyce0SqXi2rVrpbr/nO6psy7W\na5oqcXJyokePHsyZMydXs6okSfz0008MHDgQb29v6tevz+TJk8t8FGlR4xgXFwdAzZo1cTRT0t3O\nnDAXK+xN8rbsuLm50bdvX1xdXenUqRNJSUmMGjUKd3d3fH19cXNz4+bNm8VKd0ZGBuPHj6du3bq8\n8sortLI25XJq1nl621M1r9qY0qNHD2rXrs2oUaPkC3vI/1jZ+DjruHIyUzK0hgWrH6Yx914qjo6O\n9O/fv1jpLC069dnWrVtX/ju7Xf75W/6CuLm5yX9bWlrm+T9kNQ9bW1sD0LRpU06dOkVmZibVq1fH\n1dWV2NhY0tLSAPi///u/XNtPRcEz/49xGzIEPDx4OWgOLi4uOqUt+465Q4cO8jrOzs6Ym5vz+PFj\nHj58iKurK02aNJHXcXFx4YUXXuDhw4fyOtWrV8fFxQULCws8PDzy7N/Ozg4XFxc5j40bN6ZRo0b4\n+/uzevVqABYvXkzbMSEwaRJOS77H7X9N89U3b4bw8FzbtLe35++//6Zx48ZcuHABNzc3qlWrhr29\nPVZWVkDWySP776ZNm2Jtbc2AAQPYvn07FhYWBAcHc//+fQDGjh2LUqkkJRN+TVei/l9Ms397hUIh\n569hw4a50mJjY4O1tbX8WVnF1MXFBRcXF/z9/YlcvZofqMIbb7xB586dafn667n2VRCNRiNv8+23\n3+a7775j1qxZ3Lx5k4sXL5KcnCznEaBJkyZyfABajfiIXbt24bZ1KzaTJqFITsbFxYW4uDhiY2Nz\njQzPyMjA1NS0wDT5+PjI37u4uODq6so///wjf/bSSy/Jfz948ID4+Hi6dOkiry9JEhqNhrS0NBo2\nbFhg3vPYEZPvV4XFMSUlRY4jZLWuZGZmFtra5OLiUuB+i+R/2+mZmsrW99/no5MncR86lHbt2tGz\nZ09UKhWmpqbY2dlhZWXFo0ePaNu2ba54Ozo7U/3jj3Hz8ytxOoqjqHF8/fXXadq0KaNHj8bd3T13\nXn19qTZkiHzc1KtXL1deAZo3by6f521tbbPO2TqkP+dxaG9vj42NDS+//LL8fc2O3UhOTsZt4ULi\nunShe/fuucpQs2bNUCqVhRwr/6blQ42Gw337cvTMGXbMn5+rXjFGOlW2ZmZmeT6TJAmFlj6wzMy8\nzWfPFwqlMu+1oqWlJSkpKfLykiTJ62k0GszMzMjMzMTMzIwff/wxz/p2dna5tlVUpqb/hkKSJHn/\n2Xeiz8tustUmv3hpW2bKlCl4enoyYcIE7t69y+TJk/Osqy2m2enKTkN2TJVKpdwcn/NzExMTkpKS\n6Nu3L+bm5piYmNC2bVscHR356quvWLp0KU5OTgwcOJBBgwbRoUOHXDHNmSdtB7m25t/Sjmm2KVOm\n0L9/fw4cOMCvv/7KiBEjGD16tM6jJZVKpVwWp0yZwuXLl2nTpg09evQgODiYt99+O8/yz+dDW3oz\nMzMZOHAgffv21Skd2Z6P9/Mn2pzlPSMjAy8vL2bPnp1nO46OjkXab0lZWVnJcQRyHdOlzdLSknXr\n1nHy5EkOHjzI/v37+eabb4iMjMyzbH7HalkpahyLktecx2g2bef14igobgqFQmucs891uhwrT58+\nJS4uDqVSyZEjR+RxPcaqRC0k2cHM2Tylre9OF+7u7pw8eRLI6gPLblK4d+8e8fHxNGjQAHd3d9Rq\nNcnJydSpU4c6derg4ODA7Nmzi93Uke3cuXPy3+fPn0etVtOoUSPq169PfHw89+7dk79PSEjg7t27\nxfpxcxbkBw8eMH36dLlSi4qK4r333gMKj6mVlRVOTk6cP39e/uzZs2c8fvyYu3fvAllXxFWqVAGy\nmqIOHz7MjRs3WLBgAUlJSXTu3Fm+Gs2OqampKXfu3JFjmpqaCiAPyCmKsoxpdp/46tWrGTFiBDt2\n7NB5W5aWlpw8eZJHjx6xefNm3nzzTcaNG0eXLl0wNzfn2bNnuU4Uly9fzrWNU6dOae3CqF+/Prdu\n3ZLLbp06dfjjjz/45ptvCkxTzt/477//JiEhgUaNGmldNnsfTk5O8j4ePXrEnDlzcl2ElQYPDw/5\nmI6Njc3VTFjaTp48yaJFi2jevDljx45l27ZteHp68vPPP8vLVKtWjZo1a3LmzBn5s4cPH8rHU1kp\nahx1yWtZU6lUnD59OtdnOcdB6HKszJo1C0dHR0JCQvjiiy+Ij48vtfQXR4kqWwcHB5ydnVm5ciV/\n/fUXe/fuZfPmzcXalpeXl1x5r1q1igYNGnDp0iUmTJiAp6cnr7zyityPMGHCBGJiYrh27RqfffYZ\n586dK/FVzZw5c4iJieHMmTMEBQXh4+ND7dq1adu2LR4eHowfP55z585x9uxZxo0bR926deWRvkWR\nXbk9ePAAOzs79u3bJxegS5cu8eeff2JlZaVTTN9//30iIyNJSEggMTGRyZMnk5aWJl/13r9/H09P\nTyCrifr27duo1WpGjhxJw4YNefr0qTwCPCwsjJiYGNRqNevXr+fEiRMolUqmTp0KQIsWLYqc19KM\naVxcHHfu3JFjGhoayo0bN7hw4QKHDx/O1WRd2LZSUlJISkpi7ty5mJqaYmVlxe3btzlx4gQfffQR\nkiTlGrNw8eJF5syZw7Vr11i2bBmHDx9myJAhebY9ZMgQfv31VyIjI7l16xa7du0iPDy80DvOyMhI\nDh48yOXLl5k4cSINGjTA29tb67Ldu3dHqVQyceJEYmNj+fPPP5k8eTJqtVq+8Cot3t7emJmZERgY\nyOrVqxk0aFCp7j8nKysroqKiWLNmDXfu3OHw4cNcu3YtV7lQKBS8//77REREsG/fPq5cuSIPOitL\nRY2jLnkta/7+/hw6dIiVK1dy48YNvvzySy5duiR/X9ixcvDgQbZv38706dN59913adSoEdOmTSur\n7OikRJWtUqlk9uzZXLt2jc6dO7Nq1SrGjh1brG0pFApGjBgBwPjx41mxYgW9e/fG0tKSRYsWycuF\nh4fz8ssvM3r0aN555x1SU1NZtWpViU8kvXr1Yvz48QwePJgXX3yRefPmyelasmQJ1atXZ+DAgQwe\nPBgnJydWrVpVrEcpsh+RmT59Oo8fP2bp0qVyv2l2JfjFF1/oFNNBgwbx9ttvExMTw5EjR6hTpw6u\nrq5yhVW7dm05Lh988AEbN27ExMSE27dvc+PGDb7++msmTpxI1apVqVmzJqNHj+b+/fs4OjpSs2ZN\nBg4cyIMHDwDkvt+iKM2YPnjwgC5dusgxvXPnDn5+fgwaNIgGDRoQGBio07beeustbGxsWLt2LX37\n9mXx4sWcOXOGLl26MHHiRF599VXefPPNXHeb3bt359atW7z99tv88MMPLFy4UH4ULqeXX36ZhQsX\nsnPnTrp06cKcOXMICAhg6NChBaapd+/ezJo1i759+2JtbV3g42zW1tZER0fz9OlT3n33XUaNGoWX\nl5cc+9KkVCoZMWIEM2fOJDQ0tFitI/rSqFEj5s6dy4YNG+jUqRNTp05l8ODB9OrVK9dyQ4cOZdCg\nQQQHB9O3b19efPFF6tSpU0apzlLUOOqa17Lk5eXFV199xYYNG+jRowfXrl3LNc6goGMlMTGR4OBg\n+vXrR+PGjVEoFISEhPDHH38U+2avNCikSv4Uv7ZnhcuLgwcP4unpiYODA5DVX/fKK68QGRlJoNOt\nJgAAIABJREFUq1atirVNX19fhgwZIjdnF0d5jqmx8fDwIDIyEh8fn7JOiiAIJVChZ5BKS0vj6dOn\nZZ2MYnn48GGBzVfW1tZs3LiRVatWMXnyZMzNzVm1ahV2dnY0bdrUYOmq6DG1sbEpxRQJQvkgjp2S\nK7eVrS6zquzbt09+TjQ/O3fuNGQyi61///7cuHEj3++HDx/OtGnTmDFjBgMGDCAjI4PmzZuzYsWK\nIjXFPh/HwvqnynNM33333TyTGOQ0fPhwPv3002Jt29hmSzKkK1eu8O2338qTlOiTscYxIyODiIgI\n7t+/j1qtplevXrRsqf2du8ZA33HU5Xyky7FT3uKoT+W2Gfno0aPExMQwevRoYmNj+fHHH5kwYUJZ\nJ0vvtmzZwtatW9FoNLi6utKrVy9q1KhBWFgYzs7OAHTs2JG2bduyb98+9u3bh4mJCX5+fjoNaqos\ncdy6dSuHDh3C0tKS0NBQvW9fxFE/jDWOBw4c4NatW7z//vskJiby2Weflcrbr4pLxNH4lNs7W2Oa\nncaQ/vnnH1q1akV8fDyTJ0/ms88+45133qFr165069ZNXu7x48fs2rWLsLAw1Go1QUFBNGnSpNBn\nBCtLHB0dHfn0008NNm2hiKN+GGsc27RpQ+vWrYGyfV5YVyKOxqfc3tlWFqmpqfJMUM+ePWPy5Mk0\nbdqU+Ph4NBoNTk5OvP/++5w/f54///xTHtE9d+5cevbsWaQpKwVBEATDKLd3toD8ELOLi4vRP9Cs\ni4LycffuXZYvX85bb72Fra0t7du3x93dnc2bN7Nx40bq1q2ba0o3KysrkpOTSyvpAsZfHg2VLl2n\nRtVVUdOor3yV9Xb0GUdjL4v6lp1PfZdFfSrXlW22nC/rzmay7KcySIlhPHr0iOjoaF599VVatGiB\nnZ2dPPLP29ub6OhoXnrpJXm2J8iaPUrX0YHZB2Pm8O55vitvcSzKycWYD8yK8FuUhLb8Q+WKgT5o\nOzdC+Y1jfuVCb3NpG1CFqGwrsmfPnhEREcE777wjP7MaGhrKkCFDaNCgAWfPnsXd3Z0GDRqwbt06\n0tPTycjIIC4uzugn5i5NmZmZrFu3jocPH5KRkUHHjh1JS0vT20AzQRCEgojK1sjt3buXlJQU9uzZ\nI78kfdCgQaxevRoTExPs7e0ZMWIE1tbWdOrUieDgYDQajfzCASFLTEwM1tbWvPfee/JUjH369NHb\nQDNBKApx8Vf5iMrWyPn5+eH33Ku9XFxcmDFjRp5lO3ToQIcOHUoraeWKl5dXrsk+TExMuH79OvHx\n8cTExMgDza5evYqHhwdmZmaYmZnh5OTErVu3xEAzQa/ExV/lIypboVLIfq1famoqK1eupHPnznof\naJazD7ik/cHa3p2ljz5mY+6nrkzExV/lY7DKVttMIfqcjEEQiqq0BpoZagRoSbdZXkYjVwaGvvjL\n/k3ye+Fpef3NCnqBq7HnyWCV7W+//UaVKlX46KOP5JlC9DkZgyAUhRhoJhgbQ178FXZRVREfB6q0\nj/5omylE380kBV29GXPQC1Je023sxEAzwZiIi7/Kx2CVraWlJZB1JTZ//nz69u2LWq3Wax9ZQVdn\n5fHKTddmPlEhF50YaCYYE3HxV/kYdIDUgwcPmDdvHh07duS1114jKSlJr31kgiCULvHIin6Ii7/K\nx2CV7ePHj+VmkcaNGwOimUQQyjvxyIogFI/BKtstW7aQmJjIpk2b2LRpEwD+/v6imUQQyjHxyIog\nFI/BKtvBgwczePDgPJ+LZhJBKL9K63nloj6yoq9xDMa2HaHiEJNaCIJQJKX1vLKu35X123r0tR1R\nQVdsorIVhArq+TekZN8tluSNL+KRFUEoHlHZCoKgM/HIiiAUj6hsBUHQmXhkRRCKR1nWCRAEQRCE\nik7c2QoFer7fL1tJ+v0EQRAqG1HZCsUiKmFBEATdiWZkQRAEQTAwcWcr6JW444XbXVrm+awy5V8Q\nhLzEna0gCIIgGFilu7MVd16CUH5pO35vI45fwfiJO1tBEARBMLBKd2ebH3HHKwiCIBhKha1s86s8\nBUEQBKG0iWZkQRAEQTAwUdkaOR8fH/7444+yTobBJCQkcPjwYZ2X79u3L1u2bMn3e19f3wK/Ly03\n0jLpcPUZCWpNibc17k4yUQ9SC19Qi9X/pDHqdhIAe56q8bueWOL0FMfRo0fx8PAgKSkrLbGxsXh4\neHDnzp0Sb3vcnWQiIiKKte6qVasYOXIkAJs3b6ZHjx4lTk9xnDp1Kld8ikLXWCZrJKL/SWPQrUTe\neust+vXrR2RkJImJ/5aJMWPG6CWWu3fvLrNYPl/W9M3Dw4MDBw4Ueb0K24wslA/h4eGoVCpee+21\nsk6K0QpxtsJUUbx1e1cz52374r9tR19jGZo1a8bhw4dzvVBeX0KcrbAYNKhY6/bp04eePXvqOUVF\n5+npabD4ACRmSnwSl4y1Aj50sKTOFyu4ffs2ERERnDlzhgULFmBubs7nn3+OqWnxqgVjiaUhy1pJ\niMpWKBXaTtomy35CkqQySE35UtWkmDUtYKVUYKXHtBSXubk5NWvWNMi2q5ooMCnmidXKygorq7KP\nkJmZmcHiA7D8nzQkCea+YI2lUoGJszPOzs7UqVOH9957j927d9O9e3eqVq1a7H0YSywNWdZKwmgq\nW41Gw/Lly7l16xZmZmYEBATg5OSUZ7k7d+7Qvn17tm3bhq2tLZDVPBb1II3N7rZsf5LOhsfp3FdL\nOJkp6VfNnI5VzYCsZpTIB2n8lqgGoJmVKaNqWuBgqltr+rNnz5g/fz7Hjh3DxsaGIUOGMHfuXL79\n9lucnJzw8fFh4MCBbN++nWrVqrF06VJOnDjBqlWruHbtGgqFgpdeeomxY8fi5uZGQkIC/fr1IzAw\nkBUrVvDkyRNatGjBuHHjsLe3l/d7+fJl1qxZw7Vr13B1dWXmzJm0atWqRHHMKTsdy9ysqWdhUmox\nDQsL4/Tp05w+fZqDBw+yfv167ty5Q0REBKdPnyY9PR1XV1dGjBhBmzZt5PXi4uL48MMPiY2NpV69\nenz88cd4enpq3cf333/Pli1bePLkCbVr1yY2Npbo6Gjq1asHZDUdhoeHc/ToUb7//nuWL1/O3bt3\nsbW1pUGDBjRo0ICAgABsbW0JDw9nz549KBQKXnnlFaZOnYqjoyMADx8+ZNq0aRw/fpxqGWm8U8S7\nycOHD7NixQri4uKoUaMG3dTp9KmWtY1xd5LxsFQyiqymulu3buHs7MxPP/2Eubk5w4cPp0aNGixe\nvJgHDx7QsmVLpkyZghlZzchHkzNY4maTZ5/Hjh3LVTbr16/PhQsXiI6O5smTJwQHB+OhTuZ4SiZd\nq5rRwEL5bznw92fAgAG89dZbACQmJjJz5ky2b99ORkYGCoWCFi1a0LhxY54+fSp3F1hZWeHg4MDt\n21mvsh8+fDhxcXE0b96c2bNns3DhQnbu3Il9RhofOFjwqm1WOftvopqVD9OJU2uoYaKgm515rvg0\niojggw8+KFJ8LC0tWbVqFX/88QdRUVGFxifnsXvq1CmCg4Pp1KkT27dvx9fXl3HjxsnrZh9T2WUt\nc3h3tj1JZ8n9NCyVkKIBEwVkmpji7OzM66+/znfffceff/6JJEm0aNECa2trUlOzug+cnJzw8vLi\n4sWL3L17F8g61h0dHRk8eHCBZStdktj/TM0wBwsslYqsWA4eLJe1Ll260K5dOyCrGdnDw8OoYqlN\nskZiwd+pHE/OQC1By6FDGTlyJC4uLhw9ehR/f3/+/PNPbGxs8PDwYMGCBURERHDz5s1cZW337t1U\nq1aNKVOmGPx1kEbTZ3v8+HHUajWhoaH079+fNWvWFHkbV9IyWXg/jWE1LFhVx4ae9mbM/TuVO+lZ\n/WZf/p1KnFpDmIs1812tQQGT4lPILODuKnN4d/nf5317Ev/HIebPn8+UKVP45ptv0Ghy98n9sv4b\n5lVJY4I6gYShPQicOJF27dqxatUq5s+fz9OnT4mMjMy1zrJlyxgzZgxr164lISGBkJCQXN//9NNP\nDBo0iOjoaFxcXBg/fny+d4T6iGNOhohptg8//BBPT0+6d+9OZGQkkiRlHbhnjrG4BkQ6m1HvwR3C\nA6eSOqxbrni89dZbLF++nIYNGzJlyhSSk5PzbP+nn35iy5YtjB07lmXLluHl5QXAgwcP8ix74cIF\nQkJCGD9+POHh4TRt2pSYmBjatWvHmjVrmDZtGjdv3mTFihWsXbsWhULBsGHDyMjIAOCTTz7h4cOH\nLFq0iDG1LPn+cbrOMX706BHTp0+nW7durFmzhoCAAFb+k8afyRlal//vf/+LWq0mKioKX19fFixY\nQHR0NJMnT+bzzz8nJiaGHTt2FLjPhIQEAgMDc5XNnH13AE+fPuVRpoStElpZm+QqB7169SI8PFzu\nJ5w2bRq///47L7zwAl999RWvvvoqZ8+eZdeuXYSGhhIXFwdAdHQ0n3/+ubyPjz76iG+//ZZLly7R\no0cP6tWrR1RUFC9bmfDF32lIksSjDA0zElLpUtWMVbVtGOFgYZD4PPxyOiQ+I3N4d+Le70rgxIm8\n8fd1VjibMbemCU/PnybigyFZ54O5U3j69ClxcXFERUXRu3fvAuMNcDgxg0zg45qWZAJuZkrq169P\nr169WLdunbzctGnTALC1tSU0NJRGjRpx9+5dDh8+zBtvvIGtrS1WVlaYm5szffp0li9fXuB+76o1\nJEvQyMJEjmXOsrZjxw6uXLmi11jmpK2sPX8eLGosV/2Txl9qDfNcrYl0s8HExIQ5c+bku/y8efMI\nCgrKU9Z++OEHWrRowdSpUw3fyiYZiVWrVkmHDx+W/z9ixAity92+fVtSqVTS5cuX5c82bdokeXt7\nSz///LP04osvSqdOnZK/O3z4sPTkyRPpr7/+klQqlZSQkCB/l5aWJnl5eUkHDhwoNH3Xr1+XVCqV\ndPHiRfmzgwcPSiqVSrp9+7YkSZKkUqmkqKgo+fsbN25Ia9asybWdFStWSO3bt8+Vly1btsjfX7hw\nQVKpVNLVq1flbUZHR8vfHz9+XFKpVNKDBw+0plPXOOZUVjGVJEl67733pLCwMEmSJCkpKUlatmyZ\n9OjRI/n7s2fPSiqVSoqPj5ckSZJ8fHykoKCgXPt79dVXpQ0bNsjfr127VpIkSWrXrp30008/5cnn\nxIkTC8xndgyz8zlw4MAC83n16lVJpVJJsbGx8vfbt2/PVTYKcv78eUmlUkm7d++WPzt+/Lh0//79\nPDFauHCh1LJlSykjI0OSJEne9969e+V1hw8fLsdo4cKFUs+ePXPlVZK0l8358+fL5eDIkSOSSqWS\nFixYoHM5GDx4sNSvXz/p6dOnUlpamuTp6SkFBgbKaVSpVFJiYqIkSZL8/+z4fPLJJ1L37t3lbZ8+\nfVpSqVTSvXv3jCY+OY/d7PjkjEdO2o6pHj16SC+++KK0detW6cUXX5T2798vnThxQpIkSVq+fLmk\nUqmkS5cuybHJPu6XL18uNWrUSPL19ZXzk12+7t27V2hZO3HihKRSqaSbN2+Wy1hqExAQIJc1SZKk\nhIQEOZbZ28tZ1nKeQwsqa7pQqVTS/v37dU5rNqNpRk5JScnVoa1UKsnMzMTExETnbbz++us0adKE\n3r174+7uTrt27ejZsydVq1blxIkTAPzf//1fnv1ev35dbkbJz+XLlzE3N8fDw0P+rFmzZnmWc3Nz\nk/+uW7cuVlZWLFu2jCtXrnDjxg0uXrxIrVq1cq3TsuW/E9c3atQIc3NzYmNjqV+/fp5tZvepZDcv\nPU8fcczJkDF9nrW1NQMGDGD79u2cPXuWmzdvcuHCBQAyMzPl5Zo2bSr/bW5ujkqlIjY2Nte2kpKS\niI+PJzAwUL5TyG6F0DZqM2c+q1evTps2bQgICKBq1aqkpKQUmM+UlBTMzc1p2LCh/F2TJk10zveL\nL75Ix44d+fjjj3F1deXNN9+ke/fuODg4aF3excVF/j0tLCwAeOGFF+TvLS0tSU8v+M5aW9nMjnVO\n1atXB3QrBzExMaSlpdGyZUuUSiUajQaFQkFsbCxmZmao1epcv2NOlpaWucq5paUlAOnp6UYTH23H\nbs40F+b111/n0qVLTJ48GWtrawICAqhbty6+vr40aNAAgOvXr8vLz58/n4ULF6JWq9FoNFhZWREb\nG4tSqZTPDenp6YWWtWrVqgHw5MkTGjduXCFiOWTIED744APatGlDq1at8PX1LXBw1vNlK7+yZkhG\nU9laWVnJJzUASZK0VhAKRd7BItkHsKWlJevWrePkyZMcPHiQ/fv388033xAZGUlmZiZmZmb8+OOP\neda3s7MrNH2mpqY6NTNk/3CQVUH369ePtm3b0qpVK9555x1Onz6dq8koe9vZJEnKk3dtccgvLbrG\nMaeyiunzkpKS6Nu3L+bm5vznP//Bx8cHa2tr/P39cy33fH40Gg1mZmZa0x8WFsZLL70EwL179xg4\ncCCjR48uMJ+LFi3i9OnT9OrVi8jISHn7+eXzyJEj8u+WHcvn01MQhULBokWLuHTpEgcOHODXX39l\n/fr1hIaG4ufnl2d5bb+nUlm0HiFtZfPQoUMsW7YsT9pAt3Kwbds2kpOTOXbsGMePH+fgwYMcPHiQ\nVq1ayeW1oLKYXx6MJT7ajt3sCkhbmp9Xu3ZtqlatSkhICAcPHmTv3r08efKE3377jbVr1wLIsVSr\n1QQGBtK6dWs2b97MsWPHsLOzQ6FQ5CpnUHhZq127Nvb29pw9e5YmTZrkieW6devo3Lkz8+fPz7Ou\nMcRSm1atWvHrr79y6NAhDh06xKJFi1i/fj2bNm3Suvzz+ShqHvTBaPpsPTw8OHnyJJD13Fjt2rW1\nLpddsHI+Q5U92CL7RNm8eXPGjh3Ltm3b8PT05Oeff8bd3R21Wk1ycjJ16tShTp06ODg4MHv2bG7e\nvFlo+ho2bIhareby5cvyZ2fPni1wnQ0bNvDiiy+yePFiBg0ahLe3N3FxcXkqynPnzsl/nz9/HrVa\nTaNGjQpNkza6xjGnsorp8w4fPsyNGzf47rvvCAgIwMfHh3/++QfIfXFx6dIl+e/U1FQuXbok3xlk\nq1q1KjVr1uTevXty2urWrQuQ67llbfkcOXIkfn5+eHp6snHjRho0aFBgPlUqFWq1mosXL8rbPX/+\nvM75vnbtGjNnzqRRo0Z88MEHfP/993Tu3JmdO3fqHrwi0lY279+/D+QuB9mtALqUg/Xr1/P3338z\naNAgwsPDqV+/PgkJCZiamsp928VhLPHRduzmR9sxtWPHDjIyMnB2dsbV1ZXNmzfz6NEjQkND5bJZ\nr1491OqswYa1atWiTp06NGvWjNjYWJKTkzE3N0eSpFx3wIWVNRMTE7p27cratWu5ePFirljOmTMH\nhUKR65jSt5LGUptVq1Zx4sQJOnfuTFhYGBs2bODq1au5zs/GxmjubL29vTlz5gyBgYFIksSoUaO0\nLufg4ICzszMrV66kRo0aXL58mc2bNwNZd3VRUVHY29vj6+vLzZs3uXbtGu+++y7u7u74+voyYcIE\ngoODqVatGl988QXnzp2Tm2QKUqdOHXx8fAgKCiI4OJj09HRmzJgBaL+KBXB0dGTnzp3ExMTg6OjI\nL7/8wsaNG3ONNAaYM2cO9vb2mJubM23aNHx8fHSqJLXRNY45lVVMAWxsbLh16xb37t3D0dERtVrN\nzp078fb25sKFC8yaNQvI3cSzbt06GjVqROPGjVmyZAlWVlZ07do1z7aHDRvGkiVLqFWrFi+//DJb\nt24FsiqOv/76K998+vj48NNPP3Hu3Dl54MXTp0/zzWeVKlV48803mTp1KtOnTyc9PZ25c+fqlH/I\nujvetGkTVlZW9O7dm/v373Pq1CmDTgqgrWxu27YNpVLJypUr5ZGZ27ZtA3QrB1u2bGH79u2MHz+e\nrVu3yiPiDxw4QPXq1Xn48CHnz58v8l2FscRH27GbH23H1KlTp0hLS+P69etERkZy8uRJrK2tuXfv\nnjyALLtZef/+/Vy5coXatWuzYcMGUlNT+euvv/jll1945ZVXWLhwIZB1wf/VV18Vmp7Ro0dz6NAh\nAgMDuXLlCmq1Gg8PDyIiIjA1NeU///lP8YNViJLGUpt79+7xzTffYG1tjZOTE5s3b8bW1pZ69erl\nuug1lPPnz+e5W/bw8JCfTtDGaCpbpVLJiBEjdFpu9uzZzJw5k86dO9O0aVPGjh3LnDlzaNSoEXPn\nzmXJkiXMnTuX6tWrM3jwYHr16gVkTaAwe/ZsRo8eTXp6Os2aNWPVqlVUqVJFpzTOmjWLadOmMWDA\nAOzt7RkwYABffPFFvs04AwcO5PLlywQEBMjD3UNCQggKCiIhIUFerlevXowfP57ExEQ6duzI1KlT\ndUpPfvHRJY7Pr1NWMe3Xrx8TJ06ke/fu/PHHH4wdO5YvvviCxMRE6taty8SJE5kxYwbnz5+XK/Dh\nw4ezevVqrly5QpMmTVi2bBnm5nkftfH39yc1NZW5c+fy4MED+TGhnTt36pTPUaNGyRcrheVz/vz5\nhISEMGjQIKpWrcqIESNyjbotiIODA0uWLGHevHmsWbMGGxsbunTpQkBAgE7rF4e2sjl9+nQCAwO5\nfPkyv/zyC5B1kv7qq690KgehoaHs3LmTSZMmAVmtQcHBwbRs2ZJff/2VkSNHMnLkyCI/y2ks8dF2\n7OZH2zE1efJkQkND+fLLLwE4ceIEGo2G0NBQOnXqJDeBhoeH06pVKyIjI4mIiKBZs2a8+eabmJqa\nEhoaSmJiIuPHj+f69euEhobywQcfFFrWqlevzrp161iyZAkJCQl8//33QFb3QK9evXJ1rehbSWOp\nzZgxY0hNTWXs2LE8efKERo0aERUVVaLnhIti0aJFeT6bPXu21m6NbAqpJPfylUhKSgq///47r7/+\nunxiP3PmDP379+fUqVPFmnUl5zPDKpVK30kWBEEQjITR3NmWJY1GI/cN5sfOzo6pU6fSs2dP+vfv\nz5MnTwgPD6djx47Fnt6sItM1ptruSCuSihKHxMTEXAPvnmdmZlasZkERn5JRq9U8fvwYyIrlo0eP\n8ixjb28vN3mKWOYvZyzzU7169WI/2VFua4nizJSUn3/++afQuXmXLVtGREQE4eHhrFu3DktLSzp2\n7MiECROKvL+MjAx5NhPIav+vWrUqX3/9NQqFAjc3N4YOHVoqI+b0GcecdI3pG2+8Uex9ZMfx/v37\nqNVqevXqxQsvvGBUcSyNOBREW4xyPmqmqzlz5shNj9o0bdqUDRs2FHm7usTHz88PpVKptXwePnyY\nnTt3YmJigpubG8OGDUOpVDJx4kR56sCaNWtiZmaWbxnfvn07+/fvl5sgR4wYgZOTU57fs1atWvke\nKzNnzizwBRg1atSgY8eO1KpVS6dxFLo6f/48ffr00Xl5Q5Y1fdG1rOmrbGfTJZY7d+7UeTxKHkV+\nMtdIHDlyRFq8eLEkSZJ0+fJlKTw8vIxTpLv9+/dLK1eulCRJkp49eyYFBARIYWFh0rlz5yRJkqSo\nqCjp6NGjpZIWEUf9MNY4aotReVJQXNPS0qQPP/xQSk1NlSRJkr788kvp+PHjUlpamvTZZ5/ptA1J\nkqSvvvpKunbtWqH71fU3vnz5shQSEiJlZmbmSUtOEyZMkIKDg6Xg4GDp66+/lu7evSsFBgZKQUFB\n0tKlS6XMzExJkiRp79690sSJE6UpU6ZIMTExugVOkqQff/xRGjdunDRlyhSd1ylPylvZNuidbc6r\ny1q1auHn56f1rmPfvn3s27cPExMT/Pz8aNGiRaHbvnTpkjz9nkql4tq1a4bMil61adOG1q1bA/8+\nB3v9+nX5edBmzZpx+vRpvL29DZ4WEUf9MNY4aotReVJQXE1NTZkxY4b8fGb289C3bt0iLS2NmTNn\nkpmZiZ2dnTyXuLbf5saNG2zZsoXHjx/TvHlzevbsqXW/jo6Ohf7GkiQRHR3Nxx9/jFKpzJOWfv36\noVKpSE9PR5KkXFOzhoeH07dvXzw9PVm6dCkxMTGoVCp27dpFWFgYarWaoKAgmjRpotNz3I6Ojnz6\n6acsXry4CBEvP8pb2TbYAKn09HQCAwNzzVcZHh5O165d5cLk5eWFSqVixowZuQpTWFhYkSYFEARB\nKE+uXLnC4sWLqVmzplwJf/HFF0RGRqJQKDh+/DinT5/Gy8uLP//8U37CYO7cufTs2TPPc+WC8TPY\nna22Kzptdx1KpRIPDw/MzMwwMzPDycmJW7duVdrCdLuL9j4Htx0xBttnfHw8kDU1W/bfpUFf70ot\nipx5dHFx0eu2s7eb3+sEKxJDx7EsykZpevLkCW+88QZ+fn6cPn1afhwo+5l9KysrkpOTSU5OzjX9\navbnuiqL84mgncEqWwsLC7p160b79u25e/cus2fPBvRbmMqqkigrhjq5CYJQumrVqoWDgwMKhYJa\ntWphY2Mjz2YGWY8a2tjY5HrNXs7PC1PY+bCinS+z6wBjPjcarLJ1dnbGyckJhUKBi4sLtra2uaYY\nK2lhEgShbMybN4+qVauSlpZGjRo1eO+99/Q2FqOyOHLkCHfv3uWTTz7hyZMnpKam0rRpU86fP4+n\npycnT57k5ZdfpkGDBqxbt4709HQyMjKIi4sr0oT9gvEwWGV74MAB/vrrL4YNG8bDhw9JSUkRhamY\n5lu6YhcSIk5uQplTq9XywJ7su6PVq1frdWBPZdC6dWu+++47goKCUKvV9OvXT36Xb0ZGBq6urrRu\n3RqlUkmnTp0IDg5Go9HIL+oQyh+DVba+vr58/fXXBAUFoVAo+OCDD6hSpYooTEWkRoEE4uQmGIW4\nuDjS09OZOXMmKSkpdOnSRe9jMVxcXLhdwHcVRfa0ljlNnz49z2cdOnSQ56oWyi+DVbampqZ88skn\neT4Xhalo4pXmqBUKg57cBEFX5ubm+Pr6ygN7oqKiAMOMxSjqd+WRIQeaCcal3M4gVVkIWmt+AAAG\nPklEQVSYSxraqZ/wztSpBju55TzIS/OAL6u7F3FSKz5DD+wRhIpKVLZGrqakxiEjw6AnN2Mb1W3I\nNIg7iZIRA3sEoXhEZWvkjplW4a7SnDEgTm5CmRMDewSheERla+S8M56x3qKWOLkJRsHU1BR/f/88\nLQRiLIYgFExUtkbOFHgv7W/cZswQJzdBEIRyyvDvHhMEQRCESk5UtoIgCIJgYKIZWagUMjMzWbdu\nHYmJiSQnJ9OxY0fS0tIICwvD2dkZgI4dO9K2bVsxE5cgCHonKluhUoiJicHa2poJEyZw5coV5s6d\nS58+fejatSvdunWTl3v8+LGYiUsQBL0Tla1QKXh5edG0aVP5/9kvmo+PjycmJgYnJyfef/99rl69\nKmbiEgRB70RlK1QKFhYWQNZkHytXrqRz587Y2trSvn173N3d2bx5Mxs3bqRu3bolnolL28xYFXEC\njYqYJ0EwFFHZCpXGo0ePWLhwId7e3rRo0QI7Ozt5li1vb2+io6N56aWXSjwTV1G/K4/ETFyCUDRi\nNLJQKTx79oyIiAgGDBhA69atAQgNDeXq1asAnD17Fnd3dxo0aMDFixdJT08nOTlZzMQlCIJeiDtb\noVLYu3cvKSkpbNq0ibS0NAAGDRrE6tWrMTExwd7enhEjRmBtbS1m4hIEQe9EZStUCn5+fvj5+eVp\n/pwxY0aeZcVMXIIg6JtoRhYEQRAEAxOVrSAIgiAYmKhsBUEQBMHARGUrCIIgCAYmBkgJgpCvzOHd\ntX+xI6Z0EyII5Zy4sxUEQRAEAxN3toIgCEK5UJ5bWipEZXu7S8s8n5ks+6kMUiIIgiAIeYlmZEEQ\nBEEwMFHZCoIgCIKBGU0zskajYfny5dy6dQszMzMCAgJwcnIq62SVOyKOJSdiqB8ijvoh4lgxGM2d\n7fHjx1Gr1YSGhtK/f3/WrFlT1kkql0QcS07EUD9EHP+VOby71n+6EHGsGIymsr106RJeXl4AqFQq\nrl27VsYpKp9EHEtOxFA/RBz1Q8SxYjCaZuSUlBSsra3l/yuVSjIzMzExMcl3Hfml1eVg2LfOCsiL\nLi/pLlEcddyH3pTR71ZYHosTw1zbFeURKGEcK1IModTjWCHLIpT4/FiWjObO1srKipSUFPn/kiQV\nelAKeYk4lpyIoX6IOOqHiGPFYDSVrYeHBydPngQgNjaW2rVrl3GKyicRx5ITMdQPEUf9EHGsGBSS\nJEllnQj4d8TdX3/9hSRJjBo1CldX17JOVrkj4lhyIob6IeKoHyKOFYPRVLaCIAiCUFEZTTOyIAiC\nIFRUorIVBEEQBAMTla0gCIIgGJjRPGdbVJVpCrMrV67w7bffEhISUuJtFRa37du3s3//fqpWrQrA\niBEj9PL8Wn55iImJYdOmTSiVSnx8fOjQoUOJ91XYPg2RR1Ee9UPEUT9EHI1Pua1sc05hFhsby5o1\na5gwYUJZJ0vvtm7dyqFDh7C0tNTL9gqL2/Xr1/nwww9xd3fXy/4g/zxkZGSwevVqZs+ejaWlJUFB\nQbRs2RJ7e3uD7RMMk0dRHvVDxFE/RByNT7ltRq4sU5g5Ojry6aef6m17hcXtxo0bbNmyhaCgILZs\n2aKXfeaXh7i4OJycnLC1tcXU1BQPDw8uXrxo0H2CYfIoyqN+iDjqh4ij8Sm3lW1+U5hVNK1bt9br\nbDGFxa1t27YMHz6c4OBgLl26xIkTJ0q8z/zy8HxarKysSE5OLvH+CtonGCaPojzqh4ijfog4Gp9y\nW9mKKcyKp6C4SZJEly5dqFq1KqampjRv3pwbN24YNC2pqany/1NSUrCxsTHY/sBweRTlUT9EHPVD\nxNH4lNvKVkxhVjwFxS0lJYXx48eTmpqKJEmcO3dOr/2az3N1deXu3bskJiaSkZHBxYsXUalUBtsf\nGC6Pojzqh4ijfog4Gp9yO0DK29ubM2fOEBgYKE9hJhROW9wOHz5MamoqHTp0oF+/fkyfPh1TU1Ma\nN25M8+bN9Z6GnPvz9/cnNDQUjUaDj48P1atX1/v+nt+nIfIoyqN+iDjqh4ij8RHTNQqCIAiCgZXb\nZmRBEARBKC9EZSsIgiAIBiYqW0EQBEEwMFHZCoIgCIKBicpWEARBEAxMVLaCIAiCYGCishUEQRAE\nA/t/ulDkkQyDid4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeb46e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_data = data[[\"sid\",\"variable\",\"pre\",\"main\",\"sim\",\"CVS_graph\",\"sim_index\"]]\n",
    "export_data = data.copy()\n",
    "export_data.to_csv('dataframe_all_factors_by_student_x_variable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Stats tools and multicollinearity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "def eta_squared(aov):\n",
    "    aov['eta_sq'] = 'NaN'\n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    return aov\n",
    " \n",
    "def omega_squared(aov):\n",
    "    mse = aov['sum_sq'][-1]/aov['df'][-1]\n",
    "    aov['omega_sq'] = 'NaN'\n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*mse))/(sum(aov['sum_sq'])+mse)\n",
    "    return aov\n",
    "\n",
    "def clean_summary(model):\n",
    "    m = model.summary()\n",
    "    lines = m.as_text().split('\\n')\n",
    "    lines = [l for l in lines if 'C(sid)' not in l]\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# print \"Correlation coeff for table and graph CVS:\", stats.spearmanr(data['CVS_table'],data['CVS_graph'])\n",
    "# #Let's measure the variance inflation factor of including both CVS table and graph in the same models:\n",
    "# formula = 'CVS_table ~ CVS_graph + pre + C(variable) + sim_index + C(sim) '\n",
    "# print 'model: ', formula,'\\n'\n",
    "# from patsy import dmatrices\n",
    "# Y, X = dmatrices(formula, data, return_type = 'dataframe')\n",
    "# # print X.columns\n",
    "# logit = Logit(Y, X)\n",
    "# model = logit.fit()\n",
    "# print model.summary()\n",
    "# # print model.params\n",
    "# R2 = 0.4225\n",
    "# VIF = 1.0/(1-R2)\n",
    "# VIF\n",
    "\n",
    "## A VIF of 1.73 tells us that the variance (the square of the standard error) of a particular coefficient is 73% larger than it would be if that predictor was completely uncorrelated with all the other predictors. According to [this website](https://statisticalhorizons.com/multicollinearity), a VIF of 2.6 or higher is worrisome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Results to present in methods\n",
    "## Student population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study includes 148 students\n"
     ]
    }
   ],
   "source": [
    "N = len(set(data['sid']))\n",
    "print \"The study includes {0} students\".format(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Woman] 96 64.9\n",
      " [Man] 50 33.8\n",
      " [Gender non conforming/non-binary] 1 0.7\n",
      " [Trans*] 0 0.0\n",
      " [Rather specify:] 0 0.0\n",
      " [Rather specify:] [text] 0 0.0\n",
      " [Prefer not to answer] 1 0.7\n"
     ]
    }
   ],
   "source": [
    "posts = get_all_posts_surveys()\n",
    "genders = ['gender','[gender] To which gender do you most identify? [Man]','[gender] To which gender do you most identify? [Gender non conforming/non-binary]','[gender] To which gender do you most identify? [Trans*]','[gender] To which gender do you most identify? [Rather specify:]','[gender] To which gender do you most identify? [Rather specify:] [text]','[gender] To which gender do you most identify? [Prefer not to answer]']\n",
    "for g in genders:\n",
    "    if '?' in g:\n",
    "        gender = g.split('?')[1]\n",
    "    else:\n",
    "        gender = ' [Woman]'\n",
    "    print gender, len(set(posts[posts[g]==1]['sid'])), round(len(set(posts[posts[g]==1]['sid']))/float(N)*100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Student prior experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               experience_undergrad_labs\n",
      "variable                                \n",
      "Area                                 131\n",
      "Concentration                        131\n",
      "Separation                           131\n",
      "Width                                131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000000012287B00>]], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEICAYAAAADRcBUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHsVJREFUeJzt3XtYlHX+//EXxwSUq9OqDYuSGqgoihrhql1qumbl1moq\npVFGmrtZm+QufMsDaOQhqzVFQ7dcs7LtWjO7ssPmla65dmIXRfGEJ1YlU/IsoAx8fn/0c75OKo4j\n4Hy+PB9/Mfc992de89bm5dzcM/kZY4wAAPBx/lc7AAAAnqCwAABWoLAAAFagsAAAVqCwAABWoLAA\nAFagsGCl3r1766233rraMa6KgQMHavbs2Vc7RrVWrVqlmJgYj+67b98+xcTEaPv27R7dvz7/2dd3\ngVc7AOCNv//97woJCbnaMQDUIQoLVrr++uuvdgQAdYxTgvDYoUOH9Ic//EHx8fHq3r27nnvuOZ04\ncULLly9XmzZttGnTJknS8ePHdfvtt2v69OmSpIceekivvPKKUlJSFBcXpwEDBujLL790W/v1119X\nr169FB8frwceeEDr16937XvooYeUkZGh/v37q2vXrtq5c+d5p4WqOz49PV0ZGRlKT09XfHy8unbt\nquzsbNf+qqoqZWdnq2fPnoqPj1dycrJ27tzp2v/BBx+oX79+6tChg377299q9erVHs8sPT1dTz31\nlNu2c7PPnj1bY8aM0bRp05SQkKAuXbpoypQpqqysdN3/jTfe0O233674+Hi99NJL5z1GdfnS09M1\nbtw4DR48WAkJCVq3bp3OnDmjSZMm6dZbb1ViYqJycnLUt29fffPNN658M2bMUM+ePdWzZ08dO3ZM\n+fn5evjhhxUfH6/27dtr8ODBbjMuKirSI488og4dOmjAgAEqLCz0eEY/t2fPHo0ePVpdunRRu3bt\ndM8992jVqlVu9ykqKlJSUpLat2+vgQMHKi8vz7UvNzdX999/v+Li4tS9e3fNmDHDbZ6wmAE8NHTo\nUPPUU0+Zbdu2mfz8fDN8+HCTkpJijDFm1KhRZtCgQaaystKkp6ebu+++25w+fdoYY8zw4cNNbGys\nmT17ttmxY4d58cUXTWxsrNm1a5cxxpglS5aYnj17mtWrV5vdu3ebefPmmbi4OLN3716349euXWs2\nbNhgjDGmV69eZvHixR4dn5aWZmJjY82sWbNMUVGRycnJMdHR0aagoMAYY8ysWbPMbbfdZj777DOz\ne/duk5qaanr37m2cTqdZs2aN6dKli1mxYoUpKioyS5YsMe3btzf/+c9/PJpZWlqaefLJJ922nZv9\n1VdfNbGxsWb8+PFm165dZtmyZaZ169bmH//4hzHGmKVLl5qOHTuaFStWmMLCQjN27FgTHR1tXn31\nVWOMuWS+tLQ0ExMTY5YtW2Y2b95sSktLzYQJE8wdd9xhvvnmG7Nx40YzcOBAExMTY77++mtXvltv\nvdXk5+eb/Px8c+LECZOQkGCmTp1qioqKzObNm01ycrIZMGCAMcaYM2fOmF//+tfmd7/7nSksLDSf\nffaZufXWW010dLRHM9q7d6+Jjo4227ZtM1VVVaZfv34mNTXV7Ny50+zYscOMHTvW3Hbbba6/T716\n9TKxsbHm3XffNTt27DDPPfecSUhIMCdOnDBOp9MkJCSYF1980ezdu9esW7fOdOnSxbz33nseZYFv\no7Dgka+++sp07NjR9aJhjDEHDhww0dHRZvv27eb77783nTp1MuPGjTOxsbFm06ZNrvsNHz7cJCcn\nu633m9/8xsyYMcMYY0zPnj3Nhx9+6LZ/xIgRZtq0aa7jzxbjWee+6F/q+LS0NNO/f3+3/QkJCebd\nd981VVVVJjEx0SxatMi179ixY2bq1Knmxx9/NMOGDTPz5s1zO3b8+PHnldDFeFJYnTt3dpvrfffd\nZ1566SVjjDH333+/63kYY0xpaalJSEhwFdal8qWlpZk777zTte/kyZMmNjbWrFy50rVtx44dJjo6\n2q2wJk6c6Np/6NAhM3/+fFNRUeHa9umnn5rWrVsbY4xZvXq1adeunTly5Ihr/9l/FHji3MI6deqU\nWbBggdtaGzduNNHR0aa4uNiVb8KECa79p0+fNt26dTPvvfeeOXLkiImJiTELFy40VVVVxhhjNmzY\nYPbt2+dRFvg2focFj+zYsUNlZWW67bbbztu3a9cu9evXT6mpqZo8ebJGjRql2NhYt/t06dLF7XZc\nXJwKCwt16tQpFRcXa/z48Zo4caJr/5kzZxQcHOy6HRkZecFcnh7frFkzt+PCwsLkdDp15MgRHT58\nWO3bt3ftCw8PV3p6uiSpsLBQGzZsUE5Ojmt/RUWFbr755gvm8cZNN93klrVhw4aqqKhwPf7DDz/s\n2hcSEqJWrVq5bnuS79zZ7dq1SxUVFW7Pt2XLlgoPD3fLdO4xN954o4YMGaJ33nlHW7du1Z49e7R5\n82ZVVVW5MjgcDl177bWuY85d/3KEhoZq2LBh+uijj7Rx40bXY0lyO63XoUMH18/BwcGKjo7W9u3b\nNXjwYCUnJ2vq1KlasGCBbr/9dt11112Ki4vzKg98C4UFjzidTjkcDi1cuPC8fTfccIMkaevWrQoI\nCNC3336rqqoq+fv/769IAwIC3I6prKyUv7+/60Vo2rRpatu2rdt9GjRocMGff76OJ8efWwhnGWMU\nFBTk+vli6z/zzDPq1auX2/bAQM/+0/Hz8ztvm9PpdLt9NsPFjv95tnPv70m+c+dwqed7oWN++OEH\nDR48WDfffLOrAI4cOaJx48a5Mv5cdc+pOqdOnVJSUpKCg4PVt29f9erVS6GhoUpOTna738//PlVV\nVbke89lnn9WDDz6oVatWafXq1Ro1apSeeOIJjRkzxqtM8B1cdAGPtGzZUgcPHlRYWJiaN2+u5s2b\nKzAwUFOnTtXhw4f11Vdf6f3331dOTo727NmjN9980+34goIC18/GGG3cuFGtW7dWeHi4fvGLX+iH\nH35wrdu8eXMtWrTovAszLuRKj2/UqJFuuOEG17/iJam8vFzdunVTfn6+WrZsqf3797ut/dFHH2nF\nihUezS0oKEinTp1y3T516pQOHz7s0bGSFB0drQ0bNrhunzlzxu2ChsvN16xZM11zzTWuC2Skny5g\nOH78+EUzrFixQoGBgfrrX/+qlJQUde/eXQcOHJD0059ldHS09u/fr5KSEtcx587zcqxdu1a7d+/W\nO++8o9GjR6tXr1768ccfXY911tatW10/l5eXa+vWrWrVqpVKSkqUmZmpG2+8USNGjNCiRYs0atQo\nj/+84Nt4hwWPdOvWTbfccovGjh2rtLQ0BQQEKDMzU6dOnXK9ODzwwAPq0aOHnnnmGb3wwgu64447\nXKeWvvjiC7311lvq1q2b3nvvPe3bt09DhgyRJD322GOaO3euGjdurHbt2unDDz/U3/72Ny1evNij\nbFd6/COPPKJ58+bpl7/8pZo3b665c+eqYcOGat26tR577DGlpqaqRYsW6tatm/71r38pOztbM2fO\n9Gjt9u3ba/ny5frnP/+pyMhIzZ492+2dpyfZ0tLSFBsbqw4dOuj11193K7zLzRcaGqohQ4Zo+vTp\nCg8PV1hYmKZMmSLpwu+UJKlJkyYqKSnR6tWrdcstt+jbb7/VvHnzJP1UoF27dlWLFi2UlpamP/3p\nTzpw4IDmz5/v8XP8+WNVVFTo448/VkJCgjZv3qwXXnjB9VhnLVmyRK1bt1b79u01d+5chYSE6J57\n7pGfn59Wrlyp8vJyjRo1SmVlZVq7di2nBP+PoLDgEX9/f82bN09ZWVlKTk6Wv7+/unbtqj//+c96\n5ZVXdObMGT399NOSpMGDB+v999/Xc889p0WLFkmS7r77bq1cuVIzZsxQTEyM3njjDTkcDklScnKy\nysvL9eKLL6qkpEQ333yzXn31VXXq1MmjbFd6/KOPPqpTp05p/PjxOnXqlDp16qScnBzXaakJEybo\n9ddfV1ZWliIiIjR58mTdddddHq197733av369Ro7dqyuueYajRgxQkeOHPHoWEnq37+/jh8/rtmz\nZ+vw4cMaMGCAEhMTXfu9yTdu3DiVlpbq8ccfV3BwsEaPHq28vLyLnsbr37+/8vLylJ6eroqKCt1y\nyy16/vnnlZqaqk2bNqlz585asGCBJk6cqKFDh6pJkyYaMWKEZsyY4fHzPKtjx44aO3asXnrpJZ08\neVJRUVFKS0vTlClTVFBQoJYtW0qSRo4cqUWLFqmwsFBxcXFasGCB67Tv/Pnz9cILL2jgwIEKDAxU\n7969NX78+MvOAt/jZy51Mhu4Qg899JDatWuntLS0qx0Fkj7//HN17dpVDRs2lCQdPnxYXbt21apV\nq1z/iAB8Ee+wAC8dO3bM7TTVzzVo0ECNGjWqw0SemTt3rj799FONGTNGTqdTs2fPVseOHWulrCoq\nKnT06NFq73P99defdxEFcCEUFuCl1NRUrV279qL777rrLr3yyit1mMgzM2fOVFZWlgYNGiR/f391\n69ZNc+bMqZXHKigo0NChQ6u9z8cff+w61QdUh1OCAAArcFk7AMAKFBYAwApX/XdYxcXFV7yGw+Go\nkXXqim15Jfsyk7f22ZbZtrySfZlrKu/FLgDiHRYAwAoUFgDAChQWAMAKFBYAwAoUFgDAChQWAMAK\nFBYAwAoUFgDAChQWAMAKV/2bLgAA3qkc+ZurHcHditxaXZ53WAAAK1BYAAArUFgAACtQWAAAK1BY\nAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK3j0be2FhYV6++23lZGR\noT179uiNN96Qv7+/goKC9MQTT+jaa6/VypUrtXLlSgUEBGjgwIHq3LlzbWcHANQjlyys5cuXa82a\nNWrQoIEkaeHChXr00UcVFRWlzz//XMuXL9e9996rTz75RNOmTVNFRYUmTJiguLg4BQUF1foTAADU\nD5c8JdikSRONGzfOdfvpp59WVFSUJKmyslJBQUHasWOHYmJiFBQUpNDQUDVt2lRFRUW1FhoAUP9c\n8h1WYmKiDh486Lp93XXXSZK2bdumzz77TJmZmVq/fr1CQ0Nd9wkJCVFpaalHARwOx+VmrtV16opt\neSX7MpO39tmW2ba8UvWZ99ZhDk/V5oy9+j8Or1u3Tu+//77S09MVHh6u0NBQlZeXu/aXlZUpLCzM\no7WKi4u9ieDG4XDUyDp1xba8kn2ZyVv7bMtsW17Jzsw19Zp+IZd9leCaNWv06aefKiMjQ02aNJEk\ntWrVSlu2bNGZM2dUWlqq/fv3KzIy8soSAwBwjst6h1VVVaWFCxfqxhtv1MyZMyVJbdu21ZAhQ9S/\nf39NmjRJVVVVSkpKUnBwcK0EBgDUTx4VVuPGjZWVlSXpp6sEL6RPnz7q06dPzSUDAOAcfHAYAGAF\nCgsAYAUKCwBgBQoLAGAFCgsAYAUKCwBgBQoLAGAFCgsAYAUKCwBgBQoLAGAFCgsAYAUKCwBgBQoL\nAGAFCgsAYAUKCwBgBQoLAGAFCgsAYAUKCwBgBQoLAGAFCgsAYAUKCwBgBQoLAGAFCgsAYAUKCwBg\nhUBP7lRYWKi3335bGRkZOnDggLKzs+Xn56fIyEilpKTI399fK1eu1MqVKxUQEKCBAweqc+fOtZ0d\nAFCPXLKwli9frjVr1qhBgwaSpEWLFikpKUmxsbGaP3++cnNzFR0drU8++UTTpk1TRUWFJkyYoLi4\nOAUFBdX6EwAA1A+XPCXYpEkTjRs3znV7165datu2rSQpPj5e+fn52rFjh2JiYhQUFKTQ0FA1bdpU\nRUVFtZcaAFDvXPIdVmJiog4ePOi2zc/PT5IUEhKi0tJSlZaWKjQ01LX/7HZPOByOy8lb6+vUFdvy\nSvZlJm/tsy2zbXml6jPvrcMcnqrNGXv0O6xznS0rSSorK1NYWJhCQ0NVXl5+3nZPFBcXX26E8zgc\njhpZp67YlleyLzN5a59tmW3LK9mZuaZe0y/ksq8SjIqKUkFBgSQpLy9Pbdq0UatWrbRlyxadOXNG\npaWl2r9/vyIjI68sMQAA57jsd1jJycnKycmR0+lURESEEhMT5e/vr/79+2vSpEmqqqpSUlKSgoOD\nayMvAKCe8qiwGjdurKysLEk/vVXLzMw87z59+vRRnz59ajYdAAD/Hx8cBgBYgcICAFiBwgIAWIHC\nAgBYgcICAFiBwgIAWIHCAgBYgcICAFiBwgIAWIHCAgBYgcICAFiBwgIAWIHCAgBYgcICAFiBwgIA\nWIHCAgBYgcICAFiBwgIAWIHCAgBYgcICAFiBwgIAWIHCAgBYgcICAFiBwgIAWCHQm4OcTqeys7N1\n6NAh+fv76/HHH1dAQICys7Pl5+enyMhIpaSkyN+fPgQA1AyvCisvL0+VlZV6/vnnlZ+fryVLlqiy\nslJJSUmKjY3V/PnzlZubq4SEhJrOCwCop7wqrJtuuklVVVWqqqpSaWmpAgMDVVhYqLZt20qS4uPj\ntWHDBo8Ky+FweBOh1tapK7bllezLTN7aZ1tm2/JK1WfeW4c5PFWbM/aqsBo0aKBDhw5p7NixOn78\nuNLT07Vlyxb5+flJkkJCQlRaWurRWsXFxd5EcONwOGpknbpiW17JvszkrX22ZbYtr2Rn5pp6Tb8Q\nrwprxYoV6tChgx588EGVlJRo8uTJcjqdrv1lZWUKCwvzLikAABfg1VURYWFhCg0NlSQ1bNhQlZWV\nioqKUkFBgaSffsfVpk2bmksJAKj3vHqHdc8992ju3LmaOHGinE6nHnjgAbVo0UI5OTlyOp2KiIhQ\nYmJiTWcFANRjXv8OKzU19bztmZmZVxwIAIAL4YNSAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAA\nK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQ\nWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACsEenvgsmXLlJubK6fTqX79+qlt27bKzs6Wn5+f\nIiMjlZKSIn9/+hAAUDO8apSCggJt27ZNU6ZMUWZmpkpKSrRo0SIlJSVp8uTJMsYoNze3prMCAOox\nrwprw4YNatasmWbOnKnp06erc+fO2rVrl9q2bStJio+PV35+fo0GBQDUb16dEjx+/LhKSkqUnp6u\ngwcPavr06TLGyM/PT5IUEhKi0tJSj9ZyOBzeRKi1deqKbXkl+zKTt/bZltm2vFL1mffWYQ5P1eaM\nvSqsRo0aKSIiQoGBgXI4HAoODtaPP/7o2l9WVqawsDCP1iouLvYmghuHw1Ej69QV2/JK9mUmb+2z\nLbNteSU7M9fUa/qFeHVKsHXr1lq/fr2MMTp8+LDKy8vVrl07FRQUSJLy8vLUpk0b79MCAPAzXr3D\n6ty5s7Zs2aJnn31WVVVVSklJUePGjZWTkyOn06mIiAglJibWdFYAQD3m9WXtw4cPP29bZmbmFYUB\nAOBi+KAUAMAKFBYAwAoUFgDAChQWAMAKFBYAwAoUFgDAChQWAMAKFBYAwAoUFgDAChQWAMAKFBYA\nwAoUFgDAChQWAMAKFBYAwAoUFgDAChQWAMAKFBYAwAoUFgDAChQWAMAKFBYAwAoUFgDAChQWAMAK\nFBYAwAoUFgDACoFXcvCxY8eUnp6u8ePHKyAgQNnZ2fLz81NkZKRSUlLk708fAgBqhteN4nQ6NX/+\nfAUHB0uSFi1apKSkJE2ePFnGGOXm5tZYSAAAvC6sxYsXq2/fvrruuuskSbt27VLbtm0lSfHx8crP\nz6+ZhAAAyMtTgqtXr1Z4eLg6duyoDz74wLXdz89PkhQSEqLS0lKP1nI4HN5EqLV16opteSX7MpO3\n9tmW2ba8UvWZ99ZhDk/V5oy9KqxVq1ZJkjZu3Kg9e/Zozpw5OnbsmGt/WVmZwsLCPFqruLjYmwhu\nHA5HjaxTV2zLK9mXmby1z7bMtuWV7MxcU6/pF+JVYWVmZrp+zsjI0MiRI7V48WIVFBQoNjZWeXl5\nateunXdJAQC4gCu6SvBcycnJysnJkdPpVEREhBITE2tqaQAArrywMjIyXD+f+84LAICaxAelAABW\noLAAAFagsAAAVqCwAABWoLAAAFagsAAAVqCwAABWoLAAAFagsAAAVqCwAABWoLAAAFagsAAAVqCw\nAABWoLAAAFagsAAAVqCwAABWoLAAAFagsAAAVqCwAABWoLAAAFagsAAAVqCwAABWoLAAAFagsAAA\nVgj05iCn06l58+bp0KFDqqio0KBBg/TLX/5S2dnZ8vPzU2RkpFJSUuTvTx8CAGqGV4X15ZdfqlGj\nRnryySd18uRJ/fGPf1RUVJSSkpIUGxur+fPnKzc3VwkJCTWdFwBQT/kZY8zlHlReXi5jjEJCQnTi\nxAn9z//8jyoqKvTaa6/Jz89P3333nTZs2KDHHnusNjIDACTtvbvL1Y7gJnJFbq2u79U7rAYNGkiS\nysrK9PLLLyspKUmLFy+Wn5+fJCkkJESlpaUerVVcXOxNBDcOh6NG1qkrtuWV7MtM3tpnW2bb8kp2\nZq6p1/QL8fqXTCUlJcrMzFSPHj3UvXt3V1lJPxVZWFiYt0sDAHAerwrr6NGjysrK0rBhw9S7d29J\nUlRUlAoKCiRJeXl5atOmTc2lBADUe16dEly2bJlOnjyppUuXaunSpZKkRx55RAsXLpTT6VRERIQS\nExNrNCgAoH7zqrBGjBihESNGnLc9MzPzigN5w5d+8Riw4MOrHQEA/k/ig1IAACtQWAAAK1BYAAAr\nUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BY\nAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAK1BYAAArUFgAACtQWAAAKwTW5GJVVVX6y1/+oqKi\nIgUFBWn06NFq2rRpTT4EAKCeqtF3WN99950qKiqUlZWlBx98UG+++WZNLg8AqMdqtLC2bt2qjh07\nSpKio6O1c+fOmlweAFCP1egpwbKyMoWGhrpu+/v7q7KyUgEBARc9xuFwXPkDr8i98jXqWI087zpm\nW2by1j7bMtuWV7pEZh987avNGdfoO6yQkBCVlZW5bhtjqi0rAAA8VaOFFRMTo7y8PEnS9u3b1axZ\ns5pcHgBQj/kZY0xNLXb2KsH//ve/Msbo97//vSIiImpqeQBAPVajhQUAQG3hg8MAACtQWAAAK1BY\nAAAr1OjnsGrTpb72KTc3V0uXLpW/v7969eqlPn36XMW0P7lU5o8++khffPGFwsPDJUmjRo3yic+J\nFBYW6u2331ZGRobbdl+csXTxvL44X6fTqXnz5unQoUOqqKjQoEGD1KVLF9d+X5vxpfL64oyrqqr0\n2muv6fvvv5ckjRw50u2KZV+b8aXy+uKMJenYsWNKT0/X+PHj3S6uq9X5Gkt8/fXXZs6cOcYYY7Zt\n22amT5/u2ldRUWHGjBljTpw4YSoqKkx6ero5cuTI1YrqUl1mY4yZNWuW2blz59WIdlEffPCBSU1N\nNc8++6zbdl+d8cXyGuOb8/3iiy/MwoULjTHGnDhxwowePdq1zxdnXF1eY3xzxt98843Jzs42xhiz\nadMmn3+tqC6vMb4544qKCjNjxgzz1FNPmX379rltr835WnNKsLqvfdq/f7+aNm2qhg0bKjAwUDEx\nMdqyZcvViupyqa+q2r17t5YtW6YJEyZo2bJlVyPieZo0aaJx48adt91XZ3yxvJJvzrdr164aOnSo\npPM/WO+LM64ur+SbM05ISNDjjz8uSTp06JDbt+/44oyryyv55owXL16svn376rrrrnPbXtvztaaw\nLva1TxfaFxISotLS0jrP+HPVZZakX/3qVxo5cqQmTZqkrVu36t///vfViOkmMTHxgt9O4qszvlhe\nyTfn26BBA9c3wrz88stKSkpy7fPFGVeXV/LNGUtSQECA5syZo4ULF6pHjx6u7b44Y+nieSXfm/Hq\n1asVHh7u+sf4uWp7vtYUVnVf+xQSEqLy8nLXvrKyMoWFhdV5xp+rLrMxRnfffbfCw8MVGBioTp06\naffu3Vcr6iX56owvxpfnW1JSoszMTPXo0UPdu3d3bffVGV8sry/PWJLGjBmjWbNmKScnxzVXX52x\ndOG8vjjjVatWKT8/XxkZGdqzZ4/mzJmjo0ePSqr9+VpTWNV97VNERIS+//57nTx5Uk6nU1u2bFF0\ndPTViupSXeaysjI988wzKi8vlzFGmzZtUosWLa5W1Evy1RlfjK/O9+jRo8rKytKwYcPUu3dvt32+\nOOPq8vrqjNesWeM6dRYcHCw/Pz/5+//0UueLM64ury/OODMzU5mZmcrIyFBUVJTGjBmja6+9VlLt\nz9eab7q40Nc+7d69W+Xl5erTp4/rypSqqir16tVLd95559WOfMnMa9as0SeffKLAwEC1b99eQ4YM\nudqRJUkHDx7UrFmzlJWVpbVr1/r0jKWL5/XF+S5cuFDr1q1zu6rqjjvu0OnTp31yxpfK64szLi8v\n19y5c3Xs2DE5nU7dd999On36tM/+Pb5UXl+c8VkZGRkaOXJknb0WW1NYAID6zZpTggCA+o3CAgBY\ngcICAFiBwgIAWIHCAgBYgcICAFiBwgIAWOH/AR+sxowcXpNCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12287588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print 'experience in virtual labs in general'\n",
    "print pd.pivot_table(data, values=['experience_undergrad_labs'], index=['variable'],aggfunc=np.sum)[['experience_undergrad_labs']]\n",
    "pd.pivot_table(data, values=['experience_undergrad_labs'], index=['sid'],aggfunc=np.sum)[['experience_undergrad_labs']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where:\n",
      " 0 -> None\n",
      " 1 -> 1-2 (roughly)\n",
      " 2 -> 3-5 (roughly)\n",
      " 3 -> 6+ (roughly)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEICAYAAAD7pTujAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d05630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.pivot_table(data, values=['level_experience_sims'], index=['sid'],aggfunc=sum)[['level_experience_sims']].hist()\n",
    "print '''where:\n",
    " 0 -> None\n",
    " 1 -> 1-2 (roughly)\n",
    " 2 -> 3-5 (roughly)\n",
    " 3 -> 6+ (roughly)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       used_similar_sim_C  used_similar_sim_L\n",
      "count             592.000             592.000\n",
      "mean                0.044               0.166\n",
      "std                 0.205               0.372\n",
      "min                 0.000               0.000\n",
      "25%                 0.000               0.000\n",
      "50%                 0.000               0.000\n",
      "75%                 0.000               0.000\n",
      "max                 1.000               1.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x00000000139A5EB8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000012F50A20>]], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEICAYAAAADRcBUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1397fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print  'experience in virtual labs teaching light absorbance or capacitors before'\n",
    "print data[['used_similar_sim_C','used_similar_sim_L']].describe()\n",
    "pd.pivot_table(data, values=['used_similar_sim_C','used_similar_sim_L'], index=['sid'],aggfunc=np.sum)[['used_similar_sim_C','used_similar_sim_L']].hist(sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sim_index</th>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>Area</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Separation</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>Area</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Separation</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sid\n",
       "sim_index variable          \n",
       "1         Area            72\n",
       "          Concentration   76\n",
       "          Separation      72\n",
       "          Width           76\n",
       "2         Area            76\n",
       "          Concentration   72\n",
       "          Separation      76\n",
       "          Width           72"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(data, values=['sid'], index=['sim_index','variable'],aggfunc=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Learning through inquiry\n",
    "## Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "Let's look at pre to post to see if students learn.\n",
    "\n",
    "Right now we have 4 entries per student and add \"variable\" to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>main</th>\n",
       "      <th>pre</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>Area</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10127163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>Area</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10192168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>Area</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10232160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>Area</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10375163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>Area</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10420167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variable  main  pre       sid\n",
       "variable                              \n",
       "Area         Area   3.0  3.0  10127163\n",
       "Area         Area   2.0  1.0  10192168\n",
       "Area         Area   3.0  1.0  10232160\n",
       "Area         Area   3.0  1.0  10375163\n",
       "Area         Area   3.0  2.0  10420167"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.pivot_table(data, values=['pre','main'], index=['variable','sid'],aggfunc=np.mean)\n",
    "scores.reset_index(level=0, inplace=True)\n",
    "scores['sid']=scores.index\n",
    "scores.index = scores['variable']\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  -------------  ------------  ------------  -------  -----------\n",
      "Variable       pre score      main score    Sum of ranks  p-value  effect size\n",
      "Width          $1.03\\pm0.83$  $2.32pm0.75$  -10.61        0.0001   0.87\n",
      "Concentration  $1.31\\pm0.79$  $2.39pm0.64$  -9.91         0.0001   0.81\n",
      "Area           $1.24\\pm0.82$  $2.28pm0.71$  -9.51         0.0001   0.78\n",
      "Separation     $1.32\\pm0.79$  $2.19pm0.68$  -8.35         0.0001   0.69\n",
      "-------------  -------------  ------------  ------------  -------  -----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'\\\\begin{tabular}{llllll}\\n\\\\hline\\n Variable      & pre score     & main score   & Sum of ranks & p-value & effect size \\\\\\\\\\n Width         & \\\\$1.03\\\\textbackslash{}pm0.83\\\\$ & \\\\$2.32pm0.75\\\\$ & -10.61       & 0.0001  & 0.87        \\\\\\\\\\n Concentration & \\\\$1.31\\\\textbackslash{}pm0.79\\\\$ & \\\\$2.39pm0.64\\\\$ & -9.91        & 0.0001  & 0.81        \\\\\\\\\\n Area          & \\\\$1.24\\\\textbackslash{}pm0.82\\\\$ & \\\\$2.28pm0.71\\\\$ & -9.51        & 0.0001  & 0.78        \\\\\\\\\\n Separation    & \\\\$1.32\\\\textbackslash{}pm0.79\\\\$ & \\\\$2.19pm0.68\\\\$ & -8.35        & 0.0001  & 0.69        \\\\\\\\\\n\\\\hline\\n\\\\end{tabular}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [['Variable','pre score','main score','Sum of ranks','p-value','effect size']]\n",
    "for variable in ['Width','Concentration','Area','Separation']:\n",
    "    pm = round(np.mean(scores.loc[variable]['pre']),2)\n",
    "    ps = round(np.std(scores.loc[variable]['pre']),2)\n",
    "    mm = round(np.mean(scores.loc[variable]['main']),2)\n",
    "    ms = round(np.std(scores.loc[variable]['main']),2)\n",
    "    Z,p = ranksums(scores.loc[variable]['pre'],scores.loc[variable]['main'])\n",
    "    eta = round(-Z/np.sqrt(N),2)\n",
    "#     t.append([variable,str(pm)+'pm'+str(ps),str(mm)+'pm'+str(ms),round(Z,2),p,eta])\n",
    "    t.append([variable,'$'+str(pm)+'\\pm'+str(ps)+'$','$'+str(mm)+'pm'+str(ms)+'$',round(Z,2),'0.0001',eta])\n",
    "\n",
    "print tabulate(t)\n",
    "tabulate(t,tablefmt='latex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "We use Wilcoxon signed rank test since our population ares paired and dependant but ordinal values. Overall, student learn in both sims.\n",
    "\n",
    "For calculation and interpretation of effect size, read Pages 224 (bottom part) and 225 from Pallant, J. (2007). SPSS Survival Manual quoted [here](https://stats.stackexchange.com/questions/133077/effect-size-to-wilcoxon-signed-rank-test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CVS_graph_3</th>\n",
       "      <th>CVS_table_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th>CVS_levels_3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Area</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Concentration</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Separation</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Width</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            CVS_graph_3  CVS_table_3\n",
       "variable      CVS_levels_3                          \n",
       "Area          0                       0            0\n",
       "              1                       0           19\n",
       "              2                      65           65\n",
       "Concentration 0                       0            0\n",
       "              1                       0           22\n",
       "              2                      74           74\n",
       "Separation    0                       0            0\n",
       "              1                       0           15\n",
       "              2                      64           64\n",
       "Width         0                       0            0\n",
       "              1                       0           22\n",
       "              2                      66           66"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2 = pd.pivot_table(data, values=['CVS_table_3','CVS_graph_3'], index=['variable','CVS_levels_3'],aggfunc=(sum))\n",
    "# scores2.reset_index(level=0, inplace=True)\n",
    "# scores['sid']=scores.index\n",
    "# scores2.index = scores['variable']\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\hline\n",
      " ('main', 'mean') & 2.19595  & 2.39527  \\\\\n",
      " ('main', 'std')  & 0.71931  & 0.670829 \\\\\n",
      " ('pre', 'mean')  & 1.19257  & 1.25676  \\\\\n",
      " ('pre', 'std')   & 0.843768 & 0.790808 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">main</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sim_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.196</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.395</td>\n",
       "      <td>0.671</td>\n",
       "      <td>1.257</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            main           pre       \n",
       "            mean    std   mean    std\n",
       "sim_index                            \n",
       "1          2.196  0.719  1.193  0.844\n",
       "2          2.395  0.671  1.257  0.791"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores3 = pd.pivot_table(data, values=['pre','main'], index=['sim_index'],aggfunc=(np.mean,np.std))\n",
    "# scores2.reset_index(level=0, inplace=True)\n",
    "# scores['sid']=scores.index\n",
    "# scores2.index = scores['variable']\n",
    "print tabulate(scores3.transpose(),tablefmt='latex')\n",
    "scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string or a number, not 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-0d482d36fe74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Width'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Concentration'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Area'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Separation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     t.append([variable,'0 (0%)','148 (100%)',str(int(scores2.loc[variable,('CVS_table_3','sum')]))+\n\u001b[1;32m----> 4\u001b[1;33m                                 \u001b[1;34m' ('\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CVS_table_3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'%)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CVS_graph_3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                 ' ('+str(round(scores2.loc[variable,('CVS_graph_3','mean')]*100,1))+'%)',])\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string or a number, not 'DataFrame'"
     ]
    }
   ],
   "source": [
    "t = [['Variable','None','CVS-explore','CVS-table','CVS-plot']]\n",
    "for variable in ['Width','Concentration','Area','Separation']:\n",
    "    t.append([variable,'0 (0%)','148 (100%)',str(int(scores2.loc[variable,('CVS_table_3','sum')]))+\n",
    "                                ' ('+str(round(scores2.loc[variable,('CVS_table_3','mean')]*100,1))+'%)',\n",
    "                                str(int(scores2.loc[variable,('CVS_graph_3','sum')]))+\n",
    "                                ' ('+str(round(scores2.loc[variable,('CVS_graph_3','mean')]*100,1))+'%)',])\n",
    "#     pm = round(np.mean(scores.loc[variable]['pre']),2)\n",
    "#     ps = round(np.std(scores.loc[variable]['pre']),2)\n",
    "#     mm = round(np.mean(scores.loc[variable]['main']),2)\n",
    "#     ms = round(np.std(scores.loc[variable]['main']),2)\n",
    "#     Z,p = ranksums(scores.loc[variable]['pre'],scores.loc[variable]['main'])\n",
    "#     eta = round(-Z/np.sqrt(N),2)\n",
    "# #     t.append([variable,str(pm)+'pm'+str(ps),str(mm)+'pm'+str(ms),round(Z,2),p,eta])\n",
    "#     t.append([variable,'$'+str(pm)+'\\pm'+str(ps)+'$','$'+str(mm)+'pm'+str(ms)+'$',round(Z,2),'0.0001',eta])\n",
    "\n",
    "print tabulate(t)\n",
    "print tabulate(t,tablefmt='latex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation for all variables: (N=148*4)\n",
      "SpearmanrResult(correlation=0.19683704156643292, pvalue=1.390052759857402e-06)\n",
      "\n",
      "Correlation using mean pre and mean main merging both sims: (N=148)\n",
      "SpearmanrResult(correlation=0.3606523617550455, pvalue=6.7061187707435308e-06)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print \"\\nCorrelation for all variables: (N=148*4)\"\n",
    "print spearmanr(data['pre'],data['main'])\n",
    "print \"\\nCorrelation using mean pre and mean main merging both sims: (N=148)\"\n",
    "merged_scores = pd.pivot_table(data, values=['pre','main'], index=['sid'],aggfunc=np.mean)\n",
    "print spearmanr(merged_scores['pre'],merged_scores['main'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">main</th>\n",
       "      <th colspan=\"3\" halign=\"left\">pre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>len</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th>CVS_levels_3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Area</th>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.016</td>\n",
       "      <td>0.654</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.109</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.263</td>\n",
       "      <td>0.653</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.368</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2.554</td>\n",
       "      <td>0.685</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.323</td>\n",
       "      <td>0.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Concentration</th>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2.096</td>\n",
       "      <td>0.569</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.288</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2.227</td>\n",
       "      <td>0.685</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.318</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.0</td>\n",
       "      <td>2.649</td>\n",
       "      <td>0.584</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.324</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Separation</th>\n",
       "      <th>0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>2.130</td>\n",
       "      <td>0.616</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.290</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.867</td>\n",
       "      <td>0.640</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2.328</td>\n",
       "      <td>0.736</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.359</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Width</th>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.967</td>\n",
       "      <td>0.802</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2.227</td>\n",
       "      <td>0.752</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>2.667</td>\n",
       "      <td>0.536</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            main                 pre              \n",
       "                             len   mean    std   len   mean    std\n",
       "variable      CVS_levels_3                                        \n",
       "Area          0             64.0  2.016  0.654  64.0  1.109  0.758\n",
       "              1             19.0  2.263  0.653  19.0  1.368  0.761\n",
       "              2             65.0  2.554  0.685  65.0  1.323  0.903\n",
       "Concentration 0             52.0  2.096  0.569  52.0  1.288  0.667\n",
       "              1             22.0  2.227  0.685  22.0  1.318  0.995\n",
       "              2             74.0  2.649  0.584  74.0  1.324  0.813\n",
       "Separation    0             69.0  2.130  0.616  69.0  1.290  0.788\n",
       "              1             15.0  1.867  0.640  15.0  1.333  0.816\n",
       "              2             64.0  2.328  0.736  64.0  1.359  0.804\n",
       "Width         0             60.0  1.967  0.802  60.0  0.767  0.647\n",
       "              1             22.0  2.227  0.752  22.0  1.000  0.873\n",
       "              2             66.0  2.667  0.536  66.0  1.273  0.904"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.pivot_table(data, values=['pre','main'], index=['variable','CVS_levels_3'],aggfunc=(len,np.mean, np.std))\n",
    "# e= pd.pivot_table(data, values=['pre','main'], index=['variable','CVS_graph_3'],aggfunc=(np.mean, np.std))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_points_table</th>\n",
       "      <th>number_points_graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>592.000</td>\n",
       "      <td>592.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.949</td>\n",
       "      <td>3.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.738</td>\n",
       "      <td>3.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_points_table  number_points_graph\n",
       "count              592.000              592.000\n",
       "mean                 3.949                3.014\n",
       "std                  3.738                3.756\n",
       "min                  0.000                0.000\n",
       "25%                  0.000                0.000\n",
       "50%                  3.000                0.000\n",
       "75%                  6.000                5.000\n",
       "max                 23.000               23.000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['number_points_table', 'number_points_graph']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Does using strategy help student learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Using different levels of CVS and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>variable</th>\n",
       "      <th>pre</th>\n",
       "      <th>main</th>\n",
       "      <th>sim</th>\n",
       "      <th>CVS_table_2</th>\n",
       "      <th>CVS_graph_2</th>\n",
       "      <th>CVS_table_3</th>\n",
       "      <th>CVS_graph_3</th>\n",
       "      <th>CVS_table_4</th>\n",
       "      <th>...</th>\n",
       "      <th>use_graph</th>\n",
       "      <th>level_experience_sims</th>\n",
       "      <th>experience_undergrad_labs</th>\n",
       "      <th>used_similar_sim_L</th>\n",
       "      <th>used_similar_sim_C</th>\n",
       "      <th>used_similar_sim</th>\n",
       "      <th>CVS_levels_2</th>\n",
       "      <th>CVS_levels_3</th>\n",
       "      <th>CVS_levels_4</th>\n",
       "      <th>CVS_levels_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10127163</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10232160</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10537160</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10375163</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10420167</td>\n",
       "      <td>Concentration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sid       variable  pre  main sim  CVS_table_2  CVS_graph_2  CVS_table_3  CVS_graph_3  \\\n",
       "0  10127163  Concentration  1.0   3.0   L            1            1            1            1   \n",
       "1  10232160  Concentration  1.0   1.0   L            1            1            1            1   \n",
       "2  10537160  Concentration  1.0   2.0   L            1            0            1            0   \n",
       "3  10375163  Concentration  0.0   2.0   L            1            0            1            0   \n",
       "4  10420167  Concentration  1.0   3.0   L            1            1            1            1   \n",
       "\n",
       "   CVS_table_4      ...       use_graph  level_experience_sims  experience_undergrad_labs  \\\n",
       "0            1      ...               1                      1                          1   \n",
       "1            1      ...               1                      1                          1   \n",
       "2            0      ...               0                      1                          1   \n",
       "3            1      ...               1                      2                          1   \n",
       "4            1      ...               1                      3                          1   \n",
       "\n",
       "   used_similar_sim_L  used_similar_sim_C  used_similar_sim  CVS_levels_2  CVS_levels_3  \\\n",
       "0                 0.0                 0.0               0.0             2             2   \n",
       "1                 1.0                 0.0               1.0             2             2   \n",
       "2                 1.0                 0.0               1.0             1             1   \n",
       "3                 0.0                 0.0               0.0             1             1   \n",
       "4                 0.0                 0.0               0.0             2             2   \n",
       "\n",
       "   CVS_levels_4  CVS_levels_5  \n",
       "0             2             2  \n",
       "1             2             0  \n",
       "2             0             0  \n",
       "3             1             1  \n",
       "4             2             2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8 control variables:\n",
    "* sim_index\n",
    "* sim\n",
    "* variable\n",
    "* pre\n",
    "* level_experience_sims\n",
    "* experience_undergrad_labs\n",
    "* used_similar_sim\n",
    "* use_graph\n",
    "\n",
    "We look at all interactions with CVS levels given our RQ are related to CVS usage:\n",
    "* variable*CVS_levels\n",
    "* pre*CVS_levels\n",
    "* sim_index*CVS_levels\n",
    "* sim (exclude becasue already within variable?)\n",
    "* C(sid)\n",
    "* level_experience_sims\n",
    "* experience_undergrad_labs\n",
    "* used_similar_sim\n",
    "* use_graph\n",
    "\n",
    "\n",
    "*NOTE:* we don't include variable and sim in the same model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first remove students with max pre for a certain variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 27)\n",
      "(553, 27)\n",
      "(551, 27)\n"
     ]
    }
   ],
   "source": [
    "print data.shape\n",
    "filtered_maxpre_data = data.copy()\n",
    "filtered_maxpre_data = filtered_maxpre_data[filtered_maxpre_data['pre']<3]\n",
    "#remove student who didn't do CVS-explore for 2 variables\n",
    "print filtered_maxpre_data.shape\n",
    "# print filtered_maxpre_data.describe()\n",
    "filtered_maxpre_data = filtered_maxpre_data[(filtered_maxpre_data['sid']!= 11384795)|(filtered_maxpre_data['variable'].isin(['Width','Concentration']))]\n",
    "# print filtered_maxpre_data[filtered_maxpre_data['sid']==11384795]\n",
    "# filtered_maxpre_data = filtered_maxpre_data[(filtered_maxpre_data['sid']!= 11384795)&(filtered_maxpre_data['variable']=='Separation')]\n",
    "print filtered_maxpre_data.shape\n",
    "# print filtered_maxpre_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariates_for_interaction_model = \" + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\"\n",
    "covariates_for_parsimonious_model = \"+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3) + variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "\n",
      "Anova table using type 3\n",
      "\n",
      "                            sum_sq     df        F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   31.492    1.0  118.682  2.419e-24  9.747e-02  9.657e-02\n",
      "C(CVS_levels_3)              5.499    2.0   10.362  4.112e-05  1.702e-02  1.537e-02\n",
      "variable                     1.995    3.0    2.507  5.863e-02  6.176e-03  3.709e-03\n",
      "C(sid)                     175.163  147.0    4.491  1.052e-32  5.422e-01  4.211e-01\n",
      "pre                          0.028    1.0    0.106  7.448e-01  8.713e-05 -7.336e-04\n",
      "sim_index                    3.019    1.0   11.378  8.165e-04  9.345e-03  8.517e-03\n",
      "level_experience_sims        0.413    1.0    1.556  2.130e-01  1.278e-03  4.564e-04\n",
      "experience_undergrad_labs    0.623    1.0    2.348  1.263e-01  1.928e-03  1.106e-03\n",
      "used_similar_sim             0.032    1.0    0.120  7.287e-01  9.893e-05 -7.218e-04\n",
      "Residual                   104.811  395.0      NaN        NaN        NaN        NaN\n",
      "\n",
      "Here is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.598\n",
      "Model:                            OLS   Adj. R-squared:                  0.440\n",
      "Method:                 Least Squares   F-statistic:                     3.790\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           1.21e-26\n",
      "Time:                        15:57:06   Log-Likelihood:                -324.62\n",
      "No. Observations:                 551   AIC:                             961.2\n",
      "Df Residuals:                     395   BIC:                             1634.\n",
      "Df Model:                         155                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     2.0294      0.186     10.894      0.000       1.663       2.396\n",
      "C(CVS_levels_3)[T.1]         -0.0356      0.095     -0.374      0.709      -0.223       0.152\n",
      "C(CVS_levels_3)[T.2]          0.3539      0.085      4.147      0.000       0.186       0.522\n",
      "variable[T.Concentration]     0.1207      0.067      1.799      0.073      -0.011       0.253\n",
      "variable[T.Separation]       -0.0621      0.063     -0.986      0.325      -0.186       0.062\n",
      "variable[T.Width]             0.0410      0.066      0.616      0.538      -0.090       0.172\n",
      "pre                          -0.0150      0.046     -0.326      0.745      -0.106       0.076\n",
      "sim_index                     0.1572      0.047      3.373      0.001       0.066       0.249\n",
      "level_experience_sims        -0.2512      0.201     -1.247      0.213      -0.647       0.145\n",
      "experience_undergrad_labs     0.6448      0.421      1.532      0.126      -0.183       1.472\n",
      "used_similar_sim             -0.0307      0.089     -0.347      0.729      -0.205       0.143\n",
      "==============================================================================\n",
      "Omnibus:                       72.336   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              220.656\n",
      "Skew:                          -0.614   Prob(JB):                     1.22e-48\n",
      "Kurtosis:                       5.846   Cond. No.                     7.99e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.21e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "formula = 'main ~ C(CVS_levels_3) '+ covariates_for_parsimonious_model\n",
    "model = ols(formula, filtered_maxpre_data).fit()\n",
    "print \"\\n\\nModel: \",formula\n",
    "aov_table = anova_lm(model, typ=3)\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print \"\\nAnova table using type 3\\n\"\n",
    "print(aov_table)\n",
    "print \"\\nHere is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\\n\"\n",
    "print clean_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\hline\n",
      " Intercept                 & 118.68 &   0    &   0.1  \\\\\n",
      " sim\\_index                 &  11.38 &   0    &   0.01 \\\\\n",
      " C(CVS\\_levels\\_3)           &  10.36 &   0    &   0.02 \\\\\n",
      " C(sid)                    &   4.49 &   0    &   0.54 \\\\\n",
      " variable                  &   2.51 &   0.06 &   0.01 \\\\\n",
      " experience\\_undergrad\\_labs &   2.35 &   0.13 &   0    \\\\\n",
      " level\\_experience\\_sims     &   1.56 &   0.21 &   0    \\\\\n",
      " used\\_similar\\_sim          &   0.12 &   0.73 &   0    \\\\\n",
      " pre                       &   0.11 &   0.74 &   0    \\\\\n",
      " Residual                  & nan    & nan    & nan    \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\applications\\anaconda2\\lib\\site-packages\\pandas\\core\\series.py:1295: RuntimeWarning: invalid value encountered in rint\n",
      "  result = _values_from_object(self).round(decimals)\n"
     ]
    }
   ],
   "source": [
    "# aov_table = aov_table.round({'F': 2,'eta_sq':2})\n",
    "# print tabulate(aov_table[['F','PR(>F)','eta_sq']].sort_values('F',ascending =False),tablefmt='latex')\n",
    "aov_table = aov_table.round({'F': 2, 'PR(>F)': 2,'eta_sq':2})\n",
    "print tabulate(aov_table[['F','PR(>F)','eta_sq']].sort_values('F',ascending =False),tablefmt='latex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print(model.summary().as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis on CVS criteria using BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_2)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "\n",
      "Anova table using type 3\n",
      "\n",
      "                            sum_sq     df        F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   28.808    1.0  108.580  1.265e-22  9.069e-02  8.978e-02\n",
      "C(CVS_levels_2)              5.511    2.0   10.387  4.015e-05  1.735e-02  1.567e-02\n",
      "variable                     2.294    3.0    2.882  3.571e-02  7.221e-03  4.711e-03\n",
      "C(sid)                     171.641  147.0    4.401  7.315e-32  5.403e-01  4.172e-01\n",
      "pre                          0.053    1.0    0.201  6.544e-01  1.676e-04 -6.671e-04\n",
      "sim_index                    3.357    1.0   12.653  4.206e-04  1.057e-02  9.724e-03\n",
      "level_experience_sims        0.447    1.0    1.686  1.949e-01  1.408e-03  5.724e-04\n",
      "experience_undergrad_labs    0.704    1.0    2.654  1.041e-01  2.216e-03  1.380e-03\n",
      "used_similar_sim             0.038    1.0    0.145  7.037e-01  1.210e-04 -7.137e-04\n",
      "Residual                   104.798  395.0      NaN        NaN        NaN        NaN\n",
      "\n",
      "Here is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.598\n",
      "Model:                            OLS   Adj. R-squared:                  0.440\n",
      "Method:                 Least Squares   F-statistic:                     3.791\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           1.19e-26\n",
      "Time:                        14:14:16   Log-Likelihood:                -324.59\n",
      "No. Observations:                 551   AIC:                             961.2\n",
      "Df Residuals:                     395   BIC:                             1634.\n",
      "Df Model:                         155                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.9716      0.189     10.420      0.000       1.600       2.344\n",
      "C(CVS_levels_2)[T.1]          0.0730      0.090      0.807      0.420      -0.105       0.251\n",
      "C(CVS_levels_2)[T.2]          0.3733      0.084      4.439      0.000       0.208       0.539\n",
      "variable[T.Concentration]     0.1326      0.067      1.984      0.048       0.001       0.264\n",
      "variable[T.Separation]       -0.0615      0.063     -0.976      0.330      -0.185       0.062\n",
      "variable[T.Width]             0.0447      0.066      0.672      0.502      -0.086       0.175\n",
      "pre                          -0.0206      0.046     -0.448      0.654      -0.111       0.070\n",
      "sim_index                     0.1651      0.046      3.557      0.000       0.074       0.256\n",
      "level_experience_sims        -0.2612      0.201     -1.298      0.195      -0.657       0.134\n",
      "experience_undergrad_labs     0.6832      0.419      1.629      0.104      -0.141       1.508\n",
      "used_similar_sim             -0.0337      0.089     -0.381      0.704      -0.208       0.140\n",
      "==============================================================================\n",
      "Omnibus:                       70.541   Durbin-Watson:                   1.923\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              205.656\n",
      "Skew:                          -0.613   Prob(JB):                     2.20e-45\n",
      "Kurtosis:                       5.730   Cond. No.                     7.83e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.62e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "\n",
      "Anova table using type 3\n",
      "\n",
      "                            sum_sq     df        F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   31.492    1.0  118.682  2.419e-24  9.747e-02  9.657e-02\n",
      "C(CVS_levels_3)              5.499    2.0   10.362  4.112e-05  1.702e-02  1.537e-02\n",
      "variable                     1.995    3.0    2.507  5.863e-02  6.176e-03  3.709e-03\n",
      "C(sid)                     175.163  147.0    4.491  1.052e-32  5.422e-01  4.211e-01\n",
      "pre                          0.028    1.0    0.106  7.448e-01  8.713e-05 -7.336e-04\n",
      "sim_index                    3.019    1.0   11.378  8.165e-04  9.345e-03  8.517e-03\n",
      "level_experience_sims        0.413    1.0    1.556  2.130e-01  1.278e-03  4.564e-04\n",
      "experience_undergrad_labs    0.623    1.0    2.348  1.263e-01  1.928e-03  1.106e-03\n",
      "used_similar_sim             0.032    1.0    0.120  7.287e-01  9.893e-05 -7.218e-04\n",
      "Residual                   104.811  395.0      NaN        NaN        NaN        NaN\n",
      "\n",
      "Here is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.598\n",
      "Model:                            OLS   Adj. R-squared:                  0.440\n",
      "Method:                 Least Squares   F-statistic:                     3.790\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           1.21e-26\n",
      "Time:                        14:14:16   Log-Likelihood:                -324.62\n",
      "No. Observations:                 551   AIC:                             961.2\n",
      "Df Residuals:                     395   BIC:                             1634.\n",
      "Df Model:                         155                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     2.0294      0.186     10.894      0.000       1.663       2.396\n",
      "C(CVS_levels_3)[T.1]         -0.0356      0.095     -0.374      0.709      -0.223       0.152\n",
      "C(CVS_levels_3)[T.2]          0.3539      0.085      4.147      0.000       0.186       0.522\n",
      "variable[T.Concentration]     0.1207      0.067      1.799      0.073      -0.011       0.253\n",
      "variable[T.Separation]       -0.0621      0.063     -0.986      0.325      -0.186       0.062\n",
      "variable[T.Width]             0.0410      0.066      0.616      0.538      -0.090       0.172\n",
      "pre                          -0.0150      0.046     -0.326      0.745      -0.106       0.076\n",
      "sim_index                     0.1572      0.047      3.373      0.001       0.066       0.249\n",
      "level_experience_sims        -0.2512      0.201     -1.247      0.213      -0.647       0.145\n",
      "experience_undergrad_labs     0.6448      0.421      1.532      0.126      -0.183       1.472\n",
      "used_similar_sim             -0.0307      0.089     -0.347      0.729      -0.205       0.143\n",
      "==============================================================================\n",
      "Omnibus:                       72.336   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              220.656\n",
      "Skew:                          -0.614   Prob(JB):                     1.22e-48\n",
      "Kurtosis:                       5.846   Cond. No.                     7.99e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.21e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_4)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "\n",
      "Anova table using type 3\n",
      "\n",
      "                            sum_sq     df        F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   32.006    1.0  119.725  1.616e-24  9.841e-02  9.751e-02\n",
      "C(CVS_levels_4)              4.715    2.0    8.819  1.791e-04  1.450e-02  1.284e-02\n",
      "variable                     2.002    3.0    2.496  5.948e-02  6.154e-03  3.685e-03\n",
      "C(sid)                     176.762  147.0    4.498  8.979e-33  5.435e-01  4.223e-01\n",
      "pre                          0.036    1.0    0.135  7.136e-01  1.109e-04 -7.105e-04\n",
      "sim_index                    3.057    1.0   11.437  7.917e-04  9.401e-03  8.572e-03\n",
      "level_experience_sims        0.412    1.0    1.542  2.151e-01  1.267e-03  4.450e-04\n",
      "experience_undergrad_labs    0.617    1.0    2.309  1.294e-01  1.898e-03  1.075e-03\n",
      "used_similar_sim             0.019    1.0    0.071  7.897e-01  5.854e-05 -7.628e-04\n",
      "Residual                   105.595  395.0      NaN        NaN        NaN        NaN\n",
      "\n",
      "Here is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.595\n",
      "Model:                            OLS   Adj. R-squared:                  0.436\n",
      "Method:                 Least Squares   F-statistic:                     3.743\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           3.61e-26\n",
      "Time:                        14:14:17   Log-Likelihood:                -326.67\n",
      "No. Observations:                 551   AIC:                             965.3\n",
      "Df Residuals:                     395   BIC:                             1638.\n",
      "Df Model:                         155                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     2.0384      0.186     10.942      0.000       1.672       2.405\n",
      "C(CVS_levels_4)[T.1]          0.0044      0.123      0.036      0.972      -0.238       0.247\n",
      "C(CVS_levels_4)[T.2]          0.3520      0.089      3.976      0.000       0.178       0.526\n",
      "variable[T.Concentration]     0.1162      0.068      1.716      0.087      -0.017       0.249\n",
      "variable[T.Separation]       -0.0683      0.063     -1.081      0.281      -0.192       0.056\n",
      "variable[T.Width]             0.0351      0.067      0.522      0.602      -0.097       0.168\n",
      "pre                          -0.0170      0.046     -0.367      0.714      -0.108       0.074\n",
      "sim_index                     0.1583      0.047      3.382      0.001       0.066       0.250\n",
      "level_experience_sims        -0.2511      0.202     -1.242      0.215      -0.649       0.146\n",
      "experience_undergrad_labs     0.6437      0.424      1.520      0.129      -0.189       1.477\n",
      "used_similar_sim             -0.0238      0.089     -0.267      0.790      -0.199       0.152\n",
      "==============================================================================\n",
      "Omnibus:                       70.004   Durbin-Watson:                   1.939\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              209.620\n",
      "Skew:                          -0.599   Prob(JB):                     3.03e-46\n",
      "Kurtosis:                       5.774   Cond. No.                     7.30e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.82e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_5)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "\n",
      "Anova table using type 3\n",
      "\n",
      "                            sum_sq     df        F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   31.962    1.0  116.138  6.504e-24  9.631e-02  9.540e-02\n",
      "C(CVS_levels_5)              1.603    2.0    2.912  5.554e-02  4.829e-03  3.168e-03\n",
      "variable                     2.259    3.0    2.736  4.331e-02  6.807e-03  4.315e-03\n",
      "C(sid)                     181.894  147.0    4.496  9.360e-33  5.481e-01  4.258e-01\n",
      "pre                          0.003    1.0    0.009  9.231e-01  7.746e-06 -8.208e-04\n",
      "sim_index                    3.902    1.0   14.178  1.916e-04  1.176e-02  1.092e-02\n",
      "level_experience_sims        0.526    1.0    1.910  1.678e-01  1.584e-03  7.539e-04\n",
      "experience_undergrad_labs    0.953    1.0    3.461  6.356e-02  2.870e-03  2.039e-03\n",
      "used_similar_sim             0.067    1.0    0.245  6.210e-01  2.030e-04 -6.257e-04\n",
      "Residual                   108.707  395.0      NaN        NaN        NaN        NaN\n",
      "\n",
      "Here is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.583\n",
      "Model:                            OLS   Adj. R-squared:                  0.419\n",
      "Method:                 Least Squares   F-statistic:                     3.563\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           2.42e-24\n",
      "Time:                        14:14:17   Log-Likelihood:                -334.68\n",
      "No. Observations:                 551   AIC:                             981.4\n",
      "Df Residuals:                     395   BIC:                             1654.\n",
      "Df Model:                         155                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     2.0377      0.189     10.777      0.000       1.666       2.409\n",
      "C(CVS_levels_5)[T.1]          0.0080      0.131      0.061      0.951      -0.249       0.265\n",
      "C(CVS_levels_5)[T.2]          0.1916      0.083      2.311      0.021       0.029       0.355\n",
      "variable[T.Concentration]     0.1281      0.069      1.857      0.064      -0.008       0.264\n",
      "variable[T.Separation]       -0.0677      0.064     -1.056      0.291      -0.194       0.058\n",
      "variable[T.Width]             0.0387      0.068      0.566      0.571      -0.096       0.173\n",
      "pre                          -0.0045      0.047     -0.097      0.923      -0.096       0.087\n",
      "sim_index                     0.1778      0.047      3.765      0.000       0.085       0.271\n",
      "level_experience_sims        -0.2840      0.205     -1.382      0.168      -0.688       0.120\n",
      "experience_undergrad_labs     0.7981      0.429      1.860      0.064      -0.045       1.641\n",
      "used_similar_sim             -0.0447      0.090     -0.495      0.621      -0.222       0.133\n",
      "==============================================================================\n",
      "Omnibus:                       66.566   Durbin-Watson:                   1.934\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              198.121\n",
      "Skew:                          -0.570   Prob(JB):                     9.52e-44\n",
      "Kurtosis:                       5.707   Cond. No.                     8.19e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.73e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "for CVS in ['CVS_levels_2','CVS_levels_3','CVS_levels_4','CVS_levels_5']:\n",
    "    formula = 'main ~ C('+CVS+')' + covariates_for_parsimonious_model\n",
    "    model = ols(formula, filtered_maxpre_data).fit()\n",
    "    print \"\\n\\nModel: \",formula\n",
    "    aov_table = anova_lm(model, typ=3)\n",
    "    eta_squared(aov_table)\n",
    "    omega_squared(aov_table)\n",
    "    print \"\\nAnova table using type 3\\n\"\n",
    "    print(aov_table)\n",
    "    print \"\\nHere is the linear model with coefficients and confidence intervals (removed stats for individual student ids):\\n\"\n",
    "    print clean_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results were produced using AOV of linear regression with Type III SS\n",
    "\n",
    "We think a threshold of 3 pts is stricks a balance between 1) measuring more deliberatness than 2 pts and 2) it is less stringent than using more points.\n",
    "\n",
    "Here are the AIC and BIC of the models (lower means better model controlling for number of parameters)\n",
    "\n",
    "\n",
    "    no interactions\n",
    "    #pts\tR^2\n",
    "    2\t\t0.449\n",
    "    3\t\t0.447\n",
    "    4\t\t0.443\n",
    "    5\t\t0.428\n",
    "\n",
    "None of these models are drastically different from each other, thought 5pts is definitely the worst\n",
    "\n",
    "We pick #pts = 3 and call it a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Concentration', 'Width', 'Area', 'Separation'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['variable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\hline\n",
      " Threshold & Concentration & Width & Area & Separation & \\$R\\^{}2\\$ \\\\\n",
      " 2         & 0.52          & 0.48  & 0.49 & 0.48       & 0.449 \\\\\n",
      " 3         & 0.5           & 0.45  & 0.44 & 0.43       & 0.447 \\\\\n",
      " 4         & 0.47          & 0.43  & 0.41 & 0.41       & 0.443 \\\\\n",
      " 5         & 0.39          & 0.32  & 0.31 & 0.32       & 0.428 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "results = [['Threshold','Concentration ','Width ','Area ','Separation','$R^2$']]\n",
    "for t,r in zip([2,3,4,5],[0.449,0.447,0.443,0.428]):\n",
    "    res = [t]\n",
    "    res.extend([round(sum(data[data['variable']==v]['CVS_graph_'+str(t)])/float(N),2) for v in ['Concentration','Width','Area','Separation']])\n",
    "    res.append(r)\n",
    "    results.append(res)\n",
    "print tabulate(results,tablefmt='latex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This plot needs to be redone with standard deviation bars and organized by sim, colored by level\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAFNCAYAAAC6+ZDPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHkpxEO0/1rUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6aa5438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_variable = pd.pivot_table(filtered_maxpre_data, values=['main'], index=['variable','CVS_levels_3'],aggfunc=(np.mean))\n",
    "per_variable.plot(kind='bar')\n",
    "print \"This plot needs to be redone with standard deviation bars and organized by sim, colored by level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_for_variable_models = \" + pre + sim_index + level_experience_sims + experience_undergrad_labs + used_similar_sim + use_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________\n",
      "FOR VARIABLE  Width \n",
      "__________________________________\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3) + pre + sim_index + level_experience_sims + experience_undergrad_labs + used_similar_sim + use_graph\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                           sum_sq     df       F     PR(>F)     eta_sq  omega_sq\n",
      "Intercept                  20.425    1.0  42.688  1.276e-09  2.099e-01     0.204\n",
      "C(CVS_levels_3)            10.893    2.0  11.383  2.749e-05  1.119e-01     0.102\n",
      "pre                         0.055    1.0   0.115  7.353e-01  5.645e-04    -0.004\n",
      "sim_index                   1.125    1.0   2.351  1.276e-01  1.156e-02     0.007\n",
      "level_experience_sims       0.033    1.0   0.068  7.940e-01  3.366e-04    -0.005\n",
      "experience_undergrad_labs   0.765    1.0   1.599  2.082e-01  7.863e-03     0.003\n",
      "used_similar_sim            0.748    1.0   1.564  2.134e-01  7.687e-03     0.003\n",
      "use_graph                   0.115    1.0   0.239  6.254e-01  1.177e-03    -0.004\n",
      "Residual                   63.159  132.0     NaN        NaN        NaN       NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.221\n",
      "Model:                            OLS   Adj. R-squared:                  0.174\n",
      "Method:                 Least Squares   F-statistic:                     4.681\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           4.61e-05\n",
      "Time:                        16:51:30   Log-Likelihood:                -143.45\n",
      "No. Observations:                 141   AIC:                             304.9\n",
      "Df Residuals:                     132   BIC:                             331.4\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.8347      0.281      6.534      0.000       1.279       2.390\n",
      "C(CVS_levels_3)[T.1]          0.2871      0.182      1.574      0.118      -0.074       0.648\n",
      "C(CVS_levels_3)[T.2]          0.6856      0.144      4.761      0.000       0.401       0.970\n",
      "pre                           0.0284      0.084      0.339      0.735      -0.137       0.194\n",
      "sim_index                     0.1864      0.122      1.533      0.128      -0.054       0.427\n",
      "level_experience_sims         0.0181      0.069      0.262      0.794      -0.119       0.155\n",
      "experience_undergrad_labs    -0.2631      0.208     -1.265      0.208      -0.675       0.148\n",
      "used_similar_sim             -0.1656      0.132     -1.250      0.213      -0.428       0.096\n",
      "use_graph                     0.0856      0.175      0.489      0.625      -0.260       0.431\n",
      "==============================================================================\n",
      "Omnibus:                       22.283   Durbin-Watson:                   2.272\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.771\n",
      "Skew:                          -0.913   Prob(JB):                     5.66e-07\n",
      "Kurtosis:                       4.252   Cond. No.                         16.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "__________________________________\n",
      "FOR VARIABLE  Concentration \n",
      "__________________________________\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3) + pre + sim_index + level_experience_sims + experience_undergrad_labs + used_similar_sim + use_graph\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                           sum_sq     df       F     PR(>F)  eta_sq   omega_sq\n",
      "Intercept                  17.001    1.0  50.496  7.624e-11   0.241  2.347e-01\n",
      "C(CVS_levels_3)             8.160    2.0  12.119  1.525e-05   0.115  1.054e-01\n",
      "pre                         0.320    1.0   0.949  3.318e-01   0.005 -2.409e-04\n",
      "sim_index                   1.479    1.0   4.393  3.807e-02   0.021  1.609e-02\n",
      "level_experience_sims       0.196    1.0   0.581  4.473e-01   0.003 -1.987e-03\n",
      "experience_undergrad_labs   0.172    1.0   0.512  4.756e-01   0.002 -2.315e-03\n",
      "used_similar_sim            0.391    1.0   1.163  2.830e-01   0.006  7.712e-04\n",
      "use_graph                   0.189    1.0   0.563  4.546e-01   0.003 -2.074e-03\n",
      "Residual                   42.758  127.0     NaN        NaN     NaN        NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.227\n",
      "Model:                            OLS   Adj. R-squared:                  0.179\n",
      "Method:                 Least Squares   F-statistic:                     4.674\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           4.95e-05\n",
      "Time:                        16:51:31   Log-Likelihood:                -114.29\n",
      "No. Observations:                 136   AIC:                             246.6\n",
      "Df Residuals:                     127   BIC:                             272.8\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.8221      0.256      7.106      0.000       1.315       2.330\n",
      "C(CVS_levels_3)[T.1]          0.0359      0.165      0.218      0.828      -0.291       0.363\n",
      "C(CVS_levels_3)[T.2]          0.5798      0.124      4.669      0.000       0.334       0.826\n",
      "pre                           0.0786      0.081      0.974      0.332      -0.081       0.238\n",
      "sim_index                     0.2158      0.103      2.096      0.038       0.012       0.420\n",
      "level_experience_sims         0.0460      0.060      0.762      0.447      -0.073       0.165\n",
      "experience_undergrad_labs    -0.1284      0.179     -0.715      0.476      -0.483       0.227\n",
      "used_similar_sim             -0.1214      0.113     -1.078      0.283      -0.344       0.101\n",
      "use_graph                    -0.1137      0.152     -0.750      0.455      -0.414       0.186\n",
      "==============================================================================\n",
      "Omnibus:                       11.765   Durbin-Watson:                   1.932\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               12.190\n",
      "Skew:                          -0.671   Prob(JB):                      0.00225\n",
      "Kurtosis:                       3.593   Cond. No.                         18.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "__________________________________\n",
      "FOR VARIABLE  Area \n",
      "__________________________________\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3) + pre + sim_index + level_experience_sims + experience_undergrad_labs + used_similar_sim + use_graph\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                              sum_sq     df          F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                  1.665e+01    1.0  3.928e+01  5.252e-09  2.151e-01  2.085e-01\n",
      "C(CVS_levels_3)            3.811e+00    2.0  4.497e+00  1.297e-02  4.925e-02  3.809e-02\n",
      "pre                        1.160e+00    1.0  2.738e+00  1.004e-01  1.499e-02  9.466e-03\n",
      "sim_index                  4.224e-06    1.0  9.968e-06  9.975e-01  5.458e-08 -5.446e-03\n",
      "level_experience_sims      4.346e-01    1.0  1.026e+00  3.131e-01  5.616e-03  1.399e-04\n",
      "experience_undergrad_labs  2.097e-01    1.0  4.948e-01  4.831e-01  2.709e-03 -2.751e-03\n",
      "used_similar_sim           3.962e-01    1.0  9.350e-01  3.354e-01  5.119e-03 -3.542e-04\n",
      "use_graph                  9.179e-01    1.0  2.166e+00  1.436e-01  1.186e-02  6.350e-03\n",
      "Residual                   5.382e+01  127.0        NaN        NaN        NaN        NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.159\n",
      "Model:                            OLS   Adj. R-squared:                  0.106\n",
      "Method:                 Least Squares   F-statistic:                     3.002\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):            0.00406\n",
      "Time:                        16:51:31   Log-Likelihood:                -129.93\n",
      "No. Observations:                 136   AIC:                             277.9\n",
      "Df Residuals:                     127   BIC:                             304.1\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.6969      0.271      6.267      0.000       1.161       2.233\n",
      "C(CVS_levels_3)[T.1]          0.1457      0.180      0.811      0.419      -0.210       0.501\n",
      "C(CVS_levels_3)[T.2]          0.4000      0.133      2.997      0.003       0.136       0.664\n",
      "pre                           0.1382      0.083      1.655      0.100      -0.027       0.303\n",
      "sim_index                    -0.0004      0.116     -0.003      0.997      -0.230       0.229\n",
      "level_experience_sims         0.0675      0.067      1.013      0.313      -0.064       0.199\n",
      "experience_undergrad_labs    -0.1382      0.196     -0.703      0.483      -0.527       0.251\n",
      "used_similar_sim              0.1869      0.193      0.967      0.335      -0.196       0.569\n",
      "use_graph                     0.2429      0.165      1.472      0.144      -0.084       0.570\n",
      "==============================================================================\n",
      "Omnibus:                       39.883   Durbin-Watson:                   2.065\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               86.332\n",
      "Skew:                          -1.233   Prob(JB):                     1.79e-19\n",
      "Kurtosis:                       6.026   Cond. No.                         17.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "__________________________________\n",
      "FOR VARIABLE  Separation \n",
      "__________________________________\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3) + pre + sim_index + level_experience_sims + experience_undergrad_labs + used_similar_sim + use_graph\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                           sum_sq     df       F     PR(>F)  eta_sq  omega_sq\n",
      "Intercept                  11.636    1.0  29.138  3.124e-07   0.172     0.165\n",
      "C(CVS_levels_3)             0.664    2.0   0.832  4.377e-01   0.010    -0.002\n",
      "pre                         1.475    1.0   3.694  5.680e-02   0.022     0.016\n",
      "sim_index                   0.802    1.0   2.009  1.588e-01   0.012     0.006\n",
      "level_experience_sims       0.646    1.0   1.618  2.057e-01   0.010     0.004\n",
      "experience_undergrad_labs   0.149    1.0   0.373  5.425e-01   0.002    -0.004\n",
      "used_similar_sim            0.217    1.0   0.542  4.628e-01   0.003    -0.003\n",
      "use_graph                   0.612    1.0   1.532  2.181e-01   0.009     0.003\n",
      "Residual                   51.516  129.0     NaN        NaN     NaN       NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.109\n",
      "Model:                            OLS   Adj. R-squared:                  0.054\n",
      "Method:                 Least Squares   F-statistic:                     1.975\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):             0.0545\n",
      "Time:                        16:51:31   Log-Likelihood:                -127.82\n",
      "No. Observations:                 138   AIC:                             273.6\n",
      "Df Residuals:                     129   BIC:                             300.0\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.5072      0.279      5.398      0.000       0.955       2.060\n",
      "C(CVS_levels_3)[T.1]         -0.1849      0.187     -0.988      0.325      -0.555       0.185\n",
      "C(CVS_levels_3)[T.2]          0.0687      0.126      0.547      0.586      -0.180       0.318\n",
      "pre                           0.1608      0.084      1.922      0.057      -0.005       0.326\n",
      "sim_index                     0.1553      0.110      1.417      0.159      -0.062       0.372\n",
      "level_experience_sims         0.0841      0.066      1.272      0.206      -0.047       0.215\n",
      "experience_undergrad_labs    -0.1209      0.198     -0.611      0.543      -0.512       0.271\n",
      "used_similar_sim              0.1388      0.188      0.736      0.463      -0.234       0.512\n",
      "use_graph                     0.1973      0.159      1.238      0.218      -0.118       0.513\n",
      "==============================================================================\n",
      "Omnibus:                        5.338   Durbin-Watson:                   2.224\n",
      "Prob(Omnibus):                  0.069   Jarque-Bera (JB):                4.934\n",
      "Skew:                          -0.452   Prob(JB):                       0.0848\n",
      "Kurtosis:                       3.202   Cond. No.                         18.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "for variable in ['Width', 'Concentration','Area','Separation']:\n",
    "    print \"__________________________________\\nFOR VARIABLE \", variable, '\\n__________________________________'\n",
    "    formula = 'main ~ C(CVS_levels_3)' + covariates_for_variable_models\n",
    "    model = ols(formula, filtered_maxpre_data[filtered_maxpre_data['variable']==variable]).fit()\n",
    "    print \"\\n\\nModel: \",formula\n",
    "    aov_table = anova_lm(model, typ=3)\n",
    "    eta_squared(aov_table)\n",
    "    omega_squared(aov_table)\n",
    "    print \"\\nAnova table using type 3 errors\\n\"\n",
    "    print(aov_table)\n",
    "#     print \"\\nHere is the linear model with coefficients and confidence intervals:\\n\"\n",
    "    print clean_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-hoc analysis on levels using 3pts as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "Comparing CVS levels ignoring level  0\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                           sum_sq     df       F     PR(>F)     eta_sq  omega_sq\n",
      "Intercept                  10.994    1.0  30.820  1.702e-07  8.432e-02     0.081\n",
      "C(CVS_levels_3)             2.291    1.0   6.424  1.254e-02  1.757e-02     0.015\n",
      "variable                    1.800    3.0   1.682  1.744e-01  1.381e-02     0.006\n",
      "C(sid)                     69.071   87.0   2.226  2.448e-05  5.297e-01     0.291\n",
      "pre                         0.083    1.0   0.232  6.310e-01  6.343e-04    -0.002\n",
      "sim_index                   1.025    1.0   2.872  9.269e-02  7.858e-03     0.005\n",
      "level_experience_sims       0.581    1.0   1.629  2.042e-01  4.457e-03     0.002\n",
      "experience_undergrad_labs   0.791    1.0   2.217  1.391e-01  6.065e-03     0.003\n",
      "used_similar_sim            0.591    1.0   1.658  2.003e-01  4.536e-03     0.002\n",
      "Residual                   43.162  121.0     NaN        NaN        NaN       NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.593\n",
      "Model:                            OLS   Adj. R-squared:                  0.276\n",
      "Method:                 Least Squares   F-statistic:                     1.873\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           0.000590\n",
      "Time:                        16:24:56   Log-Likelihood:                -132.58\n",
      "No. Observations:                 216   AIC:                             455.2\n",
      "Df Residuals:                     121   BIC:                             775.8\n",
      "Df Model:                          94                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.7130      0.309      5.552      0.000       1.102       2.324\n",
      "C(CVS_levels_3)[T.2]          0.6471      0.255      2.535      0.013       0.142       1.153\n",
      "variable[T.Concentration]     0.0079      0.141      0.056      0.956      -0.272       0.288\n",
      "variable[T.Separation]       -0.2561      0.132     -1.937      0.055      -0.518       0.006\n",
      "variable[T.Width]            -0.0499      0.147     -0.339      0.735      -0.341       0.241\n",
      "pre                          -0.0496      0.103     -0.482      0.631      -0.254       0.154\n",
      "sim_index                     0.1818      0.107      1.695      0.093      -0.031       0.394\n",
      "level_experience_sims        -0.3119      0.244     -1.276      0.204      -0.796       0.172\n",
      "experience_undergrad_labs     0.8406      0.565      1.489      0.139      -0.277       1.958\n",
      "used_similar_sim              0.2516      0.195      1.288      0.200      -0.135       0.639\n",
      "==============================================================================\n",
      "Omnibus:                       13.666   Durbin-Watson:                   2.078\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               33.879\n",
      "Skew:                          -0.145   Prob(JB):                     4.40e-08\n",
      "Kurtosis:                       4.918   Cond. No.                     5.81e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.18e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "Comparing CVS levels ignoring level  1\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                            sum_sq     df        F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   29.111    1.0  118.004  5.655e-24  9.829e-02  9.738e-02\n",
      "C(CVS_levels_3)              3.751    2.0    7.603  5.829e-04  1.267e-02  1.099e-02\n",
      "variable                     2.341    3.0    3.163  2.467e-02  7.903e-03  5.399e-03\n",
      "C(sid)                     166.117  147.0    4.581  4.300e-32  5.609e-01  4.381e-01\n",
      "pre                          0.034    1.0    0.139  7.099e-01  1.154e-04 -7.169e-04\n",
      "sim_index                    4.612    1.0   18.697  1.985e-05  1.557e-02  1.473e-02\n",
      "level_experience_sims        0.486    1.0    1.971  1.612e-01  1.642e-03  8.081e-04\n",
      "experience_undergrad_labs    0.653    1.0    2.648  1.045e-01  2.206e-03  1.372e-03\n",
      "used_similar_sim             0.002    1.0    0.007  9.320e-01  6.082e-06 -8.262e-04\n",
      "Residual                    89.056  361.0      NaN        NaN        NaN        NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.632\n",
      "Model:                            OLS   Adj. R-squared:                  0.474\n",
      "Method:                 Least Squares   F-statistic:                     4.006\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           1.41e-27\n",
      "Time:                        16:24:56   Log-Likelihood:                -278.95\n",
      "No. Observations:                 517   AIC:                             869.9\n",
      "Df Residuals:                     361   BIC:                             1533.\n",
      "Df Model:                         155                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.9862      0.183     10.863      0.000       1.627       2.346\n",
      "C(CVS_levels_3)[T.1]          0.0063      0.105      0.060      0.952      -0.201       0.213\n",
      "C(CVS_levels_3)[T.2]          0.3393      0.088      3.858      0.000       0.166       0.512\n",
      "variable[T.Concentration]     0.1342      0.067      1.992      0.047       0.002       0.267\n",
      "variable[T.Separation]       -0.0716      0.062     -1.148      0.252      -0.194       0.051\n",
      "variable[T.Width]             0.0577      0.068      0.847      0.397      -0.076       0.192\n",
      "pre                          -0.0173      0.046     -0.372      0.710      -0.109       0.074\n",
      "sim_index                     0.2048      0.047      4.324      0.000       0.112       0.298\n",
      "level_experience_sims        -0.2731      0.195     -1.404      0.161      -0.656       0.109\n",
      "experience_undergrad_labs     0.6640      0.408      1.627      0.105      -0.138       1.466\n",
      "used_similar_sim             -0.0074      0.087     -0.085      0.932      -0.178       0.164\n",
      "==============================================================================\n",
      "Omnibus:                       76.443   Durbin-Watson:                   1.966\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              295.170\n",
      "Skew:                          -0.613   Prob(JB):                     8.03e-65\n",
      "Kurtosis:                       6.493   Cond. No.                     1.62e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.89e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "Comparing CVS levels ignoring level  2\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                            sum_sq     df       F     PR(>F)     eta_sq   omega_sq\n",
      "Intercept                   19.068    1.0  94.968  4.357e-19  8.862e-02  8.760e-02\n",
      "C(CVS_levels_3)              2.232    2.0   5.558  4.375e-03  1.037e-02  8.499e-03\n",
      "variable                     0.535    3.0   0.888  4.480e-01  2.486e-03 -3.136e-04\n",
      "C(sid)                     139.874  123.0   5.664  2.277e-30  6.501e-01  5.348e-01\n",
      "pre                          0.140    1.0   0.696  4.050e-01  6.495e-04 -2.834e-04\n",
      "sim_index                    0.564    1.0   2.808  9.514e-02  2.620e-03  1.685e-03\n",
      "level_experience_sims        2.715    1.0  13.522  2.917e-04  1.262e-02  1.167e-02\n",
      "experience_undergrad_labs    2.032    1.0  10.122  1.661e-03  9.445e-03  8.504e-03\n",
      "used_similar_sim             0.426    1.0   2.120  1.467e-01  1.979e-03  1.045e-03\n",
      "Residual                    47.586  237.0     NaN        NaN        NaN        NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.699\n",
      "Model:                            OLS   Adj. R-squared:                  0.533\n",
      "Method:                 Least Squares   F-statistic:                     4.205\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           4.30e-22\n",
      "Time:                        16:24:57   Log-Likelihood:                -145.69\n",
      "No. Observations:                 369   AIC:                             555.4\n",
      "Df Residuals:                     237   BIC:                             1072.\n",
      "Df Model:                         131                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.5304      0.157      9.745      0.000       1.221       1.840\n",
      "C(CVS_levels_3)[T.1]         -0.0295      0.090     -0.329      0.742      -0.206       0.147\n",
      "C(CVS_levels_3)[T.2]          0.3481      0.114      3.065      0.002       0.124       0.572\n",
      "variable[T.Concentration]     0.1093      0.076      1.434      0.153      -0.041       0.259\n",
      "variable[T.Separation]        0.0826      0.069      1.199      0.232      -0.053       0.218\n",
      "variable[T.Width]             0.0428      0.072      0.592      0.555      -0.100       0.185\n",
      "pre                          -0.0425      0.051     -0.834      0.405      -0.143       0.058\n",
      "sim_index                     0.0862      0.051      1.676      0.095      -0.015       0.187\n",
      "level_experience_sims         0.5300      0.144      3.677      0.000       0.246       0.814\n",
      "experience_undergrad_labs    -0.9474      0.298     -3.181      0.002      -1.534      -0.361\n",
      "used_similar_sim             -0.1598      0.110     -1.456      0.147      -0.376       0.056\n",
      "==============================================================================\n",
      "Omnibus:                       41.990   Durbin-Watson:                   1.893\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              233.073\n",
      "Skew:                          -0.210   Prob(JB):                     2.45e-51\n",
      "Kurtosis:                       6.871   Cond. No.                     2.31e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.96e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "for ignore in [0,1,2]:\n",
    "    formula = 'main ~ C(CVS_levels_3)' + covariates_for_parsimonious_model\n",
    "    model = ols(formula, filtered_maxpre_data[filtered_maxpre_data[CVS]!=ignore]).fit()\n",
    "    print \"\\n\\nModel: \",formula\n",
    "    print \"Comparing CVS levels ignoring level \",ignore\n",
    "    aov_table = anova_lm(model, typ=3)\n",
    "    eta_squared(aov_table)\n",
    "    omega_squared(aov_table)\n",
    "    print \"\\nAnova table using type 3 errors\\n\"\n",
    "    print(aov_table)\n",
    "    print clean_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This plot needs to be redone with standard deviation bars and colored by level and stars given the tests above\n",
      "0-1 => -\n",
      "1-2 => *\n",
      "0-2 => ***\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAECCAYAAABE9yh2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAEAjPUfuBsLWSmXomsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1345fb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "levels = pd.pivot_table(filtered_maxpre_data, values=['main'], index=['CVS_levels_3'],aggfunc=np.mean)\n",
    "levels.plot(kind='bar')\n",
    "print \"This plot needs to be redone with standard deviation bars and colored by level and stars given the tests above\"\n",
    "print '0-1 => -'\n",
    "print '1-2 => *'\n",
    "print '0-2 => ***'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc analysis on experience in physic undergraduate labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posthoc_exp_physics_labs = pd.pivot_table(data, values=['main'], index=['experience_undergrad_labs'],aggfunc=(np.mean))\n",
    "# posthoc_exp_physics_labs.plot(kind='bar')\n",
    "# print \"This plot needs to be redone with standard deviation bars and organized by sim, colored by level\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc analysis on order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posthoc_sim_index = pd.pivot_table(data, values=['main'], index=['sim_index'],aggfunc=(np.mean))\n",
    "# posthoc_sim_index.plot(kind='bar')\n",
    "# print \"This plot needs to be redone with standard deviation bars and organized by sim, colored by level\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc analysis on variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posthoc_variable = pd.pivot_table(data, values=['main'], index=['variable'],aggfunc=(np.mean))\n",
    "# posthoc_variable.plot(kind='bar')\n",
    "# print \"This plot needs to be redone with standard deviation bars and organized by sim, colored by level\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "Findings:\n",
    "* CVS_levels=2 (graph) matters for all except Separation\n",
    "* Pre matters for all except Width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat model for only student who use graph (85%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model:  main ~ C(CVS_levels_3)+ variable + pre + sim_index + C(sid) + level_experience_sims + experience_undergrad_labs + used_similar_sim\n",
      "\n",
      "Anova table using type 3 errors\n",
      "\n",
      "                           sum_sq     df       F     PR(>F)     eta_sq  omega_sq\n",
      "Intercept                  11.013    1.0  30.875  1.665e-07  8.456e-02     0.082\n",
      "C(CVS_levels_3)             2.291    1.0   6.424  1.254e-02  1.759e-02     0.015\n",
      "variable                    1.800    3.0   1.682  1.744e-01  1.382e-02     0.006\n",
      "C(sid)                     68.895   85.0   2.272  1.707e-05  5.290e-01     0.295\n",
      "pre                         0.083    1.0   0.232  6.310e-01  6.350e-04    -0.002\n",
      "sim_index                   1.025    1.0   2.872  9.269e-02  7.867e-03     0.005\n",
      "level_experience_sims       0.584    1.0   1.637  2.032e-01  4.483e-03     0.002\n",
      "experience_undergrad_labs   0.793    1.0   2.222  1.387e-01  6.086e-03     0.003\n",
      "used_similar_sim            0.591    1.0   1.658  2.003e-01  4.541e-03     0.002\n",
      "Residual                   43.162  121.0     NaN        NaN        NaN       NaN\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   main   R-squared:                       0.591\n",
      "Model:                            OLS   Adj. R-squared:                  0.280\n",
      "Method:                 Least Squares   F-statistic:                     1.899\n",
      "Date:                Wed, 07 Feb 2018   Prob (F-statistic):           0.000485\n",
      "Time:                        16:31:30   Log-Likelihood:                -132.34\n",
      "No. Observations:                 214   AIC:                             450.7\n",
      "Df Residuals:                     121   BIC:                             763.7\n",
      "Df Model:                          92                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================\n",
      "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                     1.7129      0.308      5.556      0.000       1.103       2.323\n",
      "C(CVS_levels_3)[T.2]          0.6471      0.255      2.535      0.013       0.142       1.153\n",
      "variable[T.Concentration]     0.0079      0.141      0.056      0.956      -0.272       0.288\n",
      "variable[T.Separation]       -0.2561      0.132     -1.937      0.055      -0.518       0.006\n",
      "variable[T.Width]            -0.0499      0.147     -0.339      0.735      -0.341       0.241\n",
      "pre                          -0.0496      0.103     -0.482      0.631      -0.254       0.154\n",
      "sim_index                     0.1818      0.107      1.695      0.093      -0.031       0.394\n",
      "level_experience_sims        -0.3111      0.243     -1.279      0.203      -0.793       0.170\n",
      "experience_undergrad_labs     0.8399      0.563      1.491      0.139      -0.276       1.955\n",
      "used_similar_sim              0.2516      0.195      1.288      0.200      -0.135       0.639\n",
      "==============================================================================\n",
      "Omnibus:                       13.229   Durbin-Watson:                   2.078\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               32.019\n",
      "Skew:                          -0.144   Prob(JB):                     1.11e-07\n",
      "Kurtosis:                       4.873   Cond. No.                     1.36e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.29e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "formula = 'main ~ C(CVS_levels_3)' + covariates_for_parsimonious_model\n",
    "model = ols(formula, filtered_maxpre_data[(filtered_maxpre_data[CVS]!=0)&(filtered_maxpre_data['use_graph']==1)]).fit()\n",
    "print \"\\n\\nModel: \",formula\n",
    "aov_table = anova_lm(model, typ=3)\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print \"\\nAnova table using type 3 errors\\n\"\n",
    "print(aov_table)\n",
    "print clean_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# What affects use CVS-like inquiry strategies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true
   },
   "source": [
    "For some reason adding students in the matric turns it into a singular matrix and fails the analysis. Probably because two students are exactly identical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Overall, how much do they use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CVS_table'] = data['CVS_table_3']\n",
    "data['CVS_graph'] = data['CVS_graph_3']\n",
    "sums = pd.pivot_table(data, values=['CVS_table','CVS_graph'], index=['sid'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 29)\n"
     ]
    }
   ],
   "source": [
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For CVs with 2 pts as a threshold\n",
      "   93% of students use CVS table once and 47% do it for all variables.\n",
      "   70% of students use CVS graph once and 29% do it for all variables.\n",
      "\n",
      "For CVs with 3 pts as a threshold\n",
      "   81% of students use CVS table once and 35% do it for all variables.\n",
      "   65% of students use CVS graph once and 26% do it for all variables.\n",
      "\n",
      "For CVs with 4 pts as a threshold\n",
      "   68% of students use CVS table once and 30% do it for all variables.\n",
      "   61% of students use CVS graph once and 23% do it for all variables.\n",
      "\n",
      "For CVs with 5 pts as a threshold\n",
      "   61% of students use CVS table once and 18% do it for all variables.\n",
      "   55% of students use CVS graph once and 13% do it for all variables.\n"
     ]
    }
   ],
   "source": [
    "for threshold in ['2','3','4','5']:\n",
    "    print '\\nFor CVs with {0} pts as a threshold'.format(threshold)\n",
    "    sums = pd.pivot_table(data, values=['CVS_table_'+threshold,'CVS_graph_'+threshold], index=['sid'], aggfunc=np.sum)\n",
    "    once = len(sums[sums['CVS_table_'+threshold]>0])/float(N)*100\n",
    "    all4 = len(sums[sums['CVS_table_'+threshold]==4])/float(N)*100\n",
    "    print \"   {0}% of students use CVS table once and {1}% do it for all variables.\".format(int(once),int(all4))\n",
    "    once = len(sums[sums['CVS_graph_'+threshold]>0])/float(N)*100\n",
    "    all4 = len(sums[sums['CVS_graph_'+threshold]==4])/float(N)*100\n",
    "    print \"   {0}% of students use CVS graph once and {1}% do it for all variables.\".format(int(once),int(all4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are they consistent in their usage of CVS graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums2 = pd.pivot_table(data, values=['CVS_graph'], index=['sid','sim'], aggfunc=np.sum)\n",
    "sums2 = sums2.reset_index(level=['sim','sid'])\n",
    "# sums2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x138856a0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcMAAAEWCAYAAAAadfxCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLlPVRJpO2JoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13667fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvs_sim = np.zeros((3,3),dtype=int)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        cvs_sim[i,j] = len(set(sums2[(sums2['sim']=='C')&(sums2['CVS_graph']==i)]['sid'])&set(sums2[(sums2['sim']=='L')&(sums2['CVS_graph']==j)]['sid']))\n",
    "ax = sns.heatmap(np.flip(cvs_sim,0),annot=True, fmt=\"d\")\n",
    "ax.set_xticklabels(['0/2','1/2','2/2'])\n",
    "ax.set_yticklabels(['0/2','1/2','2/2'])\n",
    "plt.xlabel('Number of light absorbance variables')\n",
    "plt.ylabel('Number of Caps variables')\n",
    "plt.title('Map of student use of CVS in their graph for variables per simulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "High usage is consistent. If they do CVS with 1 variable in one sim, they do it with 2 in the other (probaly second sim).We'll see how order makes a difference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## What affects use of CVS\n",
    "### Model with interaction (killed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# formula = 'CVS_graph ~ pre*variable + sim_index*variable + pre*sim_index + level_experience_sims + experience_undergrad_labs + used_similar_sim'\n",
    "# print 'model: ', formula,'\\n'\n",
    "# from patsy import dmatrices\n",
    "# Y, X = dmatrices(formula, data, return_type = 'dataframe')\n",
    "# # print X.columns\n",
    "# logit = Logit(Y, X)\n",
    "# model = logit.fit()\n",
    "# print model.summary()\n",
    "# # note that stats model has no module for running an anova on a logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parismonious model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  CVS_graph ~ pre + variable + sim_index +level_experience_sims + experience_undergrad_labs + used_similar_sim \n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.634028\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              CVS_graph   No. Observations:                  592\n",
      "Model:                          Logit   Df Residuals:                      583\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Wed, 07 Feb 2018   Pseudo R-squ.:                 0.07976\n",
      "Time:                        14:14:19   Log-Likelihood:                -375.34\n",
      "converged:                       True   LL-Null:                       -407.88\n",
      "                                        LLR p-value:                 4.685e-11\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "Intercept                    -3.5259      0.540     -6.530      0.000      -4.584      -2.468\n",
      "variable[T.Concentration]     0.2637      0.253      1.042      0.297      -0.232       0.760\n",
      "variable[T.Separation]       -0.0450      0.246     -0.183      0.855      -0.527       0.437\n",
      "variable[T.Width]             0.0868      0.254      0.342      0.732      -0.410       0.584\n",
      "pre                           0.2423      0.108      2.234      0.026       0.030       0.455\n",
      "sim_index                     0.5463      0.175      3.122      0.002       0.203       0.889\n",
      "level_experience_sims         0.1607      0.104      1.543      0.123      -0.043       0.365\n",
      "experience_undergrad_labs     2.0081      0.429      4.679      0.000       1.167       2.849\n",
      "used_similar_sim              0.0455      0.225      0.202      0.840      -0.396       0.486\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "formula = 'CVS_graph ~ pre + variable + sim_index +level_experience_sims + experience_undergrad_labs + used_similar_sim'\n",
    "print 'model: ', formula,'\\n'\n",
    "from patsy import dmatrices\n",
    "Y, X = dmatrices(formula, data, return_type = 'dataframe')\n",
    "# print X.columns\n",
    "logit = Logit(Y, X)\n",
    "model = logit.fit()\n",
    "print model.summary()\n",
    "# aov_table = anova_lm(model)\n",
    "# eta_squared(aov_table)\n",
    "# omega_squared(aov_table)\n",
    "# # print \"\\nAnova table using type 2 errors\\n\"\n",
    "# print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "In order of what affects CVS_graph most:\n",
    "* experience in undergraduate labs\n",
    "* order\n",
    "* prior knowledge\n",
    "\n",
    "Having used a similar sim doesn't matter, variable doesn't matter and sim doesn't matter.\n",
    "\n",
    "Experience in sims mattered before we included both physics and chem experience in labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>CVS_graph</td>    <th>  No. Observations:  </th>  <td>   592</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   583</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 07 Feb 2018</td> <th>  Pseudo R-squ.:     </th>  <td>0.07976</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>14:14:19</td>     <th>  Log-Likelihood:    </th> <td> -375.34</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -407.88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.685e-11</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                 <td>   -3.5259</td> <td>    0.540</td> <td>   -6.530</td> <td> 0.000</td> <td>   -4.584</td> <td>   -2.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>variable[T.Concentration]</th> <td>    0.2637</td> <td>    0.253</td> <td>    1.042</td> <td> 0.297</td> <td>   -0.232</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>variable[T.Separation]</th>    <td>   -0.0450</td> <td>    0.246</td> <td>   -0.183</td> <td> 0.855</td> <td>   -0.527</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>variable[T.Width]</th>         <td>    0.0868</td> <td>    0.254</td> <td>    0.342</td> <td> 0.732</td> <td>   -0.410</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pre</th>                       <td>    0.2423</td> <td>    0.108</td> <td>    2.234</td> <td> 0.026</td> <td>    0.030</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sim_index</th>                 <td>    0.5463</td> <td>    0.175</td> <td>    3.122</td> <td> 0.002</td> <td>    0.203</td> <td>    0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>level_experience_sims</th>     <td>    0.1607</td> <td>    0.104</td> <td>    1.543</td> <td> 0.123</td> <td>   -0.043</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>experience_undergrad_labs</th> <td>    2.0081</td> <td>    0.429</td> <td>    4.679</td> <td> 0.000</td> <td>    1.167</td> <td>    2.849</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>used_similar_sim</th>          <td>    0.0455</td> <td>    0.225</td> <td>    0.202</td> <td> 0.840</td> <td>   -0.396</td> <td>    0.486</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              CVS_graph   No. Observations:                  592\n",
       "Model:                          Logit   Df Residuals:                      583\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Wed, 07 Feb 2018   Pseudo R-squ.:                 0.07976\n",
       "Time:                        14:14:19   Log-Likelihood:                -375.34\n",
       "converged:                       True   LL-Null:                       -407.88\n",
       "                                        LLR p-value:                 4.685e-11\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "Intercept                    -3.5259      0.540     -6.530      0.000      -4.584      -2.468\n",
       "variable[T.Concentration]     0.2637      0.253      1.042      0.297      -0.232       0.760\n",
       "variable[T.Separation]       -0.0450      0.246     -0.183      0.855      -0.527       0.437\n",
       "variable[T.Width]             0.0868      0.254      0.342      0.732      -0.410       0.584\n",
       "pre                           0.2423      0.108      2.234      0.026       0.030       0.455\n",
       "sim_index                     0.5463      0.175      3.122      0.002       0.203       0.889\n",
       "level_experience_sims         0.1607      0.104      1.543      0.123      -0.043       0.365\n",
       "experience_undergrad_labs     2.0081      0.429      4.679      0.000       1.167       2.849\n",
       "used_similar_sim              0.0455      0.225      0.202      0.840      -0.396       0.486\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}              &    CVS_graph     & \\textbf{  No. Observations:  } &      592    \\\\\n",
      "\\textbf{Model:}                      &      Logit       & \\textbf{  Df Residuals:      } &      583    \\\\\n",
      "\\textbf{Method:}                     &       MLE        & \\textbf{  Df Model:          } &        8    \\\\\n",
      "\\textbf{Date:}                       & Wed, 07 Feb 2018 & \\textbf{  Pseudo R-squ.:     } &  0.07976    \\\\\n",
      "\\textbf{Time:}                       &     14:14:20     & \\textbf{  Log-Likelihood:    } &   -375.34   \\\\\n",
      "\\textbf{converged:}                  &       True       & \\textbf{  LL-Null:           } &   -407.88   \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$>$$|$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}                   &      -3.5259  &        0.540     &    -6.530  &         0.000        &       -4.584    &       -2.468     \\\\\n",
      "\\textbf{variable[T.Concentration]}   &       0.2637  &        0.253     &     1.042  &         0.297        &       -0.232    &        0.760     \\\\\n",
      "\\textbf{variable[T.Separation]}      &      -0.0450  &        0.246     &    -0.183  &         0.855        &       -0.527    &        0.437     \\\\\n",
      "\\textbf{variable[T.Width]}           &       0.0868  &        0.254     &     0.342  &         0.732        &       -0.410    &        0.584     \\\\\n",
      "\\textbf{pre}                         &       0.2423  &        0.108     &     2.234  &         0.026        &        0.030    &        0.455     \\\\\n",
      "\\textbf{sim\\_index}                  &       0.5463  &        0.175     &     3.122  &         0.002        &        0.203    &        0.889     \\\\\n",
      "\\textbf{level\\_experience\\_sims}     &       0.1607  &        0.104     &     1.543  &         0.123        &       -0.043    &        0.365     \\\\\n",
      "\\textbf{experience\\_undergrad\\_labs} &       2.0081  &        0.429     &     4.679  &         0.000        &        1.167    &        2.849     \\\\\n",
      "\\textbf{used\\_similar\\_sim}          &       0.0455  &        0.225     &     0.202  &         0.840        &       -0.396    &        0.486     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Logit Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "print model.summary().as_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post hoc of experience in undergraduate labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvs_exp = pd.pivot_table(data, values=['CVS_graph'], index=['experience_undergrad_labs'],aggfunc=(np.mean,np.std))\n",
    "# print \"Here is prob that they do CVS graph depending on the experience_undergrad_labs\"\n",
    "# cvs_exp['CVS_graph']['mean'].plot.bar(yerr=cvs_exp['CVS_graph']['std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post hoc of activity order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvs_exp = pd.pivot_table(data, values=['CVS_graph'], index=['sim_index'],aggfunc=(np.mean,np.std))\n",
    "# print \"Here is prob that they do CVS graph depending on sim_index\"\n",
    "# cvs_exp['CVS_graph']['mean'].plot.bar(yerr=cvs_exp['CVS_graph']['std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post hoc of experience with sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvs_exp = pd.pivot_table(data, values=['CVS_graph'], index=['level_experience_sims'],aggfunc=(np.mean,np.std))\n",
    "# print \"Here is prob that they do CVS graph depending on level_experience_sims\"\n",
    "# cvs_exp['CVS_graph']['mean'].plot.bar(yerr=cvs_exp['CVS_graph']['std'])\n",
    "# print '''where:\n",
    "#  0 -> None\n",
    "#  1 -> 1-2 (roughly)\n",
    "#  2 -> 3-5 (roughly)\n",
    "#  3 -> 6+ (roughly)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### post hoc of pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvs_pre = pd.pivot_table(data, values=['CVS_graph'], index=['pre'],aggfunc=(np.mean,np.std))\n",
    "# print \"Here is the avg pre score of students depending if they do CVS graph or not\"\n",
    "# cvs_pre['CVS_graph']['mean'].plot.bar(yerr=cvs_pre['CVS_graph']['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
